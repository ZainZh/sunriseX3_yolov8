# å®‰è£…ç³»ç»Ÿ

1. ä¸‹è½½æ—­æ—¥X3æ´¾ç³»ç»Ÿé•œåƒï¼ˆæ¡Œé¢ç‰ˆï¼‰
    
    [é“¾æ¥ï¼š[https://pan.baidu.com/s/1whw8k4EVS4zKCaaBWOia_Q?pwd=snv2](https://pan.baidu.com/s/1whw8k4EVS4zKCaaBWOia_Q?pwd=snv2) ](https://developer.horizon.ai/resource)
    
    é“¾æ¥ï¼š[https://pan.baidu.com/s/1whw8k4EVS4zKCaaBWOia_Q?pwd=snv2](https://pan.baidu.com/s/1whw8k4EVS4zKCaaBWOia_Q?pwd=snv2) 
    
2. åˆ©ç”¨balenaEtcherå°†ä¸‹è½½å¾—åˆ°çš„é•œåƒæ–‡ä»¶çƒ§å†™è‡³SDå¡
3. å¯åŠ¨ç³»ç»Ÿ
    
    ä¿æŒæ—­æ—¥X3æ´¾å¼€å‘æ¿æ–­ç”µï¼Œå°†åˆ¶ä½œå¥½çš„TFå­˜å‚¨å¡æ’å…¥æ—­æ—¥X3æ´¾å¼€å‘æ¿çš„TFå¡æ§½ï¼Œå¹¶å°†æ˜¾ç¤ºå™¨æ¥å…¥å¼€å‘æ¿HDMIæ¥å£ï¼Œç„¶åç»™å¼€å‘æ¿ä¸Šç”µï¼Œç”¨æˆ·å¯é€šè¿‡æŒ‡ç¤ºç¯åˆ¤æ–­å¼€å‘æ¿çŠ¶æ€ï¼ŒæŒ‡ç¤ºç¯è¯´æ˜å¦‚ä¸‹ï¼š
    
    - çº¢è‰²æŒ‡ç¤ºç¯ï¼šç‚¹äº®ä»£è¡¨ç¡¬ä»¶ä¸Šç”µæ­£å¸¸
    - ç»¿è‰²æŒ‡ç¤ºç¯ï¼šç‚¹äº®ä»£è¡¨ç³»ç»Ÿå¯åŠ¨ä¸­ï¼Œç†„ç­ä»£è¡¨ç³»ç»Ÿå¯åŠ¨å®Œæˆ
    
    ç³»ç»Ÿé¦–æ¬¡å¯åŠ¨æ—¶ä¼šå®‰è£…é•œåƒä¸­é¢„ç½®çš„å·¥å…·åŒ…ï¼Œæ•´ä¸ªè¿‡ç¨‹å¤§æ¦‚éœ€è¦1åˆ†é’Ÿï¼Œå®Œæˆåæ‰“å¼€HDMIè¾“å‡ºï¼Œå¹¶æ˜¾ç¤ºå¼€æœºç”»é¢(Serverç³»ç»Ÿæ˜¾ç¤ºåœ°å¹³çº¿logoã€Desktopç‰ˆæœ¬æ˜¾ç¤ºç³»ç»Ÿæ¡Œé¢)ã€‚
    
    ç»¿è‰²æŒ‡ç¤ºç¯ç†„ç­ï¼Œå¹¶ä¸”å¼€æœºç”»é¢æ­£å¸¸æ˜¾ç¤ºåï¼Œè¯´æ˜ç³»ç»Ÿå¯åŠ¨å®Œæˆï¼Œæ­¤æ—¶å¯é€šè¿‡[ä¸²å£ç™»å½•](https://developer.horizon.ai/api/v1/fileData/documents_pi/Quick_Start/Quick_Start.html#login_uart)ã€[SSHç™»å½•](https://developer.horizon.ai/api/v1/fileData/documents_pi/Quick_Start/Quick_Start.html#ssh)æ–¹å¼ç™»å½•å¼€å‘æ¿ï¼Œç™»å½•ç”¨æˆ·åï¼š`sunrise`Â å¯†ç ï¼š`sunrise`
    

# ç¡¬ä»¶è®¾ç½®

## é£æ‰‡ä½¿ç”¨

X3æ´¾è‡ªå¸¦çš„é“å£³ä¸Šæœ‰ä¸€ä¸ªå°é£æ‰‡ï¼Œé£æ‰‡æ¥çº¿æŒ‰ä¸‹å›¾æ‰€ç¤ºæ¥åœ¨40Pinæ¥å£çš„4ã€6ç«¯å£ä¸Šã€‚é£æ‰‡èƒ½çœ‹åˆ°æ ‡ç­¾çš„ä¸€é¢å¯¹åº”å‡ºé£æ–¹å‘ï¼Œåº”æœå‘èŠ¯ç‰‡ã€‚

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/71caa1e0-943b-46fc-999a-f57cca5f0263/Untitled.png)

![å¾®ä¿¡å›¾ç‰‡_20221215163313.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/7816d2b9-d35e-4b4b-a1b1-231393beadc6/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20221215163313.png)

## WIFIå¤©çº¿

å…ˆå°†WIFIå°„é¢‘çº¿Då‹ç«¯ä»é“å£³å­”ä¸­ç©¿å‡ºï¼Œå†å°†å°ç«¯æŒ‰å‹åœ¨ä¸»æ¿ä¸Šï¼Œæœ€åå°†ä¸»æ¿è£…åœ¨é“å£³å†…ã€‚

## MIPIç›¸æœºè¿æ¥

![å¾®ä¿¡å›¾ç‰‡_20221215173137.jpg](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/6560d07f-a6c5-465d-a4d7-b6db9bc7a27c/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20221215173137.jpg)

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/7ab72804-3ca5-433a-aac9-7cd7fc3419f9/Untitled.png)

å®‰è£…æ’çº¿æ³¨æ„äº‹é¡¹ï¼š

ç›¸æœºã€ä¸»æ¿æ¥æ’ä»¶ä¸Šéƒ½æœ‰ä¸€æ’é»‘è‰²ç¿»æ¿å¡æ‰£ï¼Œå®‰è£…æ’çº¿æ—¶éœ€è¦å…ˆå°†å¡æ‰£æ‰“å¼€ï¼›

ç›¸æœºç«¯ï¼Œè“è‰²ç‰‡æœå‘ç›¸æœºèƒŒé¢ï¼›

ä¸»æ¿ç«¯ï¼Œè“è‰²ç‰‡æœå‘ä¸»æ¿æ­£é¢ï¼›

```bash
cd /app/ai_inference/03_mipi_camera_sample/
sudo python3 ./mipi_camera.py
```

# è¿œç¨‹ç™»å½•è®¾ç½®

åœ¨å±€åŸŸç½‘å†…ï¼Œé€šè¿‡ä¸€å°Winç¬”è®°æœ¬ï¼Œå®ç°äº†ç»ç”±WIFIçš„è¿œç¨‹ç™»å½•ã€‚ä¸»è¦éœ€è¦é…ç½®Winç”µè„‘ç«¯çš„IPv4è¿æ¥å±æ€§ï¼Œå°†æœ¬æœºIPè®¾ä¸ºé™æ€IPï¼Œç½‘å…³è®¾ä¸º255.255.255.0ã€‚X3æ´¾ä¸€ç«¯ä»…éœ€è¿æ¥åˆ°åŒä¸€WIFIï¼Œä¸éœ€è¦è¿›è¡Œé¢å¤–è®¾ç½®ã€‚X3æ´¾çš„IPåœ°å€å¯ä»¥é€šè¿‡è·¯ç”±å™¨æŸ¥çœ‹ï¼Œè®¾å¤‡åç§°ä¸ºubuntuã€‚

ä½¿ç”¨MobaXtermè½¯ä»¶ï¼Œæ–°å»ºä¸€ä¸ªSSHè¿æ¥ï¼Œè¿œç¨‹IPå¡«å†™X3æ´¾IPï¼ŒæŒ‡å®šç”¨æˆ·ï¼šsunriseï¼Œå¯†ç ä¹Ÿä¸ºsunriseã€‚èƒ½å¤ŸæˆåŠŸç™»å½•ã€‚

# æ¨¡å‹éƒ¨ç½²

## åŸºæœ¬æ¦‚å¿µ

åœ¨X3æ´¾ä¸Šéƒ¨ç½²è‡ªå®šä¹‰æ¨¡å‹æ¶‰åŠå¤šé¡¹è½¯ä»¶åŠå…¶è¿è¡Œç¯å¢ƒã€‚ä»è¿è¡Œç¯å¢ƒæ¥è¯´ï¼ŒåŒ…æ‹¬ï¼š

1. å¼€å‘æœºï¼ˆUbuntuç³»ç»Ÿï¼Œå®è·µä¸­é‡‡ç”¨20.04ï¼‰
2. X3æ´¾ï¼ˆUbuntuç³»ç»Ÿï¼‰

åœ¨å¼€å‘æœºä¸Šï¼Œéœ€è¦ä¸‹è½½å¹¶è§£å‹å¤©å·¥å¼€ç‰©ï¼ˆä¹Ÿå°±æ˜¯ä¸‹æ–‡æåˆ°çš„OEï¼‰å‘å¸ƒåŒ…ã€æ‹‰å–OEå¼€å‘ç¯å¢ƒé•œåƒã€‚X3æ´¾ä¸Šä¸éœ€è¦ä¸‹è½½æˆ–æ‹‰å–é•œåƒï¼Œæ¨¡å‹çš„éƒ¨ç½²éƒ½æ˜¯é€šè¿‡å¼€å‘æœºå®Œæˆã€‚

OEå‘å¸ƒåŒ…æ˜¯ä¸€ä¸ªæ•´åˆäº†å„é¡¹èµ„æºï¼Œä¾‹å¦‚é¢„è®­ç»ƒæ¨¡å‹ç­‰çš„èµ„æºåŒ…ï¼›OEé•œåƒåˆ™åŒ…æ‹¬æ¨¡å‹éƒ¨ç½²æ‰€éœ€çš„å„é¡¹è½¯ä»¶åŠå…¶ä¾èµ–çš„ç¯å¢ƒã€‚

## è·å–Open Explorerå‘å¸ƒåŒ…

åœ¨ä»¥ä¸‹é“¾æ¥ï¼š

[](https://developer.horizon.ai/forumDetail/136488103547258769)

ä¸‹è½½**2.2.3 ç‰ˆæœ¬**çš„Open Explorer (ç®€ç§°OE)ã€‚è¿è¡Œä»¥ä¸‹å‘½ä»¤è¿›è¡Œä¸‹è½½ï¼š

```bash
# ä¸‹è½½å‘å¸ƒåŒ…
wget -c ftp://vrftp.horizon.ai/Open_Explorer_gcc_9.3.0/2.2.3/horizon_xj3_open_explorer_v2.2.3a_20220701.tar.gz

# ä¸‹è½½æ–‡æ¡£ï¼ˆå¯é€‰ï¼‰
wget -c ftp://vrftp.horizon.ai/Open_Explorer_gcc_9.3.0/2.2.3/horizon_xj3_open_explorer_v2.2.3a_doc.zip
```

<aside>
âš ï¸ ç›´æ¥ç‚¹å‡»é“¾æ¥ä¸‹è½½æ— ååº”ã€‚å®˜æ–¹æä¾›çš„ä¸‹è½½æ–¹å¼æ˜¯é€šè¿‡wgetï¼Œåœ¨Winç«¯å¯é€šè¿‡MobaXtermå†…ç½®çš„Terminalè¿è¡Œä¸Šè¿°å‘½ä»¤ï¼Œç„¶åå†é€šè¿‡ä»¥ä¸‹å‘½ä»¤ï¼Œå°†å…¶ä»Mobaå†…éƒ¨åœ°å€ç§»åŠ¨åˆ°Winç«¯ï¼š
mv horizon_xj3_open_explorer_v2.2.3a_doc.zip /drives/c/Users/dzp/Downloads/

</aside>

åœ¨Ubuntuå¼€å‘æœºä¸Šï¼Œå°†å‘å¸ƒåŒ…è§£å‹ï¼Œå¾—åˆ° `horizon_xj3_open_explorer_v2.2.3a_20220701` æ–‡ä»¶å¤¹ï¼Œå…¶ä¸­å†…å®¹åŒ…æ‹¬ï¼š

```bash
.
â”œâ”€â”€ bsp
â”œâ”€â”€ ddk
â”œâ”€â”€ doc
â”œâ”€â”€ release_note.txt
â”œâ”€â”€ run_docker.sh
â””â”€â”€ tools
```

## è·å–OE Dockeré•œåƒ

ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ä»å®˜æ–¹æºæ‹‰å–é•œåƒï¼š

```bash
docker pull openexplorer/ai_toolchain_centos_7_xj3:v2.3.3
```

<aside>
ğŸ’¡ OEå¼€å‘åŒ…ä¸­çš„ `run_docker.sh` è„šæœ¬ä¸­å†…ç½®äº†è‡ªåŠ¨pullæ‰€éœ€é•œåƒçš„æ“ä½œï¼Œå› æ­¤å¯ä»¥ä¸å•ç‹¬æ“ä½œã€‚ä½†å½“æ‰€éœ€é•œåƒæœªåœ¨Docker Hubå…±äº«æ—¶ï¼Œåˆ™éœ€è¦å•ç‹¬ä¸‹è½½é•œåƒå‹ç¼©åŒ…ï¼Œå¹¶ä»å®˜æ–¹æä¾›çš„tar.gzä¸­è§£å‹å¾—åˆ°æ‰€éœ€é•œåƒï¼Œæœ‰å¿…è¦çš„è¯è¿˜è¦å¯¹é•œåƒé‡å‘½åã€‚
`docker load < docker_openexplorer_centos_7_xj3_v2.4.2.tar.gz`
`docker tag [hub.hobot.cc/aitools/ai_toolchain_centos_7_xj3:v2.4.2](http://hub.hobot.cc/aitools/ai_toolchain_centos_7_xj3:v2.4.2) openexplorer/ai_toolchain_centos_7_xj3:v2.4.2`

</aside>

<aside>
âš ï¸ é™¤äº† `ai_toolchain_centos_7_xj3` å¤–ï¼Œopenexplorerè¿˜æä¾›äº† `ai_toolchain_ubuntu_gpu_xj3` ********ï¼Œ `ai_toolchain_centos_7` ï¼Œ `ai_toolchain_ubuntu_gpu` ç­‰é•œåƒï¼Œä½†è¿™äº›é•œåƒå‡å·²åœæ­¢ç»´æŠ¤ã€‚

</aside>

## å‡†å¤‡å¼€å‘ç¯å¢ƒ

[1. äº§å“ä»‹ç» - horizon_ai_toolchain_user_guide v1.12.3 æ–‡æ¡£](https://developer.horizon.ai/api/v1/fileData/doc/ddk_doc/navigation/ai_toolchain/docs_cn/horizon_ai_toolchain_user_guide/introduction.html)

åœ¨å¼€å‘æœºç«¯æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š

```bash
# è¿›å…¥OEåŒ…é¡¶å±‚è·¯å¾„
cd horizon_xj3_open_explorer_v2.2.3a_20220701/

# è¿è¡Œè„šæœ¬å¯åŠ¨CPU Dockerå®¹å™¨ï¼Œ/dataè¯·åœ¨ä½¿ç”¨æ—¶æ›¿æ¢ä¸ºæ‚¨æ ¡å‡†/è¯„æµ‹æ•°æ®é›†è·¯å¾„
# å®¹å™¨å¯åŠ¨åï¼Œé»˜è®¤ä¼šå°†OEåŒ…æŒ‚è½½åœ¨/open_explorerï¼Œå°†æ•°æ®é›†æŒ‚è½½åœ¨/data/horizon_x3/data
# dataå¯ä»¥ä¸ºæ–°å»ºæ–‡ä»¶å¤¹ï¼Œä¸”å¯ä»¥ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼Œä¾‹å¦‚./data
bash run_docker.sh ./data
```

æ‰§è¡Œå®Œæˆåä¼šè¿›å…¥å®¹å™¨ `[root@40a4c5d5f2a7 open_explorer]#` ï¼Œä½¿ç”¨ `ll` å‘½ä»¤æŸ¥çœ‹æ ¹ç›®å½•ä¸‹å†…å®¹ï¼Œå¯ä»¥çœ‹åˆ°æ ¹ç›®å½•å†…å®¹ä¸OEé¡¶å±‚æ–‡ä»¶å¤¹å†…å®¹ä¸€è‡´ã€‚

## æ¿ç«¯ç¯å¢ƒé…ç½®

åœ¨å®¹å™¨å†…éƒ¨æ ¹ç›®å½•ä¸‹è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š

```bash
cd /open_explorer/ddk/package/board

# board_ipæ˜¯å¼€å‘æ¿å±€åŸŸç½‘IPï¼Œä¾‹å¦‚192.168.31.90ï¼Œå¯é€šè¿‡pingå‘½ä»¤æŸ¥çœ‹èƒ½å¦è¿æ¥ã€‚
# æ‰§è¡Œä»¥ä¸‹å‘½ä»¤åéœ€è¦è¾“å…¥å¯†ç ä»¥å»ºç«‹SSHè¿æ¥ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå»ºç«‹è¿æ¥çš„ç”¨æˆ·æ˜¯rootï¼Œå¯†ç ä¹Ÿæ˜¯rootï¼Œè€Œä¸æ˜¯sunriseã€‚å®‰è£…è¿‡ç¨‹ä¸­éœ€è¦å¤šæ¬¡è¾“å…¥å¯†ç ã€‚
bash install.sh {board_ip}

# DZP: ä»¥ä¸‹å†…å®¹åœ¨å®˜æ–¹æ–‡æ¡£æœ‰æ¶‰åŠï¼Œä½†å­˜åœ¨ä¸€äº›æ–‡ä»¶ä¸å­˜åœ¨ç±»å‹çš„é—®é¢˜ã€‚ä¸”ä¸åšå¯¹éƒ¨ç½²è‡ªå®šä¹‰æ¨¡å‹åº”è¯¥æ— å½±å“
# cd /open_explorer
# scp -r ddk/samples/model_zoo/runtime/ root@{boad_ip}:/userdata/xj3/model/
# cd /userdata/xj3/script/00_quick_start/
# bash run_mobilenetV1.sh
```

<aside>
ğŸš§ **scp: /userdata/xj3/model/: No such file or directory**
åœ¨ä¸Šè¿°è¿è¡Œè¿‡ç¨‹ä¸­ï¼Œscpå¦‚å‡ºç°è¯¥é—®é¢˜ï¼Œå¯ä»¥åœ¨å¼€å‘æœºä¸Šé€šè¿‡Asbruï¼ˆç›¸å½“äºUbuntuç«¯çš„MobaXtermï¼‰è¿œç¨‹ç™»å½•åˆ°X3æ´¾ä¸­ï¼Œç™»å½•ç”¨æˆ·é€‰æ‹©ä¸ºrootï¼Œåœ¨/userdataæ–‡ä»¶å¤¹ä¸‹åˆ›å»ºç¼ºå¤±è·¯å¾„

</aside>

```bash
mkdir -p xj3/model
```

## å®˜æ–¹æ¨¡å‹éƒ¨ç½²ç¤ºä¾‹

æœ¬éƒ¨åˆ†å†…å®¹å¯å‚è€ƒæ¨¡å‹è½¬æ¢ç¤ºä¾‹åŒ…**ï¼ˆå³ï¼šhorizon_model_convert_sampleï¼‰**æ‰‹å†Œï¼š

[æ¨¡å‹è½¬æ¢ç¤ºä¾‹åŒ…æ‰‹å†Œ - horizon_model_convert_sample_documentation v1.12.3 æ–‡æ¡£](https://developer.horizon.ai/api/v1/fileData/doc/ddk_doc/navigation/ai_toolchain/docs_cn/hb_mapper_sample_doc/index.html)

å®˜æ–¹æä¾›çš„YOLOv3æ¨¡å‹éƒ¨ç½²ç¤ºä¾‹ä½äºOEå‘å¸ƒåŒ… `ddk/samples/ai_toolchain/horizon_model_convert_sample/04_detection/02_yolov3_darknet53/mapper` ä¸­ã€‚å…¶ä¸­åŒ…æ‹¬ä½¿ç”¨æ•°å­—ç¼–å·çš„è„šæœ¬ï¼š

```bash
â”œâ”€â”€ 01_check.sh
â”œâ”€â”€ 02_preprocess.sh
â”œâ”€â”€ 03_build.sh
â”œâ”€â”€ 04_inference.sh
â”œâ”€â”€ 05_evaluate.sh
```

å…¶ä¸­01~04å®é™…ä¸Šæ­£å¯¹åº”æ¨¡å‹éƒ¨ç½²çš„å®Œæ•´æµç¨‹ï¼ŒåŒ…æ‹¬ï¼š

1. æ¨¡å‹æ£€æŸ¥
2. æ ¡å‡†æ•°æ®é¢„å¤„ç†
3. æ„å»ºBPUç”¨å¼‚æ„æ¨¡å‹ï¼ˆæ¨¡å‹è½¬åŒ–ï¼‰
4. ä½¿ç”¨è½¬åŒ–åçš„æ¨¡å‹è¿›è¡Œæ¨ç†æµ‹è¯•

åœ¨å¼€å‘æœºOEé•œåƒå†…éƒ¨ï¼Œä¾æ¬¡è¿è¡Œä¸Šè¿°è„šæœ¬ï¼Œç†è®ºä¸Šå³å¯ç”Ÿæˆæ¨¡å‹ï¼Œå…¶ä¸­æœ€ä¸»è¦çš„æ˜¯åç¼€ä¸ºbinçš„æ¨¡å‹æ–‡ä»¶ã€‚æ€»ä½“æ¥è¯´ï¼Œä¸ºäº†è¿è¡Œè¯¥æ¨¡å‹å¹¶å®ç°ç›¸å…³åŠŸèƒ½ï¼Œéƒ¨ç½²æ‰€éœ€æ–‡ä»¶å¦‚ä¸‹ï¼š

- Pythonåº“æ–‡ä»¶å¤¹
- Pythonç¨‹åºæ–‡ä»¶
- æ¨¡å‹binæ–‡ä»¶
- coco_metric.py
- coco_classes.names

å…¶ä¸­ï¼Œé»„è‰²æ–‡ä»¶æ˜¯å‚ç…§ä¸Šè¿°æµç¨‹ç”Ÿæˆçš„ï¼Œç»¿è‰²æ–‡ä»¶æ˜¯å·²æœ‰çš„ã€‚é»‘è‰²æ–‡ä»¶éœ€è¦ç”¨æˆ·è‡ªè¡Œç¼–å†™ã€‚ä¸Šè¿°æ–‡ä»¶ç½®äºåŒä¸€æ–‡ä»¶å¤¹å†…ï¼Œå¯æ‹·è´è‡³å¼€å‘æ¿ç³»ç»Ÿä»»æ„ä½ç½®ã€‚åœ¨å¼€å‘æ¿ä¸Šè¿è¡Œæ—¶ï¼Œéœ€è¦ä½¿ç”¨ `sudo` ã€‚

<aside>
âš ï¸ ä¸€äº›å¯èƒ½éœ€è¦çš„ä¾èµ–é¡¹ï¼š
sudo pip3 install EasyDict pycocotools

</aside>

### æ¨¡å‹æ£€æŸ¥

```bash
#!/usr/bin/env sh

set -e -v
cd $(dirname $0) || exit

model_type="caffe"
proto="../../../01_common/model_zoo/mapper/detection/yolov3_darknet53/yolov3_transposed.prototxt"
caffe_model="../../../01_common/model_zoo/mapper/detection/yolov3_darknet53/yolov3.caffemodel"
march="bernoulli2"

hb_mapper checker --model-type ${model_type} \
                  --proto ${proto} --model ${caffe_model} \
                  --march ${march}
```

### æ ¡å‡†æ•°æ®é¢„å¤„ç†

```bash
#!/usr/bin/env bash

set -e -v
cd $(dirname $0) || exit

python3 ../../../data_preprocess.py \
  --src_dir ../../../01_common/calibration_data/coco \
  --dst_dir ./calibration_data_rgb_f32 \
  --pic_ext .rgb \
  --read_mode opencv
```

### æ„å»ºå¼‚æ„æ¨¡å‹

```bash
#!/bin/bash

set -e -v
cd $(dirname $0)

config_file="./yolov3_darknet53_config.yaml"
model_type="caffe"
# build model
hb_mapper makertbin --config ${config_file} --model-type ${model_type}
```

<aside>
ğŸ’¡ ä¸Šè¿°è„šæœ¬ä½¿ç”¨Â `hb_mapper` å·¥å…·è½¬æ¢æ¨¡å‹ï¼Œæœ€éœ€è¦å…³æ³¨çš„æ˜¯è½¬æ¢çš„é…ç½®æ–‡ä»¶ï¼Œ è¯·å‚è€ƒæ–‡æ¡£åŒ…Â [Horizon AI Toolchain User Guide](https://developer.horizon.ai/api/v1/fileData/doc/ddk_doc/navigation/ai_toolchain/docs_cn/horizon_ai_toolchain_user_guide/model_conversion.html#hb-mapper-makertbin)Â æ–‡æ¡£ä¸­ã€Šä½¿ç”¨ hb_mapper makertbin å·¥å…·è½¬æ¢æ¨¡å‹ã€‹å†…å®¹ã€‚

</aside>

### æ¨ç†æµ‹è¯•

```bash
#!/bin/bash

set -e -v
cd $(dirname $0)

#for converted quanti model inference
quanti_model_file="./model_output/yolov3_darknet53_416x416_nv12_quantized_model.onnx"
quanti_input_layout="NHWC"

#for original float model inference
original_model_file="./model_output/yolov3_darknet53_416x416_nv12_original_float_model.onnx"
original_input_layout="NCHW"

if [[ $1 =~ "origin" ]];  then
  model=$original_model_file
  layout=$original_input_layout
  input_offset=128
else
  model=$quanti_model_file
  layout=$quanti_input_layout
  input_offset=128  
fi

infer_image="../../../01_common/test_data/det_images/kite.jpg"

# -----------------------------------------------------------------------------------------------------
# shell command "sh 04_inference.sh" runs quanti inference by default 
# If quanti model infer is intended, please run the shell via command "sh 04_inference.sh quanti"
# If float model infer is intended, please run the shell via command "sh 04_inference.sh origin"
# -----------------------------------------------------------------------------------------------------

python3 -u ../../det_inference.py \
        --model ${model} \
        --image ${infer_image} \
        --input_layout ${layout} \
        --input_offset ${input_offset}
```

# è‡ªå®šä¹‰æ¨¡å‹éƒ¨ç½²

X3å¼€å‘æ¿çš„çœŸæ­£ä»·å€¼æ˜¯éƒ¨ç½²å¹¶è¿è¡Œæˆ‘ä»¬è‡ªå·±å¼€å‘çš„AIæ¨¡å‹ã€‚ä»¥ä¸‹è¯´æ˜å¦‚ä½•éƒ¨ç½²è‡ªå®šä¹‰æ¨¡å‹ã€‚æ¨¡å‹ç»“æ„é‡‡ç”¨yolov5ï¼Œéƒ¨ç½²çš„å…³é”®æ˜¯å°†yolov5æ¨¡å‹ç”±PyTorchçš„ptæ ¼å¼è½¬æ¢ä¸ºONNXæ ¼å¼åï¼Œå†è½¬æ¢ä¸ºX3æ”¯æŒçš„æ ¼å¼ã€‚

[](https://developer.horizon.ai/forumDetail/112555549341653639)

## è·å–YOLOv5

```bash
git clone https://github.com/ultralytics/yolov5
```

### YOLOv5å¿«é€Ÿè¿è¡ŒéªŒè¯

å¯é€šè¿‡ä»¥ä¸‹ç¤ºä¾‹æ£€æŸ¥yolov5æ˜¯å¦æ­£å¸¸å·¥ä½œï¼Œå„ä¾èµ–é¡¹æ˜¯å¦æˆåŠŸå®‰è£…ï¼š

```bash
python detect.py --weights ./models/yolov5s.pt --source 0
```

## æ ¹æ®å®˜æ–¹æŒ‡å¼•é…ç½®æ¨¡å‹è½¬æ¢è¿‡ç¨‹

åœ°å¹³çº¿å®˜æ–¹ç¤ºä¾‹ä¸­ä½¿ç”¨çš„yolov5ä¸ºè¯¥è½¯ä»¶ä»“åº“ä¸­ `tag` ä¸º `v2.0` çš„ç‰ˆæœ¬ï¼š

[2. ç®—æ³•æ¨¡å‹ç¤ºä¾‹ - horizon_model_convert_sample_documentation v1.12.3 æ–‡æ¡£](https://developer.horizon.ai/api/v1/fileData/doc/ddk_doc/navigation/ai_toolchain/docs_cn/hb_mapper_sample_doc/samples/algorithm_sample.html#yolov5s)

**ATTENTION:å¯¹äºyolov3æ¨¡å‹ï¼Œä½¿ç”¨ä¸‹é¢çš„æ›´æ”¹æ–¹æ³•ï¼Œä¼šç”±äºç»´åº¦ä¸åŒ¹é…æŠ¥é”™ã€‚**

```bash
Traceback (most recent call last):
  File "train.py", line 635, in <module>
    main(opt)
  File "train.py", line 528, in main
    train(opt.hyp, opt, device, callbacks)
  File "train.py", line 310, in train
    loss, loss_items = compute_loss(pred, targets.to(device))  # loss scaled by batch_size
  File "/home/clover/yolov3/utils/loss.py", line 135, in __call__
    pxy, pwh, _, pcls = pi[b, a, gj, gi].split((2, 2, 1, self.nc), 1)  # target-subset of predictions
  File "/home/clover/.yolov3/lib/python3.8/site-packages/torch/_tensor.py", line 611, in split
    return super(Tensor, self).split_with_sizes(split_size, dim)
IndexError: Dimension out of range (expected to be in range of [-1, 0], but got 1)
```

åœ°å¹³çº¿é’ˆå¯¹è¯¥ç‰ˆæœ¬ï¼Œåœ¨ONNXæ¨¡å‹å¯¼å‡ºå‰å¯¹Githubä»£ç åšäº†å¦‚ä¸‹ä¿®æ”¹ ï¼ˆä»£ç å‚è§ï¼š[https://github.com/ultralytics/yolov5/blob/v2.0/models/yolo.py](https://github.com/ultralytics/yolov5/blob/v2.0/models/yolo.py)ï¼‰ï¼š

```bash
def forward(self, x):
    # x = x.copy()  # for profiling
    z = []  # inference output
    self.training |= self.export
    for i in range(self.nl):
        x[i] = self.m[i](x[i])  # conv
        bs, _, ny, nx = x[i].shape  # x(bs,255,20,20) to x(bs,3,20,20,85)
        # x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()
        x[i] = x[i].permute(0, 2, 3, 1).contiguous()
```

å³å°†åŸæœ¬çš„5ç»´è¾“å‡ºæ”¹ä¸º4ç»´ï¼Œä¸æ‹†åˆ† `anchor size (3)` å’Œ `info size (85)` ï¼Œè€Œæ˜¯å°†ä¸¤è€…åˆå¹¶ï¼Œè§†ä¸ºé€šé“ `C (255)` å¹¶åç½®ã€‚è¿™æ ·åšçš„åŸå› æ˜¯ï¼Œ[BPUçš„è¾“å‡ºåªèƒ½æ˜¯4ç»´çš„æ•°æ®](https://developer.horizon.ai/forumDetail/106482341031036103)ã€‚

è¯¥ç‰ˆæœ¬ `forward` ä»£ç ä¸­æœ¬æ¥è¿˜æœ‰ä»¥ä¸‹æ ‡é»„å†…å®¹ï¼Œç»è¿‡è°ƒè¯•å‘ç°ï¼Œè¯¥ç‰ˆæœ¬åœ¨ `export` è„šæœ¬è¿è¡Œæ—¶ `self.training` å˜é‡ä¸º `True` ï¼Œå› æ­¤æ ‡é»„éƒ¨åˆ†æ ¹æœ¬ä¸ä¼šè¿è¡Œï¼Œ `x` å°±æ˜¯æ¨¡å‹çš„æœ€ç»ˆè¾“å‡ºï¼Œè¿™æ ·ä¹Ÿä¸éš¾ç†è§£ç›¸å¯¹åº”çš„åå¤„ç†ä»£ç å‡ºç°åœ¨åœ°å¹³çº¿å®˜æ–¹æä¾›çš„ä¾‹ç¨‹ä¸­ã€‚

```python
def forward(self, x):
    # x = x.copy()  # for profiling
    z = []  # inference output
    self.training |= self.export
    for i in range(self.nl):
        x[i] = self.m[i](x[i])  # conv
        bs, _, ny, nx = x[i].shape  # x(bs,255,20,20) to x(bs,3,20,20,85)
        # x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()
        x[i] = x[i].permute(0, 2, 3, 1).contiguous()

        if not self.training:  # inference
            if self.grid[i].shape[2:4] != x[i].shape[2:4]:
                self.grid[i] = self._make_grid(nx, ny).to(x[i].device)

            y = x[i].sigmoid()
            y[..., 0:2] = (y[..., 0:2] * 2. - 0.5 + self.grid[i].to(x[i].device)) * self.stride[i]  # xy
            y[..., 2:4] = (y[..., 2:4] * 2) ** 2 * self.anchor_grid[i]  # wh
            z.append(y.view(bs, -1, self.no))

    return x if self.training else (torch.cat(z, 1), x)
```

<aside>
ğŸš§ ä½¿ç”¨å®˜æ–¹æ¨èçš„v2.0ç‰ˆæœ¬è¿›è¡Œå¦‚ä¸Šæ“ä½œï¼Œä¼šç”±äºPyTorchç‰ˆæœ¬é—®é¢˜æŠ¥ä»¥ä¸‹é”™è¯¯ï¼š

[https://github.com/ultralytics/yolov5/issues/6948](https://github.com/ultralytics/yolov5/issues/6948)

å…·ä½“æŠ¥é”™ä¿¡æ¯å¦‚ä¸‹ï¼š

```bash
Traceback (most recent call last):
  File "models/export.py", line 29, in <module>
    y = model(img)  # dry run
  File "/home/dzp/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dzp/yolov5/models/yolo.py", line 99, in forward
    return self.forward_once(x, profile)  # single-scale inference, train
  File "/home/dzp/yolov5/models/yolo.py", line 119, in forward_once
    x = m(x)  # run
  File "/home/dzp/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/dzp/.local/lib/python3.8/site-packages/torch/nn/modules/upsampling.py", line 154, in forward
    recompute_scale_factor=self.recompute_scale_factor)
  File "/home/dzp/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1207, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'Upsample' object has no attribute 'recompute_scale_factor'
```

ä¸è¿‡ï¼Œè¯¥é—®é¢˜çš„ä¿®å¤æ–¹å¼ç›¸å¯¹ç®€å•ï¼ˆé’ˆå¯¹ torch 1.12.1ï¼‰ï¼Œæ–¹æ³•ä¸ºï¼Œå°† `torch/nn/modules/upsampling.py` 154è¡Œä»£ç æ›´æ”¹ä¸ºï¼š

```bash
def forward(self, input: Tensor) -> Tensor:
    # return F.interpolate(input, self.size, self.scale_factor, self.mode, self.align_corners,
    #                      recompute_scale_factor=self.recompute_scale_factor)
    return F.interpolate(input, self.size, self.scale_factor, self.mode, self.align_corners)
```

è¯¥æ”¹åŠ¨çš„æ½œåœ¨éšæ‚£ç›®å‰æœªçŸ¥ã€‚

</aside>

## PTè½¬ONNXï¼ˆv2.0ç‰ˆï¼‰

åœ¨è§£å†³ä¸Šè¿°é—®é¢˜åï¼ŒæŒ‰å®˜æ–¹æŒ‡å¼•ä¿®æ”¹ `export.py` æ–‡ä»¶ï¼Œè¿è¡Œç»“æœå¦‚ä¸‹ï¼š

- `export PYTHONPATH="$PWD" && python models/export.py` è¿è¡Œäº `yolov5` æ ¹ç›®å½•ä¸‹ï¼ˆæœªä¿®æ”¹yolo.pyï¼‰
    
    ```bash
    Namespace(batch_size=1, img_size=[672, 672], weights='./weights/yolov5s.pt')
    
    Starting TorchScript export with torch 1.12.1+cu116...
    /home/dzp/.local/lib/python3.8/site-packages/torch/jit/_trace.py:967: TracerWarning: Encountering a list at the output of the tracer might cause the trace to be incorrect, this is only valid if the container structure does not change based on the module's inputs. Consider using a constant container instead (e.g. for `list`, use a `tuple` instead. for `dict`, use a `NamedTuple` instead). If you absolutely need this and know the side effects, pass strict=False to trace() to allow this behavior.
      module._c._create_method_from_trace(
    TorchScript export success, saved as ./weights/yolov5s.torchscript.pt
    
    Starting ONNX export with onnx 1.12.0...
    Fusing layers... Model Summary: 140 layers, 7.45958e+06 parameters, 6.61683e+06 gradients, 17.4 GFLOPS
    /home/dzp/yolov5/models/yolo.py:83: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
      if augment:
    /home/dzp/yolov5/models/yolo.py:107: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
      if profile:
    /home/dzp/yolov5/models/yolo.py:122: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
      if profile:
    graph torch_jit (
      %data[FLOAT, 1x3x672x672]
    ) initializers (
      %model.0.conv.conv.weight[FLOAT, 32x12x3x3]
      %model.0.conv.conv.bias[FLOAT, 32]
      %model.1.conv.weight[FLOAT, 64x32x3x3]
      %model.1.conv.bias[FLOAT, 64]
      %model.2.cv1.conv.weight[FLOAT, 32x64x1x1]
      %model.2.cv1.conv.bias[FLOAT, 32]
      %model.2.cv2.weight[FLOAT, 32x64x1x1]
      %model.2.cv3.weight[FLOAT, 32x32x1x1]
      %model.2.cv4.conv.weight[FLOAT, 64x64x1x1]
      %model.2.cv4.conv.bias[FLOAT, 64]
      %model.2.bn.weight[FLOAT, 64]
      %model.2.bn.bias[FLOAT, 64]
      %model.2.bn.running_mean[FLOAT, 64]
      %model.2.bn.running_var[FLOAT, 64]
      %model.2.m.0.cv1.conv.weight[FLOAT, 32x32x1x1]
      %model.2.m.0.cv1.conv.bias[FLOAT, 32]
      %model.2.m.0.cv2.conv.weight[FLOAT, 32x32x3x3]
      %model.2.m.0.cv2.conv.bias[FLOAT, 32]
      %model.3.conv.weight[FLOAT, 128x64x3x3]
      %model.3.conv.bias[FLOAT, 128]
      %model.4.cv1.conv.weight[FLOAT, 64x128x1x1]
      %model.4.cv1.conv.bias[FLOAT, 64]
      %model.4.cv2.weight[FLOAT, 64x128x1x1]
      %model.4.cv3.weight[FLOAT, 64x64x1x1]
      %model.4.cv4.conv.weight[FLOAT, 128x128x1x1]
      %model.4.cv4.conv.bias[FLOAT, 128]
      %model.4.bn.weight[FLOAT, 128]
      %model.4.bn.bias[FLOAT, 128]
      %model.4.bn.running_mean[FLOAT, 128]
      %model.4.bn.running_var[FLOAT, 128]
      %model.4.m.0.cv1.conv.weight[FLOAT, 64x64x1x1]
      %model.4.m.0.cv1.conv.bias[FLOAT, 64]
      %model.4.m.0.cv2.conv.weight[FLOAT, 64x64x3x3]
      %model.4.m.0.cv2.conv.bias[FLOAT, 64]
      %model.4.m.1.cv1.conv.weight[FLOAT, 64x64x1x1]
      %model.4.m.1.cv1.conv.bias[FLOAT, 64]
      %model.4.m.1.cv2.conv.weight[FLOAT, 64x64x3x3]
      %model.4.m.1.cv2.conv.bias[FLOAT, 64]
      %model.4.m.2.cv1.conv.weight[FLOAT, 64x64x1x1]
      %model.4.m.2.cv1.conv.bias[FLOAT, 64]
      %model.4.m.2.cv2.conv.weight[FLOAT, 64x64x3x3]
      %model.4.m.2.cv2.conv.bias[FLOAT, 64]
      %model.5.conv.weight[FLOAT, 256x128x3x3]
      %model.5.conv.bias[FLOAT, 256]
      %model.6.cv1.conv.weight[FLOAT, 128x256x1x1]
      %model.6.cv1.conv.bias[FLOAT, 128]
      %model.6.cv2.weight[FLOAT, 128x256x1x1]
      %model.6.cv3.weight[FLOAT, 128x128x1x1]
      %model.6.cv4.conv.weight[FLOAT, 256x256x1x1]
      %model.6.cv4.conv.bias[FLOAT, 256]
      %model.6.bn.weight[FLOAT, 256]
      %model.6.bn.bias[FLOAT, 256]
      %model.6.bn.running_mean[FLOAT, 256]
      %model.6.bn.running_var[FLOAT, 256]
      %model.6.m.0.cv1.conv.weight[FLOAT, 128x128x1x1]
      %model.6.m.0.cv1.conv.bias[FLOAT, 128]
      %model.6.m.0.cv2.conv.weight[FLOAT, 128x128x3x3]
      %model.6.m.0.cv2.conv.bias[FLOAT, 128]
      %model.6.m.1.cv1.conv.weight[FLOAT, 128x128x1x1]
      %model.6.m.1.cv1.conv.bias[FLOAT, 128]
      %model.6.m.1.cv2.conv.weight[FLOAT, 128x128x3x3]
      %model.6.m.1.cv2.conv.bias[FLOAT, 128]
      %model.6.m.2.cv1.conv.weight[FLOAT, 128x128x1x1]
      %model.6.m.2.cv1.conv.bias[FLOAT, 128]
      %model.6.m.2.cv2.conv.weight[FLOAT, 128x128x3x3]
      %model.6.m.2.cv2.conv.bias[FLOAT, 128]
      %model.7.conv.weight[FLOAT, 512x256x3x3]
      %model.7.conv.bias[FLOAT, 512]
      %model.8.cv1.conv.weight[FLOAT, 256x512x1x1]
      %model.8.cv1.conv.bias[FLOAT, 256]
      %model.8.cv2.conv.weight[FLOAT, 512x1024x1x1]
      %model.8.cv2.conv.bias[FLOAT, 512]
      %model.9.cv1.conv.weight[FLOAT, 256x512x1x1]
      %model.9.cv1.conv.bias[FLOAT, 256]
      %model.9.cv2.weight[FLOAT, 256x512x1x1]
      %model.9.cv3.weight[FLOAT, 256x256x1x1]
      %model.9.cv4.conv.weight[FLOAT, 512x512x1x1]
      %model.9.cv4.conv.bias[FLOAT, 512]
      %model.9.bn.weight[FLOAT, 512]
      %model.9.bn.bias[FLOAT, 512]
      %model.9.bn.running_mean[FLOAT, 512]
      %model.9.bn.running_var[FLOAT, 512]
      %model.9.m.0.cv1.conv.weight[FLOAT, 256x256x1x1]
      %model.9.m.0.cv1.conv.bias[FLOAT, 256]
      %model.9.m.0.cv2.conv.weight[FLOAT, 256x256x3x3]
      %model.9.m.0.cv2.conv.bias[FLOAT, 256]
      %model.10.conv.weight[FLOAT, 256x512x1x1]
      %model.10.conv.bias[FLOAT, 256]
      %model.13.cv1.conv.weight[FLOAT, 128x512x1x1]
      %model.13.cv1.conv.bias[FLOAT, 128]
      %model.13.cv2.weight[FLOAT, 128x512x1x1]
      %model.13.cv3.weight[FLOAT, 128x128x1x1]
      %model.13.cv4.conv.weight[FLOAT, 256x256x1x1]
      %model.13.cv4.conv.bias[FLOAT, 256]
      %model.13.bn.weight[FLOAT, 256]
      %model.13.bn.bias[FLOAT, 256]
      %model.13.bn.running_mean[FLOAT, 256]
      %model.13.bn.running_var[FLOAT, 256]
      %model.13.m.0.cv1.conv.weight[FLOAT, 128x128x1x1]
      %model.13.m.0.cv1.conv.bias[FLOAT, 128]
      %model.13.m.0.cv2.conv.weight[FLOAT, 128x128x3x3]
      %model.13.m.0.cv2.conv.bias[FLOAT, 128]
      %model.14.conv.weight[FLOAT, 128x256x1x1]
      %model.14.conv.bias[FLOAT, 128]
      %model.17.cv1.conv.weight[FLOAT, 64x256x1x1]
      %model.17.cv1.conv.bias[FLOAT, 64]
      %model.17.cv2.weight[FLOAT, 64x256x1x1]
      %model.17.cv3.weight[FLOAT, 64x64x1x1]
      %model.17.cv4.conv.weight[FLOAT, 128x128x1x1]
      %model.17.cv4.conv.bias[FLOAT, 128]
      %model.17.bn.weight[FLOAT, 128]
      %model.17.bn.bias[FLOAT, 128]
      %model.17.bn.running_mean[FLOAT, 128]
      %model.17.bn.running_var[FLOAT, 128]
      %model.17.m.0.cv1.conv.weight[FLOAT, 64x64x1x1]
      %model.17.m.0.cv1.conv.bias[FLOAT, 64]
      %model.17.m.0.cv2.conv.weight[FLOAT, 64x64x3x3]
      %model.17.m.0.cv2.conv.bias[FLOAT, 64]
      %model.18.conv.weight[FLOAT, 128x128x3x3]
      %model.18.conv.bias[FLOAT, 128]
      %model.20.cv1.conv.weight[FLOAT, 128x256x1x1]
      %model.20.cv1.conv.bias[FLOAT, 128]
      %model.20.cv2.weight[FLOAT, 128x256x1x1]
      %model.20.cv3.weight[FLOAT, 128x128x1x1]
      %model.20.cv4.conv.weight[FLOAT, 256x256x1x1]
      %model.20.cv4.conv.bias[FLOAT, 256]
      %model.20.bn.weight[FLOAT, 256]
      %model.20.bn.bias[FLOAT, 256]
      %model.20.bn.running_mean[FLOAT, 256]
      %model.20.bn.running_var[FLOAT, 256]
      %model.20.m.0.cv1.conv.weight[FLOAT, 128x128x1x1]
      %model.20.m.0.cv1.conv.bias[FLOAT, 128]
      %model.20.m.0.cv2.conv.weight[FLOAT, 128x128x3x3]
      %model.20.m.0.cv2.conv.bias[FLOAT, 128]
      %model.21.conv.weight[FLOAT, 256x256x3x3]
      %model.21.conv.bias[FLOAT, 256]
      %model.23.cv1.conv.weight[FLOAT, 256x512x1x1]
      %model.23.cv1.conv.bias[FLOAT, 256]
      %model.23.cv2.weight[FLOAT, 256x512x1x1]
      %model.23.cv3.weight[FLOAT, 256x256x1x1]
      %model.23.cv4.conv.weight[FLOAT, 512x512x1x1]
      %model.23.cv4.conv.bias[FLOAT, 512]
      %model.23.bn.weight[FLOAT, 512]
      %model.23.bn.bias[FLOAT, 512]
      %model.23.bn.running_mean[FLOAT, 512]
      %model.23.bn.running_var[FLOAT, 512]
      %model.23.m.0.cv1.conv.weight[FLOAT, 256x256x1x1]
      %model.23.m.0.cv1.conv.bias[FLOAT, 256]
      %model.23.m.0.cv2.conv.weight[FLOAT, 256x256x3x3]
      %model.23.m.0.cv2.conv.bias[FLOAT, 256]
      %model.24.m.0.weight[FLOAT, 255x128x1x1]
      %model.24.m.0.bias[FLOAT, 255]
      %model.24.m.1.weight[FLOAT, 255x256x1x1]
      %model.24.m.1.bias[FLOAT, 255]
      %model.24.m.2.weight[FLOAT, 255x512x1x1]
      %model.24.m.2.bias[FLOAT, 255]
      %onnx::Resize_419[FLOAT, 4]
      %onnx::Reshape_426[INT64, 5]
      %onnx::Reshape_432[INT64, 5]
      %onnx::Reshape_438[INT64, 5]
    ) {
      %onnx::Resize_420 = Identity(%onnx::Resize_419)
      %onnx::Slice_169 = Constant[value = <Tensor>]()
      %onnx::Slice_170 = Constant[value = <Tensor>]()
      %onnx::Slice_171 = Constant[value = <Tensor>]()
      %onnx::Slice_172 = Constant[value = <Tensor>]()
      %onnx::Slice_173 = Slice(%data, %onnx::Slice_170, %onnx::Slice_171, %onnx::Slice_169, %onnx::Slice_172)
      %onnx::Slice_174 = Constant[value = <Tensor>]()
      %onnx::Slice_175 = Constant[value = <Tensor>]()
      %onnx::Slice_176 = Constant[value = <Tensor>]()
      %onnx::Slice_177 = Constant[value = <Tensor>]()
      %onnx::Concat_178 = Slice(%onnx::Slice_173, %onnx::Slice_175, %onnx::Slice_176, %onnx::Slice_174, %onnx::Slice_177)
      %onnx::Slice_179 = Constant[value = <Tensor>]()
      %onnx::Slice_180 = Constant[value = <Tensor>]()
      %onnx::Slice_181 = Constant[value = <Tensor>]()
      %onnx::Slice_182 = Constant[value = <Tensor>]()
      %onnx::Slice_183 = Slice(%data, %onnx::Slice_180, %onnx::Slice_181, %onnx::Slice_179, %onnx::Slice_182)
      %onnx::Slice_184 = Constant[value = <Tensor>]()
      %onnx::Slice_185 = Constant[value = <Tensor>]()
      %onnx::Slice_186 = Constant[value = <Tensor>]()
      %onnx::Slice_187 = Constant[value = <Tensor>]()
      %onnx::Concat_188 = Slice(%onnx::Slice_183, %onnx::Slice_185, %onnx::Slice_186, %onnx::Slice_184, %onnx::Slice_187)
      %onnx::Slice_189 = Constant[value = <Tensor>]()
      %onnx::Slice_190 = Constant[value = <Tensor>]()
      %onnx::Slice_191 = Constant[value = <Tensor>]()
      %onnx::Slice_192 = Constant[value = <Tensor>]()
      %onnx::Slice_193 = Slice(%data, %onnx::Slice_190, %onnx::Slice_191, %onnx::Slice_189, %onnx::Slice_192)
      %onnx::Slice_194 = Constant[value = <Tensor>]()
      %onnx::Slice_195 = Constant[value = <Tensor>]()
      %onnx::Slice_196 = Constant[value = <Tensor>]()
      %onnx::Slice_197 = Constant[value = <Tensor>]()
      %onnx::Concat_198 = Slice(%onnx::Slice_193, %onnx::Slice_195, %onnx::Slice_196, %onnx::Slice_194, %onnx::Slice_197)
      %onnx::Slice_199 = Constant[value = <Tensor>]()
      %onnx::Slice_200 = Constant[value = <Tensor>]()
      %onnx::Slice_201 = Constant[value = <Tensor>]()
      %onnx::Slice_202 = Constant[value = <Tensor>]()
      %onnx::Slice_203 = Slice(%data, %onnx::Slice_200, %onnx::Slice_201, %onnx::Slice_199, %onnx::Slice_202)
      %onnx::Slice_204 = Constant[value = <Tensor>]()
      %onnx::Slice_205 = Constant[value = <Tensor>]()
      %onnx::Slice_206 = Constant[value = <Tensor>]()
      %onnx::Slice_207 = Constant[value = <Tensor>]()
      %onnx::Concat_208 = Slice(%onnx::Slice_203, %onnx::Slice_205, %onnx::Slice_206, %onnx::Slice_204, %onnx::Slice_207)
      %input = Concat[axis = 1](%onnx::Concat_178, %onnx::Concat_188, %onnx::Concat_198, %onnx::Concat_208)
      %input.3 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input, %model.0.conv.conv.weight, %model.0.conv.conv.bias)
      %onnx::Conv_211 = LeakyRelu[alpha = 0.100000001490116](%input.3)
      %input.7 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%onnx::Conv_211, %model.1.conv.weight, %model.1.conv.bias)
      %onnx::Conv_213 = LeakyRelu[alpha = 0.100000001490116](%input.7)
      %input.11 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_213, %model.2.cv1.conv.weight, %model.2.cv1.conv.bias)
      %onnx::Conv_215 = LeakyRelu[alpha = 0.100000001490116](%input.11)
      %input.15 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_215, %model.2.m.0.cv1.conv.weight, %model.2.m.0.cv1.conv.bias)
      %onnx::Conv_217 = LeakyRelu[alpha = 0.100000001490116](%input.15)
      %input.19 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%onnx::Conv_217, %model.2.m.0.cv2.conv.weight, %model.2.m.0.cv2.conv.bias)
      %onnx::Add_219 = LeakyRelu[alpha = 0.100000001490116](%input.19)
      %input.23 = Add(%onnx::Conv_215, %onnx::Add_219)
      %onnx::Concat_221 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.23, %model.2.cv3.weight)
      %onnx::Concat_222 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_213, %model.2.cv2.weight)
      %input.27 = Concat[axis = 1](%onnx::Concat_221, %onnx::Concat_222)
      %input.31 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.990000009536743](%input.27, %model.2.bn.weight, %model.2.bn.bias, %model.2.bn.running_mean, %model.2.bn.running_var)
      %onnx::Conv_225 = LeakyRelu[alpha = 0.100000001490116](%input.31)
      %input.35 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_225, %model.2.cv4.conv.weight, %model.2.cv4.conv.bias)
      %onnx::Conv_227 = LeakyRelu[alpha = 0.100000001490116](%input.35)
      %input.39 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%onnx::Conv_227, %model.3.conv.weight, %model.3.conv.bias)
      %onnx::Conv_229 = LeakyRelu[alpha = 0.100000001490116](%input.39)
      %input.43 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_229, %model.4.cv1.conv.weight, %model.4.cv1.conv.bias)
      %onnx::Conv_231 = LeakyRelu[alpha = 0.100000001490116](%input.43)
      %input.47 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_231, %model.4.m.0.cv1.conv.weight, %model.4.m.0.cv1.conv.bias)
      %onnx::Conv_233 = LeakyRelu[alpha = 0.100000001490116](%input.47)
      %input.51 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%onnx::Conv_233, %model.4.m.0.cv2.conv.weight, %model.4.m.0.cv2.conv.bias)
      %onnx::Add_235 = LeakyRelu[alpha = 0.100000001490116](%input.51)
      %input.55 = Add(%onnx::Conv_231, %onnx::Add_235)
      %input.59 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.55, %model.4.m.1.cv1.conv.weight, %model.4.m.1.cv1.conv.bias)
      %onnx::Conv_238 = LeakyRelu[alpha = 0.100000001490116](%input.59)
      %input.63 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%onnx::Conv_238, %model.4.m.1.cv2.conv.weight, %model.4.m.1.cv2.conv.bias)
      %onnx::Add_240 = LeakyRelu[alpha = 0.100000001490116](%input.63)
      %input.67 = Add(%input.55, %onnx::Add_240)
      %input.71 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.67, %model.4.m.2.cv1.conv.weight, %model.4.m.2.cv1.conv.bias)
      %onnx::Conv_243 = LeakyRelu[alpha = 0.100000001490116](%input.71)
      %input.75 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%onnx::Conv_243, %model.4.m.2.cv2.conv.weight, %model.4.m.2.cv2.conv.bias)
      %onnx::Add_245 = LeakyRelu[alpha = 0.100000001490116](%input.75)
      %input.79 = Add(%input.67, %onnx::Add_245)
      %onnx::Concat_247 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.79, %model.4.cv3.weight)
      %onnx::Concat_248 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_229, %model.4.cv2.weight)
      %input.83 = Concat[axis = 1](%onnx::Concat_247, %onnx::Concat_248)
      %input.87 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.990000009536743](%input.83, %model.4.bn.weight, %model.4.bn.bias, %model.4.bn.running_mean, %model.4.bn.running_var)
      %onnx::Conv_251 = LeakyRelu[alpha = 0.100000001490116](%input.87)
      %input.91 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_251, %model.4.cv4.conv.weight, %model.4.cv4.conv.bias)
      %onnx::Conv_253 = LeakyRelu[alpha = 0.100000001490116](%input.91)
      %input.95 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%onnx::Conv_253, %model.5.conv.weight, %model.5.conv.bias)
      %onnx::Conv_255 = LeakyRelu[alpha = 0.100000001490116](%input.95)
      %input.99 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_255, %model.6.cv1.conv.weight, %model.6.cv1.conv.bias)
      %onnx::Conv_257 = LeakyRelu[alpha = 0.100000001490116](%input.99)
      %input.103 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_257, %model.6.m.0.cv1.conv.weight, %model.6.m.0.cv1.conv.bias)
      %onnx::Conv_259 = LeakyRelu[alpha = 0.100000001490116](%input.103)
      %input.107 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%onnx::Conv_259, %model.6.m.0.cv2.conv.weight, %model.6.m.0.cv2.conv.bias)
      %onnx::Add_261 = LeakyRelu[alpha = 0.100000001490116](%input.107)
      %input.111 = Add(%onnx::Conv_257, %onnx::Add_261)
      %input.115 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.111, %model.6.m.1.cv1.conv.weight, %model.6.m.1.cv1.conv.bias)
      %onnx::Conv_264 = LeakyRelu[alpha = 0.100000001490116](%input.115)
      %input.119 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%onnx::Conv_264, %model.6.m.1.cv2.conv.weight, %model.6.m.1.cv2.conv.bias)
      %onnx::Add_266 = LeakyRelu[alpha = 0.100000001490116](%input.119)
      %input.123 = Add(%input.111, %onnx::Add_266)
      %input.127 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.123, %model.6.m.2.cv1.conv.weight, %model.6.m.2.cv1.conv.bias)
      %onnx::Conv_269 = LeakyRelu[alpha = 0.100000001490116](%input.127)
      %input.131 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%onnx::Conv_269, %model.6.m.2.cv2.conv.weight, %model.6.m.2.cv2.conv.bias)
      %onnx::Add_271 = LeakyRelu[alpha = 0.100000001490116](%input.131)
      %input.135 = Add(%input.123, %onnx::Add_271)
      %onnx::Concat_273 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.135, %model.6.cv3.weight)
      %onnx::Concat_274 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_255, %model.6.cv2.weight)
      %input.139 = Concat[axis = 1](%onnx::Concat_273, %onnx::Concat_274)
      %input.143 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.990000009536743](%input.139, %model.6.bn.weight, %model.6.bn.bias, %model.6.bn.running_mean, %model.6.bn.running_var)
      %onnx::Conv_277 = LeakyRelu[alpha = 0.100000001490116](%input.143)
      %input.147 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_277, %model.6.cv4.conv.weight, %model.6.cv4.conv.bias)
      %onnx::Conv_279 = LeakyRelu[alpha = 0.100000001490116](%input.147)
      %input.151 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%onnx::Conv_279, %model.7.conv.weight, %model.7.conv.bias)
      %onnx::Conv_281 = LeakyRelu[alpha = 0.100000001490116](%input.151)
      %input.155 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_281, %model.8.cv1.conv.weight, %model.8.cv1.conv.bias)
      %onnx::MaxPool_283 = LeakyRelu[alpha = 0.100000001490116](%input.155)
      %onnx::Concat_284 = MaxPool[ceil_mode = 0, kernel_shape = [5, 5], pads = [2, 2, 2, 2], strides = [1, 1]](%onnx::MaxPool_283)
      %onnx::Concat_285 = MaxPool[ceil_mode = 0, kernel_shape = [9, 9], pads = [4, 4, 4, 4], strides = [1, 1]](%onnx::MaxPool_283)
      %onnx::Concat_286 = MaxPool[ceil_mode = 0, kernel_shape = [13, 13], pads = [6, 6, 6, 6], strides = [1, 1]](%onnx::MaxPool_283)
      %input.159 = Concat[axis = 1](%onnx::MaxPool_283, %onnx::Concat_284, %onnx::Concat_285, %onnx::Concat_286)
      %input.163 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.159, %model.8.cv2.conv.weight, %model.8.cv2.conv.bias)
      %onnx::Conv_289 = LeakyRelu[alpha = 0.100000001490116](%input.163)
      %input.167 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_289, %model.9.cv1.conv.weight, %model.9.cv1.conv.bias)
      %onnx::Conv_291 = LeakyRelu[alpha = 0.100000001490116](%input.167)
      %input.171 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_291, %model.9.m.0.cv1.conv.weight, %model.9.m.0.cv1.conv.bias)
      %onnx::Conv_293 = LeakyRelu[alpha = 0.100000001490116](%input.171)
      %input.175 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%onnx::Conv_293, %model.9.m.0.cv2.conv.weight, %model.9.m.0.cv2.conv.bias)
      %onnx::Conv_295 = LeakyRelu[alpha = 0.100000001490116](%input.175)
      %onnx::Concat_296 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_295, %model.9.cv3.weight)
      %onnx::Concat_297 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_289, %model.9.cv2.weight)
      %input.179 = Concat[axis = 1](%onnx::Concat_296, %onnx::Concat_297)
      %input.183 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.990000009536743](%input.179, %model.9.bn.weight, %model.9.bn.bias, %model.9.bn.running_mean, %model.9.bn.running_var)
      %onnx::Conv_300 = LeakyRelu[alpha = 0.100000001490116](%input.183)
      %input.187 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_300, %model.9.cv4.conv.weight, %model.9.cv4.conv.bias)
      %onnx::Conv_302 = LeakyRelu[alpha = 0.100000001490116](%input.187)
      %input.191 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_302, %model.10.conv.weight, %model.10.conv.bias)
      %onnx::Resize_304 = LeakyRelu[alpha = 0.100000001490116](%input.191)
      %onnx::Resize_308 = Constant[value = <Tensor>]()
      %onnx::Concat_309 = Resize[coordinate_transformation_mode = 'asymmetric', cubic_coeff_a = -0.75, mode = 'nearest', nearest_mode = 'floor'](%onnx::Resize_304, %onnx::Resize_308, %onnx::Resize_419)
      %input.195 = Concat[axis = 1](%onnx::Concat_309, %onnx::Conv_279)
      %input.199 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.195, %model.13.cv1.conv.weight, %model.13.cv1.conv.bias)
      %onnx::Conv_312 = LeakyRelu[alpha = 0.100000001490116](%input.199)
      %input.203 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_312, %model.13.m.0.cv1.conv.weight, %model.13.m.0.cv1.conv.bias)
      %onnx::Conv_314 = LeakyRelu[alpha = 0.100000001490116](%input.203)
      %input.207 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%onnx::Conv_314, %model.13.m.0.cv2.conv.weight, %model.13.m.0.cv2.conv.bias)
      %onnx::Conv_316 = LeakyRelu[alpha = 0.100000001490116](%input.207)
      %onnx::Concat_317 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_316, %model.13.cv3.weight)
      %onnx::Concat_318 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.195, %model.13.cv2.weight)
      %input.211 = Concat[axis = 1](%onnx::Concat_317, %onnx::Concat_318)
      %input.215 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.990000009536743](%input.211, %model.13.bn.weight, %model.13.bn.bias, %model.13.bn.running_mean, %model.13.bn.running_var)
      %onnx::Conv_321 = LeakyRelu[alpha = 0.100000001490116](%input.215)
      %input.219 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_321, %model.13.cv4.conv.weight, %model.13.cv4.conv.bias)
      %onnx::Conv_323 = LeakyRelu[alpha = 0.100000001490116](%input.219)
      %input.223 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_323, %model.14.conv.weight, %model.14.conv.bias)
      %onnx::Resize_325 = LeakyRelu[alpha = 0.100000001490116](%input.223)
      %onnx::Resize_329 = Constant[value = <Tensor>]()
      %onnx::Concat_330 = Resize[coordinate_transformation_mode = 'asymmetric', cubic_coeff_a = -0.75, mode = 'nearest', nearest_mode = 'floor'](%onnx::Resize_325, %onnx::Resize_329, %onnx::Resize_420)
      %input.227 = Concat[axis = 1](%onnx::Concat_330, %onnx::Conv_253)
      %input.231 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.227, %model.17.cv1.conv.weight, %model.17.cv1.conv.bias)
      %onnx::Conv_333 = LeakyRelu[alpha = 0.100000001490116](%input.231)
      %input.235 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_333, %model.17.m.0.cv1.conv.weight, %model.17.m.0.cv1.conv.bias)
      %onnx::Conv_335 = LeakyRelu[alpha = 0.100000001490116](%input.235)
      %input.239 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%onnx::Conv_335, %model.17.m.0.cv2.conv.weight, %model.17.m.0.cv2.conv.bias)
      %onnx::Conv_337 = LeakyRelu[alpha = 0.100000001490116](%input.239)
      %onnx::Concat_338 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_337, %model.17.cv3.weight)
      %onnx::Concat_339 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.227, %model.17.cv2.weight)
      %input.243 = Concat[axis = 1](%onnx::Concat_338, %onnx::Concat_339)
      %input.247 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.990000009536743](%input.243, %model.17.bn.weight, %model.17.bn.bias, %model.17.bn.running_mean, %model.17.bn.running_var)
      %onnx::Conv_342 = LeakyRelu[alpha = 0.100000001490116](%input.247)
      %input.251 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_342, %model.17.cv4.conv.weight, %model.17.cv4.conv.bias)
      %onnx::Conv_344 = LeakyRelu[alpha = 0.100000001490116](%input.251)
      %input.255 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%onnx::Conv_344, %model.18.conv.weight, %model.18.conv.bias)
      %onnx::Concat_346 = LeakyRelu[alpha = 0.100000001490116](%input.255)
      %input.259 = Concat[axis = 1](%onnx::Concat_346, %onnx::Resize_325)
      %input.263 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.259, %model.20.cv1.conv.weight, %model.20.cv1.conv.bias)
      %onnx::Conv_349 = LeakyRelu[alpha = 0.100000001490116](%input.263)
      %input.267 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_349, %model.20.m.0.cv1.conv.weight, %model.20.m.0.cv1.conv.bias)
      %onnx::Conv_351 = LeakyRelu[alpha = 0.100000001490116](%input.267)
      %input.271 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%onnx::Conv_351, %model.20.m.0.cv2.conv.weight, %model.20.m.0.cv2.conv.bias)
      %onnx::Conv_353 = LeakyRelu[alpha = 0.100000001490116](%input.271)
      %onnx::Concat_354 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_353, %model.20.cv3.weight)
      %onnx::Concat_355 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.259, %model.20.cv2.weight)
      %input.275 = Concat[axis = 1](%onnx::Concat_354, %onnx::Concat_355)
      %input.279 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.990000009536743](%input.275, %model.20.bn.weight, %model.20.bn.bias, %model.20.bn.running_mean, %model.20.bn.running_var)
      %onnx::Conv_358 = LeakyRelu[alpha = 0.100000001490116](%input.279)
      %input.283 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_358, %model.20.cv4.conv.weight, %model.20.cv4.conv.bias)
      %onnx::Conv_360 = LeakyRelu[alpha = 0.100000001490116](%input.283)
      %input.287 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%onnx::Conv_360, %model.21.conv.weight, %model.21.conv.bias)
      %onnx::Concat_362 = LeakyRelu[alpha = 0.100000001490116](%input.287)
      %input.291 = Concat[axis = 1](%onnx::Concat_362, %onnx::Resize_304)
      %input.295 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.291, %model.23.cv1.conv.weight, %model.23.cv1.conv.bias)
      %onnx::Conv_365 = LeakyRelu[alpha = 0.100000001490116](%input.295)
      %input.299 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_365, %model.23.m.0.cv1.conv.weight, %model.23.m.0.cv1.conv.bias)
      %onnx::Conv_367 = LeakyRelu[alpha = 0.100000001490116](%input.299)
      %input.303 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%onnx::Conv_367, %model.23.m.0.cv2.conv.weight, %model.23.m.0.cv2.conv.bias)
      %onnx::Conv_369 = LeakyRelu[alpha = 0.100000001490116](%input.303)
      %onnx::Concat_370 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_369, %model.23.cv3.weight)
      %onnx::Concat_371 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.291, %model.23.cv2.weight)
      %input.307 = Concat[axis = 1](%onnx::Concat_370, %onnx::Concat_371)
      %input.311 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.990000009536743](%input.307, %model.23.bn.weight, %model.23.bn.bias, %model.23.bn.running_mean, %model.23.bn.running_var)
      %onnx::Conv_374 = LeakyRelu[alpha = 0.100000001490116](%input.311)
      %input.315 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_374, %model.23.cv4.conv.weight, %model.23.cv4.conv.bias)
      %onnx::Conv_376 = LeakyRelu[alpha = 0.100000001490116](%input.315)
      %onnx::Reshape_377 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_344, %model.24.m.0.weight, %model.24.m.0.bias)
      %onnx::Transpose_389 = Reshape(%onnx::Reshape_377, %onnx::Reshape_426)
      %output = Transpose[perm = [0, 1, 3, 4, 2]](%onnx::Transpose_389)
      %onnx::Reshape_391 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_360, %model.24.m.1.weight, %model.24.m.1.bias)
      %onnx::Transpose_403 = Reshape(%onnx::Reshape_391, %onnx::Reshape_432)
      %404 = Transpose[perm = [0, 1, 3, 4, 2]](%onnx::Transpose_403)
      %onnx::Reshape_405 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_376, %model.24.m.2.weight, %model.24.m.2.bias)
      %onnx::Transpose_417 = Reshape(%onnx::Reshape_405, %onnx::Reshape_438)
      %418 = Transpose[perm = [0, 1, 3, 4, 2]](%onnx::Transpose_417)
      return %output, %404, %418
    }
    ONNX export success, saved as ./weights/yolov5s.onnx
    CoreML export failure: No module named 'coremltools'
    ```
    

- ä¿®æ”¹yolo.py
    
    ```bash
    Namespace(batch_size=1, img_size=[672, 672], weights='./weights/yolov5s.pt')
    
    Starting TorchScript export with torch 1.12.1+cu116...
    /home/dzp/.local/lib/python3.8/site-packages/torch/jit/_trace.py:967: TracerWarning: Encountering a list at the output of the tracer might cause the trace to be incorrect, this is only valid if the container structure does not change based on the module's inputs. Consider using a constant container instead (e.g. for `list`, use a `tuple` instead. for `dict`, use a `NamedTuple` instead). If you absolutely need this and know the side effects, pass strict=False to trace() to allow this behavior.
      module._c._create_method_from_trace(
    TorchScript export success, saved as ./weights/yolov5s.torchscript.pt
    
    Starting ONNX export with onnx 1.12.0...
    Fusing layers... Model Summary: 140 layers, 7.45958e+06 parameters, 6.61683e+06 gradients, 17.4 GFLOPS
    /home/dzp/yolov5/models/yolo.py:84: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
      if augment:
    /home/dzp/yolov5/models/yolo.py:108: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
      if profile:
    /home/dzp/yolov5/models/yolo.py:123: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
      if profile:
    graph torch_jit (
      %data[FLOAT, 1x3x672x672]
    ) initializers (
      %model.0.conv.conv.weight[FLOAT, 32x12x3x3]
      %model.0.conv.conv.bias[FLOAT, 32]
      %model.1.conv.weight[FLOAT, 64x32x3x3]
      %model.1.conv.bias[FLOAT, 64]
      %model.2.cv1.conv.weight[FLOAT, 32x64x1x1]
      %model.2.cv1.conv.bias[FLOAT, 32]
      %model.2.cv2.weight[FLOAT, 32x64x1x1]
      %model.2.cv3.weight[FLOAT, 32x32x1x1]
      %model.2.cv4.conv.weight[FLOAT, 64x64x1x1]
      %model.2.cv4.conv.bias[FLOAT, 64]
      %model.2.bn.weight[FLOAT, 64]
      %model.2.bn.bias[FLOAT, 64]
      %model.2.bn.running_mean[FLOAT, 64]
      %model.2.bn.running_var[FLOAT, 64]
      %model.2.m.0.cv1.conv.weight[FLOAT, 32x32x1x1]
      %model.2.m.0.cv1.conv.bias[FLOAT, 32]
      %model.2.m.0.cv2.conv.weight[FLOAT, 32x32x3x3]
      %model.2.m.0.cv2.conv.bias[FLOAT, 32]
      %model.3.conv.weight[FLOAT, 128x64x3x3]
      %model.3.conv.bias[FLOAT, 128]
      %model.4.cv1.conv.weight[FLOAT, 64x128x1x1]
      %model.4.cv1.conv.bias[FLOAT, 64]
      %model.4.cv2.weight[FLOAT, 64x128x1x1]
      %model.4.cv3.weight[FLOAT, 64x64x1x1]
      %model.4.cv4.conv.weight[FLOAT, 128x128x1x1]
      %model.4.cv4.conv.bias[FLOAT, 128]
      %model.4.bn.weight[FLOAT, 128]
      %model.4.bn.bias[FLOAT, 128]
      %model.4.bn.running_mean[FLOAT, 128]
      %model.4.bn.running_var[FLOAT, 128]
      %model.4.m.0.cv1.conv.weight[FLOAT, 64x64x1x1]
      %model.4.m.0.cv1.conv.bias[FLOAT, 64]
      %model.4.m.0.cv2.conv.weight[FLOAT, 64x64x3x3]
      %model.4.m.0.cv2.conv.bias[FLOAT, 64]
      %model.4.m.1.cv1.conv.weight[FLOAT, 64x64x1x1]
      %model.4.m.1.cv1.conv.bias[FLOAT, 64]
      %model.4.m.1.cv2.conv.weight[FLOAT, 64x64x3x3]
      %model.4.m.1.cv2.conv.bias[FLOAT, 64]
      %model.4.m.2.cv1.conv.weight[FLOAT, 64x64x1x1]
      %model.4.m.2.cv1.conv.bias[FLOAT, 64]
      %model.4.m.2.cv2.conv.weight[FLOAT, 64x64x3x3]
      %model.4.m.2.cv2.conv.bias[FLOAT, 64]
      %model.5.conv.weight[FLOAT, 256x128x3x3]
      %model.5.conv.bias[FLOAT, 256]
      %model.6.cv1.conv.weight[FLOAT, 128x256x1x1]
      %model.6.cv1.conv.bias[FLOAT, 128]
      %model.6.cv2.weight[FLOAT, 128x256x1x1]
      %model.6.cv3.weight[FLOAT, 128x128x1x1]
      %model.6.cv4.conv.weight[FLOAT, 256x256x1x1]
      %model.6.cv4.conv.bias[FLOAT, 256]
      %model.6.bn.weight[FLOAT, 256]
      %model.6.bn.bias[FLOAT, 256]
      %model.6.bn.running_mean[FLOAT, 256]
      %model.6.bn.running_var[FLOAT, 256]
      %model.6.m.0.cv1.conv.weight[FLOAT, 128x128x1x1]
      %model.6.m.0.cv1.conv.bias[FLOAT, 128]
      %model.6.m.0.cv2.conv.weight[FLOAT, 128x128x3x3]
      %model.6.m.0.cv2.conv.bias[FLOAT, 128]
      %model.6.m.1.cv1.conv.weight[FLOAT, 128x128x1x1]
      %model.6.m.1.cv1.conv.bias[FLOAT, 128]
      %model.6.m.1.cv2.conv.weight[FLOAT, 128x128x3x3]
      %model.6.m.1.cv2.conv.bias[FLOAT, 128]
      %model.6.m.2.cv1.conv.weight[FLOAT, 128x128x1x1]
      %model.6.m.2.cv1.conv.bias[FLOAT, 128]
      %model.6.m.2.cv2.conv.weight[FLOAT, 128x128x3x3]
      %model.6.m.2.cv2.conv.bias[FLOAT, 128]
      %model.7.conv.weight[FLOAT, 512x256x3x3]
      %model.7.conv.bias[FLOAT, 512]
      %model.8.cv1.conv.weight[FLOAT, 256x512x1x1]
      %model.8.cv1.conv.bias[FLOAT, 256]
      %model.8.cv2.conv.weight[FLOAT, 512x1024x1x1]
      %model.8.cv2.conv.bias[FLOAT, 512]
      %model.9.cv1.conv.weight[FLOAT, 256x512x1x1]
      %model.9.cv1.conv.bias[FLOAT, 256]
      %model.9.cv2.weight[FLOAT, 256x512x1x1]
      %model.9.cv3.weight[FLOAT, 256x256x1x1]
      %model.9.cv4.conv.weight[FLOAT, 512x512x1x1]
      %model.9.cv4.conv.bias[FLOAT, 512]
      %model.9.bn.weight[FLOAT, 512]
      %model.9.bn.bias[FLOAT, 512]
      %model.9.bn.running_mean[FLOAT, 512]
      %model.9.bn.running_var[FLOAT, 512]
      %model.9.m.0.cv1.conv.weight[FLOAT, 256x256x1x1]
      %model.9.m.0.cv1.conv.bias[FLOAT, 256]
      %model.9.m.0.cv2.conv.weight[FLOAT, 256x256x3x3]
      %model.9.m.0.cv2.conv.bias[FLOAT, 256]
      %model.10.conv.weight[FLOAT, 256x512x1x1]
      %model.10.conv.bias[FLOAT, 256]
      %model.13.cv1.conv.weight[FLOAT, 128x512x1x1]
      %model.13.cv1.conv.bias[FLOAT, 128]
      %model.13.cv2.weight[FLOAT, 128x512x1x1]
      %model.13.cv3.weight[FLOAT, 128x128x1x1]
      %model.13.cv4.conv.weight[FLOAT, 256x256x1x1]
      %model.13.cv4.conv.bias[FLOAT, 256]
      %model.13.bn.weight[FLOAT, 256]
      %model.13.bn.bias[FLOAT, 256]
      %model.13.bn.running_mean[FLOAT, 256]
      %model.13.bn.running_var[FLOAT, 256]
      %model.13.m.0.cv1.conv.weight[FLOAT, 128x128x1x1]
      %model.13.m.0.cv1.conv.bias[FLOAT, 128]
      %model.13.m.0.cv2.conv.weight[FLOAT, 128x128x3x3]
      %model.13.m.0.cv2.conv.bias[FLOAT, 128]
      %model.14.conv.weight[FLOAT, 128x256x1x1]
      %model.14.conv.bias[FLOAT, 128]
      %model.17.cv1.conv.weight[FLOAT, 64x256x1x1]
      %model.17.cv1.conv.bias[FLOAT, 64]
      %model.17.cv2.weight[FLOAT, 64x256x1x1]
      %model.17.cv3.weight[FLOAT, 64x64x1x1]
      %model.17.cv4.conv.weight[FLOAT, 128x128x1x1]
      %model.17.cv4.conv.bias[FLOAT, 128]
      %model.17.bn.weight[FLOAT, 128]
      %model.17.bn.bias[FLOAT, 128]
      %model.17.bn.running_mean[FLOAT, 128]
      %model.17.bn.running_var[FLOAT, 128]
      %model.17.m.0.cv1.conv.weight[FLOAT, 64x64x1x1]
      %model.17.m.0.cv1.conv.bias[FLOAT, 64]
      %model.17.m.0.cv2.conv.weight[FLOAT, 64x64x3x3]
      %model.17.m.0.cv2.conv.bias[FLOAT, 64]
      %model.18.conv.weight[FLOAT, 128x128x3x3]
      %model.18.conv.bias[FLOAT, 128]
      %model.20.cv1.conv.weight[FLOAT, 128x256x1x1]
      %model.20.cv1.conv.bias[FLOAT, 128]
      %model.20.cv2.weight[FLOAT, 128x256x1x1]
      %model.20.cv3.weight[FLOAT, 128x128x1x1]
      %model.20.cv4.conv.weight[FLOAT, 256x256x1x1]
      %model.20.cv4.conv.bias[FLOAT, 256]
      %model.20.bn.weight[FLOAT, 256]
      %model.20.bn.bias[FLOAT, 256]
      %model.20.bn.running_mean[FLOAT, 256]
      %model.20.bn.running_var[FLOAT, 256]
      %model.20.m.0.cv1.conv.weight[FLOAT, 128x128x1x1]
      %model.20.m.0.cv1.conv.bias[FLOAT, 128]
      %model.20.m.0.cv2.conv.weight[FLOAT, 128x128x3x3]
      %model.20.m.0.cv2.conv.bias[FLOAT, 128]
      %model.21.conv.weight[FLOAT, 256x256x3x3]
      %model.21.conv.bias[FLOAT, 256]
      %model.23.cv1.conv.weight[FLOAT, 256x512x1x1]
      %model.23.cv1.conv.bias[FLOAT, 256]
      %model.23.cv2.weight[FLOAT, 256x512x1x1]
      %model.23.cv3.weight[FLOAT, 256x256x1x1]
      %model.23.cv4.conv.weight[FLOAT, 512x512x1x1]
      %model.23.cv4.conv.bias[FLOAT, 512]
      %model.23.bn.weight[FLOAT, 512]
      %model.23.bn.bias[FLOAT, 512]
      %model.23.bn.running_mean[FLOAT, 512]
      %model.23.bn.running_var[FLOAT, 512]
      %model.23.m.0.cv1.conv.weight[FLOAT, 256x256x1x1]
      %model.23.m.0.cv1.conv.bias[FLOAT, 256]
      %model.23.m.0.cv2.conv.weight[FLOAT, 256x256x3x3]
      %model.23.m.0.cv2.conv.bias[FLOAT, 256]
      %model.24.m.0.weight[FLOAT, 255x128x1x1]
      %model.24.m.0.bias[FLOAT, 255]
      %model.24.m.1.weight[FLOAT, 255x256x1x1]
      %model.24.m.1.bias[FLOAT, 255]
      %model.24.m.2.weight[FLOAT, 255x512x1x1]
      %model.24.m.2.bias[FLOAT, 255]
      %onnx::Resize_383[FLOAT, 4]
    ) {
      %onnx::Resize_384 = Identity(%onnx::Resize_383)
      %onnx::Slice_169 = Constant[value = <Tensor>]()
      %onnx::Slice_170 = Constant[value = <Tensor>]()
      %onnx::Slice_171 = Constant[value = <Tensor>]()
      %onnx::Slice_172 = Constant[value = <Tensor>]()
      %onnx::Slice_173 = Slice(%data, %onnx::Slice_170, %onnx::Slice_171, %onnx::Slice_169, %onnx::Slice_172)
      %onnx::Slice_174 = Constant[value = <Tensor>]()
      %onnx::Slice_175 = Constant[value = <Tensor>]()
      %onnx::Slice_176 = Constant[value = <Tensor>]()
      %onnx::Slice_177 = Constant[value = <Tensor>]()
      %onnx::Concat_178 = Slice(%onnx::Slice_173, %onnx::Slice_175, %onnx::Slice_176, %onnx::Slice_174, %onnx::Slice_177)
      %onnx::Slice_179 = Constant[value = <Tensor>]()
      %onnx::Slice_180 = Constant[value = <Tensor>]()
      %onnx::Slice_181 = Constant[value = <Tensor>]()
      %onnx::Slice_182 = Constant[value = <Tensor>]()
      %onnx::Slice_183 = Slice(%data, %onnx::Slice_180, %onnx::Slice_181, %onnx::Slice_179, %onnx::Slice_182)
      %onnx::Slice_184 = Constant[value = <Tensor>]()
      %onnx::Slice_185 = Constant[value = <Tensor>]()
      %onnx::Slice_186 = Constant[value = <Tensor>]()
      %onnx::Slice_187 = Constant[value = <Tensor>]()
      %onnx::Concat_188 = Slice(%onnx::Slice_183, %onnx::Slice_185, %onnx::Slice_186, %onnx::Slice_184, %onnx::Slice_187)
      %onnx::Slice_189 = Constant[value = <Tensor>]()
      %onnx::Slice_190 = Constant[value = <Tensor>]()
      %onnx::Slice_191 = Constant[value = <Tensor>]()
      %onnx::Slice_192 = Constant[value = <Tensor>]()
      %onnx::Slice_193 = Slice(%data, %onnx::Slice_190, %onnx::Slice_191, %onnx::Slice_189, %onnx::Slice_192)
      %onnx::Slice_194 = Constant[value = <Tensor>]()
      %onnx::Slice_195 = Constant[value = <Tensor>]()
      %onnx::Slice_196 = Constant[value = <Tensor>]()
      %onnx::Slice_197 = Constant[value = <Tensor>]()
      %onnx::Concat_198 = Slice(%onnx::Slice_193, %onnx::Slice_195, %onnx::Slice_196, %onnx::Slice_194, %onnx::Slice_197)
      %onnx::Slice_199 = Constant[value = <Tensor>]()
      %onnx::Slice_200 = Constant[value = <Tensor>]()
      %onnx::Slice_201 = Constant[value = <Tensor>]()
      %onnx::Slice_202 = Constant[value = <Tensor>]()
      %onnx::Slice_203 = Slice(%data, %onnx::Slice_200, %onnx::Slice_201, %onnx::Slice_199, %onnx::Slice_202)
      %onnx::Slice_204 = Constant[value = <Tensor>]()
      %onnx::Slice_205 = Constant[value = <Tensor>]()
      %onnx::Slice_206 = Constant[value = <Tensor>]()
      %onnx::Slice_207 = Constant[value = <Tensor>]()
      %onnx::Concat_208 = Slice(%onnx::Slice_203, %onnx::Slice_205, %onnx::Slice_206, %onnx::Slice_204, %onnx::Slice_207)
      %input = Concat[axis = 1](%onnx::Concat_178, %onnx::Concat_188, %onnx::Concat_198, %onnx::Concat_208)
      %input.3 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input, %model.0.conv.conv.weight, %model.0.conv.conv.bias)
      %onnx::Conv_211 = LeakyRelu[alpha = 0.100000001490116](%input.3)
      %input.7 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%onnx::Conv_211, %model.1.conv.weight, %model.1.conv.bias)
      %onnx::Conv_213 = LeakyRelu[alpha = 0.100000001490116](%input.7)
      %input.11 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_213, %model.2.cv1.conv.weight, %model.2.cv1.conv.bias)
      %onnx::Conv_215 = LeakyRelu[alpha = 0.100000001490116](%input.11)
      %input.15 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_215, %model.2.m.0.cv1.conv.weight, %model.2.m.0.cv1.conv.bias)
      %onnx::Conv_217 = LeakyRelu[alpha = 0.100000001490116](%input.15)
      %input.19 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%onnx::Conv_217, %model.2.m.0.cv2.conv.weight, %model.2.m.0.cv2.conv.bias)
      %onnx::Add_219 = LeakyRelu[alpha = 0.100000001490116](%input.19)
      %input.23 = Add(%onnx::Conv_215, %onnx::Add_219)
      %onnx::Concat_221 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.23, %model.2.cv3.weight)
      %onnx::Concat_222 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_213, %model.2.cv2.weight)
      %input.27 = Concat[axis = 1](%onnx::Concat_221, %onnx::Concat_222)
      %input.31 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.990000009536743](%input.27, %model.2.bn.weight, %model.2.bn.bias, %model.2.bn.running_mean, %model.2.bn.running_var)
      %onnx::Conv_225 = LeakyRelu[alpha = 0.100000001490116](%input.31)
      %input.35 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_225, %model.2.cv4.conv.weight, %model.2.cv4.conv.bias)
      %onnx::Conv_227 = LeakyRelu[alpha = 0.100000001490116](%input.35)
      %input.39 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%onnx::Conv_227, %model.3.conv.weight, %model.3.conv.bias)
      %onnx::Conv_229 = LeakyRelu[alpha = 0.100000001490116](%input.39)
      %input.43 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_229, %model.4.cv1.conv.weight, %model.4.cv1.conv.bias)
      %onnx::Conv_231 = LeakyRelu[alpha = 0.100000001490116](%input.43)
      %input.47 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_231, %model.4.m.0.cv1.conv.weight, %model.4.m.0.cv1.conv.bias)
      %onnx::Conv_233 = LeakyRelu[alpha = 0.100000001490116](%input.47)
      %input.51 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%onnx::Conv_233, %model.4.m.0.cv2.conv.weight, %model.4.m.0.cv2.conv.bias)
      %onnx::Add_235 = LeakyRelu[alpha = 0.100000001490116](%input.51)
      %input.55 = Add(%onnx::Conv_231, %onnx::Add_235)
      %input.59 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.55, %model.4.m.1.cv1.conv.weight, %model.4.m.1.cv1.conv.bias)
      %onnx::Conv_238 = LeakyRelu[alpha = 0.100000001490116](%input.59)
      %input.63 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%onnx::Conv_238, %model.4.m.1.cv2.conv.weight, %model.4.m.1.cv2.conv.bias)
      %onnx::Add_240 = LeakyRelu[alpha = 0.100000001490116](%input.63)
      %input.67 = Add(%input.55, %onnx::Add_240)
      %input.71 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.67, %model.4.m.2.cv1.conv.weight, %model.4.m.2.cv1.conv.bias)
      %onnx::Conv_243 = LeakyRelu[alpha = 0.100000001490116](%input.71)
      %input.75 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%onnx::Conv_243, %model.4.m.2.cv2.conv.weight, %model.4.m.2.cv2.conv.bias)
      %onnx::Add_245 = LeakyRelu[alpha = 0.100000001490116](%input.75)
      %input.79 = Add(%input.67, %onnx::Add_245)
      %onnx::Concat_247 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.79, %model.4.cv3.weight)
      %onnx::Concat_248 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_229, %model.4.cv2.weight)
      %input.83 = Concat[axis = 1](%onnx::Concat_247, %onnx::Concat_248)
      %input.87 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.990000009536743](%input.83, %model.4.bn.weight, %model.4.bn.bias, %model.4.bn.running_mean, %model.4.bn.running_var)
      %onnx::Conv_251 = LeakyRelu[alpha = 0.100000001490116](%input.87)
      %input.91 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_251, %model.4.cv4.conv.weight, %model.4.cv4.conv.bias)
      %onnx::Conv_253 = LeakyRelu[alpha = 0.100000001490116](%input.91)
      %input.95 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%onnx::Conv_253, %model.5.conv.weight, %model.5.conv.bias)
      %onnx::Conv_255 = LeakyRelu[alpha = 0.100000001490116](%input.95)
      %input.99 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_255, %model.6.cv1.conv.weight, %model.6.cv1.conv.bias)
      %onnx::Conv_257 = LeakyRelu[alpha = 0.100000001490116](%input.99)
      %input.103 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_257, %model.6.m.0.cv1.conv.weight, %model.6.m.0.cv1.conv.bias)
      %onnx::Conv_259 = LeakyRelu[alpha = 0.100000001490116](%input.103)
      %input.107 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%onnx::Conv_259, %model.6.m.0.cv2.conv.weight, %model.6.m.0.cv2.conv.bias)
      %onnx::Add_261 = LeakyRelu[alpha = 0.100000001490116](%input.107)
      %input.111 = Add(%onnx::Conv_257, %onnx::Add_261)
      %input.115 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.111, %model.6.m.1.cv1.conv.weight, %model.6.m.1.cv1.conv.bias)
      %onnx::Conv_264 = LeakyRelu[alpha = 0.100000001490116](%input.115)
      %input.119 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%onnx::Conv_264, %model.6.m.1.cv2.conv.weight, %model.6.m.1.cv2.conv.bias)
      %onnx::Add_266 = LeakyRelu[alpha = 0.100000001490116](%input.119)
      %input.123 = Add(%input.111, %onnx::Add_266)
      %input.127 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.123, %model.6.m.2.cv1.conv.weight, %model.6.m.2.cv1.conv.bias)
      %onnx::Conv_269 = LeakyRelu[alpha = 0.100000001490116](%input.127)
      %input.131 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%onnx::Conv_269, %model.6.m.2.cv2.conv.weight, %model.6.m.2.cv2.conv.bias)
      %onnx::Add_271 = LeakyRelu[alpha = 0.100000001490116](%input.131)
      %input.135 = Add(%input.123, %onnx::Add_271)
      %onnx::Concat_273 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.135, %model.6.cv3.weight)
      %onnx::Concat_274 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_255, %model.6.cv2.weight)
      %input.139 = Concat[axis = 1](%onnx::Concat_273, %onnx::Concat_274)
      %input.143 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.990000009536743](%input.139, %model.6.bn.weight, %model.6.bn.bias, %model.6.bn.running_mean, %model.6.bn.running_var)
      %onnx::Conv_277 = LeakyRelu[alpha = 0.100000001490116](%input.143)
      %input.147 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_277, %model.6.cv4.conv.weight, %model.6.cv4.conv.bias)
      %onnx::Conv_279 = LeakyRelu[alpha = 0.100000001490116](%input.147)
      %input.151 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%onnx::Conv_279, %model.7.conv.weight, %model.7.conv.bias)
      %onnx::Conv_281 = LeakyRelu[alpha = 0.100000001490116](%input.151)
      %input.155 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_281, %model.8.cv1.conv.weight, %model.8.cv1.conv.bias)
      %onnx::MaxPool_283 = LeakyRelu[alpha = 0.100000001490116](%input.155)
      %onnx::Concat_284 = MaxPool[ceil_mode = 0, kernel_shape = [5, 5], pads = [2, 2, 2, 2], strides = [1, 1]](%onnx::MaxPool_283)
      %onnx::Concat_285 = MaxPool[ceil_mode = 0, kernel_shape = [9, 9], pads = [4, 4, 4, 4], strides = [1, 1]](%onnx::MaxPool_283)
      %onnx::Concat_286 = MaxPool[ceil_mode = 0, kernel_shape = [13, 13], pads = [6, 6, 6, 6], strides = [1, 1]](%onnx::MaxPool_283)
      %input.159 = Concat[axis = 1](%onnx::MaxPool_283, %onnx::Concat_284, %onnx::Concat_285, %onnx::Concat_286)
      %input.163 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.159, %model.8.cv2.conv.weight, %model.8.cv2.conv.bias)
      %onnx::Conv_289 = LeakyRelu[alpha = 0.100000001490116](%input.163)
      %input.167 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_289, %model.9.cv1.conv.weight, %model.9.cv1.conv.bias)
      %onnx::Conv_291 = LeakyRelu[alpha = 0.100000001490116](%input.167)
      %input.171 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_291, %model.9.m.0.cv1.conv.weight, %model.9.m.0.cv1.conv.bias)
      %onnx::Conv_293 = LeakyRelu[alpha = 0.100000001490116](%input.171)
      %input.175 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%onnx::Conv_293, %model.9.m.0.cv2.conv.weight, %model.9.m.0.cv2.conv.bias)
      %onnx::Conv_295 = LeakyRelu[alpha = 0.100000001490116](%input.175)
      %onnx::Concat_296 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_295, %model.9.cv3.weight)
      %onnx::Concat_297 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_289, %model.9.cv2.weight)
      %input.179 = Concat[axis = 1](%onnx::Concat_296, %onnx::Concat_297)
      %input.183 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.990000009536743](%input.179, %model.9.bn.weight, %model.9.bn.bias, %model.9.bn.running_mean, %model.9.bn.running_var)
      %onnx::Conv_300 = LeakyRelu[alpha = 0.100000001490116](%input.183)
      %input.187 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_300, %model.9.cv4.conv.weight, %model.9.cv4.conv.bias)
      %onnx::Conv_302 = LeakyRelu[alpha = 0.100000001490116](%input.187)
      %input.191 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_302, %model.10.conv.weight, %model.10.conv.bias)
      %onnx::Resize_304 = LeakyRelu[alpha = 0.100000001490116](%input.191)
      %onnx::Resize_308 = Constant[value = <Tensor>]()
      %onnx::Concat_309 = Resize[coordinate_transformation_mode = 'asymmetric', cubic_coeff_a = -0.75, mode = 'nearest', nearest_mode = 'floor'](%onnx::Resize_304, %onnx::Resize_308, %onnx::Resize_383)
      %input.195 = Concat[axis = 1](%onnx::Concat_309, %onnx::Conv_279)
      %input.199 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.195, %model.13.cv1.conv.weight, %model.13.cv1.conv.bias)
      %onnx::Conv_312 = LeakyRelu[alpha = 0.100000001490116](%input.199)
      %input.203 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_312, %model.13.m.0.cv1.conv.weight, %model.13.m.0.cv1.conv.bias)
      %onnx::Conv_314 = LeakyRelu[alpha = 0.100000001490116](%input.203)
      %input.207 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%onnx::Conv_314, %model.13.m.0.cv2.conv.weight, %model.13.m.0.cv2.conv.bias)
      %onnx::Conv_316 = LeakyRelu[alpha = 0.100000001490116](%input.207)
      %onnx::Concat_317 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_316, %model.13.cv3.weight)
      %onnx::Concat_318 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.195, %model.13.cv2.weight)
      %input.211 = Concat[axis = 1](%onnx::Concat_317, %onnx::Concat_318)
      %input.215 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.990000009536743](%input.211, %model.13.bn.weight, %model.13.bn.bias, %model.13.bn.running_mean, %model.13.bn.running_var)
      %onnx::Conv_321 = LeakyRelu[alpha = 0.100000001490116](%input.215)
      %input.219 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_321, %model.13.cv4.conv.weight, %model.13.cv4.conv.bias)
      %onnx::Conv_323 = LeakyRelu[alpha = 0.100000001490116](%input.219)
      %input.223 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_323, %model.14.conv.weight, %model.14.conv.bias)
      %onnx::Resize_325 = LeakyRelu[alpha = 0.100000001490116](%input.223)
      %onnx::Resize_329 = Constant[value = <Tensor>]()
      %onnx::Concat_330 = Resize[coordinate_transformation_mode = 'asymmetric', cubic_coeff_a = -0.75, mode = 'nearest', nearest_mode = 'floor'](%onnx::Resize_325, %onnx::Resize_329, %onnx::Resize_384)
      %input.227 = Concat[axis = 1](%onnx::Concat_330, %onnx::Conv_253)
      %input.231 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.227, %model.17.cv1.conv.weight, %model.17.cv1.conv.bias)
      %onnx::Conv_333 = LeakyRelu[alpha = 0.100000001490116](%input.231)
      %input.235 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_333, %model.17.m.0.cv1.conv.weight, %model.17.m.0.cv1.conv.bias)
      %onnx::Conv_335 = LeakyRelu[alpha = 0.100000001490116](%input.235)
      %input.239 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%onnx::Conv_335, %model.17.m.0.cv2.conv.weight, %model.17.m.0.cv2.conv.bias)
      %onnx::Conv_337 = LeakyRelu[alpha = 0.100000001490116](%input.239)
      %onnx::Concat_338 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_337, %model.17.cv3.weight)
      %onnx::Concat_339 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.227, %model.17.cv2.weight)
      %input.243 = Concat[axis = 1](%onnx::Concat_338, %onnx::Concat_339)
      %input.247 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.990000009536743](%input.243, %model.17.bn.weight, %model.17.bn.bias, %model.17.bn.running_mean, %model.17.bn.running_var)
      %onnx::Conv_342 = LeakyRelu[alpha = 0.100000001490116](%input.247)
      %input.251 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_342, %model.17.cv4.conv.weight, %model.17.cv4.conv.bias)
      %onnx::Conv_344 = LeakyRelu[alpha = 0.100000001490116](%input.251)
      %input.255 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%onnx::Conv_344, %model.18.conv.weight, %model.18.conv.bias)
      %onnx::Concat_346 = LeakyRelu[alpha = 0.100000001490116](%input.255)
      %input.259 = Concat[axis = 1](%onnx::Concat_346, %onnx::Resize_325)
      %input.263 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.259, %model.20.cv1.conv.weight, %model.20.cv1.conv.bias)
      %onnx::Conv_349 = LeakyRelu[alpha = 0.100000001490116](%input.263)
      %input.267 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_349, %model.20.m.0.cv1.conv.weight, %model.20.m.0.cv1.conv.bias)
      %onnx::Conv_351 = LeakyRelu[alpha = 0.100000001490116](%input.267)
      %input.271 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%onnx::Conv_351, %model.20.m.0.cv2.conv.weight, %model.20.m.0.cv2.conv.bias)
      %onnx::Conv_353 = LeakyRelu[alpha = 0.100000001490116](%input.271)
      %onnx::Concat_354 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_353, %model.20.cv3.weight)
      %onnx::Concat_355 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.259, %model.20.cv2.weight)
      %input.275 = Concat[axis = 1](%onnx::Concat_354, %onnx::Concat_355)
      %input.279 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.990000009536743](%input.275, %model.20.bn.weight, %model.20.bn.bias, %model.20.bn.running_mean, %model.20.bn.running_var)
      %onnx::Conv_358 = LeakyRelu[alpha = 0.100000001490116](%input.279)
      %input.283 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_358, %model.20.cv4.conv.weight, %model.20.cv4.conv.bias)
      %onnx::Conv_360 = LeakyRelu[alpha = 0.100000001490116](%input.283)
      %input.287 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%onnx::Conv_360, %model.21.conv.weight, %model.21.conv.bias)
      %onnx::Concat_362 = LeakyRelu[alpha = 0.100000001490116](%input.287)
      %input.291 = Concat[axis = 1](%onnx::Concat_362, %onnx::Resize_304)
      %input.295 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.291, %model.23.cv1.conv.weight, %model.23.cv1.conv.bias)
      %onnx::Conv_365 = LeakyRelu[alpha = 0.100000001490116](%input.295)
      %input.299 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_365, %model.23.m.0.cv1.conv.weight, %model.23.m.0.cv1.conv.bias)
      %onnx::Conv_367 = LeakyRelu[alpha = 0.100000001490116](%input.299)
      %input.303 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%onnx::Conv_367, %model.23.m.0.cv2.conv.weight, %model.23.m.0.cv2.conv.bias)
      %onnx::Conv_369 = LeakyRelu[alpha = 0.100000001490116](%input.303)
      %onnx::Concat_370 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_369, %model.23.cv3.weight)
      %onnx::Concat_371 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%input.291, %model.23.cv2.weight)
      %input.307 = Concat[axis = 1](%onnx::Concat_370, %onnx::Concat_371)
      %input.311 = BatchNormalization[epsilon = 0.00100000004749745, momentum = 0.990000009536743](%input.307, %model.23.bn.weight, %model.23.bn.bias, %model.23.bn.running_mean, %model.23.bn.running_var)
      %onnx::Conv_374 = LeakyRelu[alpha = 0.100000001490116](%input.311)
      %input.315 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_374, %model.23.cv4.conv.weight, %model.23.cv4.conv.bias)
      %onnx::Conv_376 = LeakyRelu[alpha = 0.100000001490116](%input.315)
      %onnx::Transpose_377 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_344, %model.24.m.0.weight, %model.24.m.0.bias)
      %output = Transpose[perm = [0, 2, 3, 1]](%onnx::Transpose_377)
      %onnx::Transpose_379 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_360, %model.24.m.1.weight, %model.24.m.1.bias)
      %380 = Transpose[perm = [0, 2, 3, 1]](%onnx::Transpose_379)
      %onnx::Transpose_381 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%onnx::Conv_376, %model.24.m.2.weight, %model.24.m.2.bias)
      %382 = Transpose[perm = [0, 2, 3, 1]](%onnx::Transpose_381)
      return %output, %380, %382
    }
    ONNX export success, saved as ./weights/yolov5s.onnx
    CoreML export failure: No module named 'coremltools'
    ```
    

### YOLOv5s ONNXç»“æ„å›¾ï¼ˆæœ€æ–°ç‰ˆï¼‰

![yolov5s.onnx.svg](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/1a3753bb-b527-4fbf-bba4-95bd36f0e1e8/yolov5s.onnx.svg)

### YOLOv5s ONNX v2.0ç‰ˆç»“æ„å›¾

![yolov5s.onnx (1).svg](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/eb3cf4a6-3645-4584-8396-ac12091d63fd/yolov5s.onnx_(1).svg)

<aside>
âš ï¸ åœ°å¹³çº¿å®˜æ–¹æ–‡æ¡£ä¸­æåˆ°ä¸€å¤„å¯¹yolo.pyæ–‡ä»¶çš„ä¿®æ”¹ï¼š

```python
def forward(self, x):
    # x = x.copy()  # for profiling
    z = []  # inference output
    self.training |= self.export
    for i in range(self.nl):
        x[i] = self.m[i](x[i])  # conv
        bs, _, ny, nx = x[i].shape  # x(bs,255,20,20) to x(bs,3,20,20,85)
        #  x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()
        x[i] = x[i].permute(0, 2, 3, 1).contiguous()
```

é’ˆå¯¹æ˜¯å¦æœ‰å¿…è¦åšè¯¥ä¿®æ”¹ï¼Œä»¥åŠè¯¥ä¿®æ”¹çš„å½±å“ï¼Œåˆ†åˆ«è¿›è¡Œå®éªŒã€‚

</aside>

- æœªåšä¿®æ”¹æ—¶ `bash 01_check.sh` çš„è¾“å‡º
    
    ```bash
    cd $(dirname $0) || exit
    
    MODEL_NAME=${1:-yolov5s}
    
    model_type="onnx"
    onnx_model="./models/$MODEL_NAME.onnx"
    march="bernoulli2"
    
    hb_mapper checker --model-type ${model_type} \
                      --model ${onnx_model} \
                      --march ${march}
    /usr/local/lib/python3.6/site-packages/paramiko/transport.py:33: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography and will be removed in a future release.
      from cryptography.hazmat.backends import default_backend
    2023-01-10 11:03:45,663 INFO log will be stored in /open_explorer/smart_vision/hb_mapper_checker.log
    2023-01-10 11:03:45,663 INFO Start hb_mapper....
    2023-01-10 11:03:45,663 INFO hbdk version 3.41.4
    2023-01-10 11:03:45,663 INFO horizon_nn version 0.15.3
    2023-01-10 11:03:45,663 INFO hb_mapper version 1.13.3
    2023-01-10 11:03:45,681 INFO Model type: onnx
    2023-01-10 11:03:45,681 INFO input names []
    2023-01-10 11:03:45,681 INFO input shapes {}
    2023-01-10 11:03:45,681 INFO Begin model checking....
    2023-01-10 11:03:45,692 INFO [Tue Jan 10 11:03:45 2023] Start to Horizon NN Model Convert.
    2023-01-10 11:03:45,692 INFO The input parameter is not specified, convert with default parameters.
    2023-01-10 11:03:45,692 INFO Parsing the hbdk parameter:{'hbdk_pass_through_params': '--O0'}
    2023-01-10 11:03:45,692 INFO HorizonNN version: 0.15.3
    2023-01-10 11:03:45,693 INFO HBDK version: 3.41.4
    2023-01-10 11:03:45,693 INFO [Tue Jan 10 11:03:45 2023] Start to parse the onnx model.
    2023-01-10 11:03:45,708 INFO Input ONNX model infomation:
    ONNX IR version:          6
    Opset version:            [11]
    Producer:                 pytorch1.12.1
    Domain:                   none
    Input name:               data, [1, 3, 672, 672]
    Output name:              output, [1, 3, 84, 84, 85]
    Output name:              404, [1, 3, 42, 42, 85]
    Output name:              418, [1, 3, 21, 21, 85]
    2023-01-10 11:03:45,807 INFO [Tue Jan 10 11:03:45 2023] End to parse the onnx model.
    2023-01-10 11:03:45,807 INFO Model input names parsed from model: ['data']
    2023-01-10 11:03:45,821 INFO Saving the original float model: ./.hb_check/original_float_model.onnx.
    2023-01-10 11:03:45,821 INFO [Tue Jan 10 11:03:45 2023] Start to optimize the model.
    2023-01-10 11:03:46,231 INFO [Tue Jan 10 11:03:46 2023] End to optimize the model.
    2023-01-10 11:03:46,245 INFO Saving the optimized model: ./.hb_check/optimized_float_model.onnx.
    2023-01-10 11:03:46,245 INFO [Tue Jan 10 11:03:46 2023] Start to calibrate the model.
    2023-01-10 11:03:46,251 INFO There are 1 samples in the calibration data set.
    2023-01-10 11:03:46,387 INFO Run calibration model with max method.
    max calibration in progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.36it/s]
    2023-01-10 11:03:46,822 INFO [Tue Jan 10 11:03:46 2023] End to calibrate the model.
    2023-01-10 11:03:46,822 INFO [Tue Jan 10 11:03:46 2023] Start to quantize the model.
    2023-01-10 11:03:47,878 INFO [Tue Jan 10 11:03:47 2023] End to quantize the model.
    2023-01-10 11:03:48,049 INFO Saving the quantized model: ./.hb_check/quantized_model.onnx.
    2023-01-10 11:03:48,564 INFO [Tue Jan 10 11:03:48 2023] Start to compile the model with march bernoulli2.
    2023-01-10 11:03:48,807 INFO Compile submodel: torch_jit_subgraph_0
    2023-01-10 11:03:49,177 INFO hbdk-cc parameters:['--O0', '--input-layout', 'NHWC', '--output-layout', 'NCHW']
    2023-01-10 11:03:49,212 INFO INFO: "-j" or "--jobs" is not specified, launch 16 threads for optimization
    [==================================================] 100%
    2023-01-10 11:03:50,301 INFO consumed time 1.09413
    2023-01-10 11:03:50,416 INFO FPS=9.6, latency = 104172.3 us   (see ./.hb_check/torch_jit_subgraph_0.html)
    2023-01-10 11:03:50,552 INFO [Tue Jan 10 11:03:50 2023] End to compile the model with march bernoulli2.
    2023-01-10 11:03:50,553 INFO The converted model node information:
    ==============================================================================================
    Node                                                ON   Subgraph  Type                       
    ----------------------------------------------------------------------------------------------
    Slice_5                                             CPU  --        Slice                      
    Slice_10                                            CPU  --        Slice                      
    Slice_15                                            CPU  --        Slice                      
    Slice_20                                            CPU  --        Slice                      
    Slice_25                                            CPU  --        Slice                      
    Slice_30                                            CPU  --        Slice                      
    Slice_35                                            CPU  --        Slice                      
    Slice_40                                            CPU  --        Slice                      
    Concat_41                                           CPU  --        Concat                     
    Conv_42                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_43                                        BPU  id(0)     HzLeakyRelu                
    Conv_44                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_45                                        BPU  id(0)     HzLeakyRelu                
    Conv_46                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_47                                        BPU  id(0)     HzLeakyRelu                
    Conv_48                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_49                                        BPU  id(0)     HzLeakyRelu                
    Conv_50                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_51                                        BPU  id(0)     HzLeakyRelu                
    UNIT_CONV_FOR_Add_52                                BPU  id(0)     HzSQuantizedConv           
    Conv_53                                             BPU  id(0)     HzSQuantizedConv           
    Conv_54                                             BPU  id(0)     HzSQuantizedConv           
    Concat_55                                           BPU  id(0)     Concat                     
    LeakyRelu_57                                        BPU  id(0)     HzLeakyRelu                
    Conv_58                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_59                                        BPU  id(0)     HzLeakyRelu                
    Conv_60                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_61                                        BPU  id(0)     HzLeakyRelu                
    Conv_62                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_63                                        BPU  id(0)     HzLeakyRelu                
    Conv_64                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_65                                        BPU  id(0)     HzLeakyRelu                
    Conv_66                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_67                                        BPU  id(0)     HzLeakyRelu                
    UNIT_CONV_FOR_Add_68                                BPU  id(0)     HzSQuantizedConv           
    Conv_69                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_70                                        BPU  id(0)     HzLeakyRelu                
    Conv_71                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_72                                        BPU  id(0)     HzLeakyRelu                
    UNIT_CONV_FOR_Add_73                                BPU  id(0)     HzSQuantizedConv           
    Conv_74                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_75                                        BPU  id(0)     HzLeakyRelu                
    Conv_76                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_77                                        BPU  id(0)     HzLeakyRelu                
    UNIT_CONV_FOR_Add_78                                BPU  id(0)     HzSQuantizedConv           
    Conv_79                                             BPU  id(0)     HzSQuantizedConv           
    Conv_80                                             BPU  id(0)     HzSQuantizedConv           
    Concat_81                                           BPU  id(0)     Concat                     
    LeakyRelu_83                                        BPU  id(0)     HzLeakyRelu                
    Conv_84                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_85                                        BPU  id(0)     HzLeakyRelu                
    Conv_86                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_87                                        BPU  id(0)     HzLeakyRelu                
    Conv_88                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_89                                        BPU  id(0)     HzLeakyRelu                
    Conv_90                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_91                                        BPU  id(0)     HzLeakyRelu                
    Conv_92                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_93                                        BPU  id(0)     HzLeakyRelu                
    UNIT_CONV_FOR_Add_94                                BPU  id(0)     HzSQuantizedConv           
    Conv_95                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_96                                        BPU  id(0)     HzLeakyRelu                
    Conv_97                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_98                                        BPU  id(0)     HzLeakyRelu                
    UNIT_CONV_FOR_Add_99                                BPU  id(0)     HzSQuantizedConv           
    Conv_100                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_101                                       BPU  id(0)     HzLeakyRelu                
    Conv_102                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_103                                       BPU  id(0)     HzLeakyRelu                
    UNIT_CONV_FOR_Add_104                               BPU  id(0)     HzSQuantizedConv           
    Conv_105                                            BPU  id(0)     HzSQuantizedConv           
    Conv_106                                            BPU  id(0)     HzSQuantizedConv           
    Concat_107                                          BPU  id(0)     Concat                     
    LeakyRelu_109                                       BPU  id(0)     HzLeakyRelu                
    Conv_110                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_111                                       BPU  id(0)     HzLeakyRelu                
    Conv_112                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_113                                       BPU  id(0)     HzLeakyRelu                
    Conv_114                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_115                                       BPU  id(0)     HzLeakyRelu                
    MaxPool_116                                         BPU  id(0)     HzQuantizedMaxPool         
    MaxPool_117                                         BPU  id(0)     HzQuantizedMaxPool         
    MaxPool_118                                         BPU  id(0)     HzQuantizedMaxPool         
    Concat_119                                          BPU  id(0)     Concat                     
    Conv_120                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_121                                       BPU  id(0)     HzLeakyRelu                
    Conv_122                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_123                                       BPU  id(0)     HzLeakyRelu                
    Conv_124                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_125                                       BPU  id(0)     HzLeakyRelu                
    Conv_126                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_127                                       BPU  id(0)     HzLeakyRelu                
    Conv_128                                            BPU  id(0)     HzSQuantizedConv           
    Conv_129                                            BPU  id(0)     HzSQuantizedConv           
    Concat_130                                          BPU  id(0)     Concat                     
    LeakyRelu_132                                       BPU  id(0)     HzLeakyRelu                
    Conv_133                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_134                                       BPU  id(0)     HzLeakyRelu                
    Conv_135                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_136                                       BPU  id(0)     HzLeakyRelu                
    Resize_138                                          BPU  id(0)     HzQuantizedResizeUpsample  
    UNIT_CONV_FOR_onnx::Conv_279_0.03335_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv           
    Concat_139                                          BPU  id(0)     Concat                     
    Conv_140                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_141                                       BPU  id(0)     HzLeakyRelu                
    Conv_142                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_143                                       BPU  id(0)     HzLeakyRelu                
    Conv_144                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_145                                       BPU  id(0)     HzLeakyRelu                
    Conv_146                                            BPU  id(0)     HzSQuantizedConv           
    Conv_147                                            BPU  id(0)     HzSQuantizedConv           
    Concat_148                                          BPU  id(0)     Concat                     
    LeakyRelu_150                                       BPU  id(0)     HzLeakyRelu                
    Conv_151                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_152                                       BPU  id(0)     HzLeakyRelu                
    Conv_153                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_154                                       BPU  id(0)     HzLeakyRelu                
    Resize_156                                          BPU  id(0)     HzQuantizedResizeUpsample  
    Concat_157                                          BPU  id(0)     Concat                     
    Conv_158                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_159                                       BPU  id(0)     HzLeakyRelu                
    Conv_160                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_161                                       BPU  id(0)     HzLeakyRelu                
    Conv_162                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_163                                       BPU  id(0)     HzLeakyRelu                
    Conv_164                                            BPU  id(0)     HzSQuantizedConv           
    Conv_165                                            BPU  id(0)     HzSQuantizedConv           
    Concat_166                                          BPU  id(0)     Concat                     
    LeakyRelu_168                                       BPU  id(0)     HzLeakyRelu                
    Conv_169                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_170                                       BPU  id(0)     HzLeakyRelu                
    Conv_171                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_172                                       BPU  id(0)     HzLeakyRelu                
    ...CONV_FOR_onnx::Resize_325_0.03978_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv           
    Concat_173                                          BPU  id(0)     Concat                     
    Conv_174                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_175                                       BPU  id(0)     HzLeakyRelu                
    Conv_176                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_177                                       BPU  id(0)     HzLeakyRelu                
    Conv_178                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_179                                       BPU  id(0)     HzLeakyRelu                
    Conv_180                                            BPU  id(0)     HzSQuantizedConv           
    Conv_181                                            BPU  id(0)     HzSQuantizedConv           
    Concat_182                                          BPU  id(0)     Concat                     
    LeakyRelu_184                                       BPU  id(0)     HzLeakyRelu                
    Conv_185                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_186                                       BPU  id(0)     HzLeakyRelu                
    Conv_187                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_188                                       BPU  id(0)     HzLeakyRelu                
    Concat_189                                          BPU  id(0)     Concat                     
    Conv_190                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_191                                       BPU  id(0)     HzLeakyRelu                
    Conv_192                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_193                                       BPU  id(0)     HzLeakyRelu                
    Conv_194                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_195                                       BPU  id(0)     HzLeakyRelu                
    Conv_196                                            BPU  id(0)     HzSQuantizedConv           
    Conv_197                                            BPU  id(0)     HzSQuantizedConv           
    Concat_198                                          BPU  id(0)     Concat                     
    LeakyRelu_200                                       BPU  id(0)     HzLeakyRelu                
    Conv_201                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_202                                       BPU  id(0)     HzLeakyRelu                
    Conv_203                                            BPU  id(0)     HzSQuantizedConv           
    Reshape_204                                         CPU  --        Reshape                    
    Transpose_205                                       CPU  --        Transpose                  
    Conv_206                                            BPU  id(0)     HzSQuantizedConv           
    Reshape_207                                         CPU  --        Reshape                    
    Transpose_208                                       CPU  --        Transpose                  
    Conv_209                                            BPU  id(0)     HzSQuantizedConv           
    Reshape_210                                         CPU  --        Reshape                    
    Transpose_211                                       CPU  --        Transpose
    2023-01-10 11:03:50,555 INFO [Tue Jan 10 11:03:50 2023] End to Horizon NN Model Convert.
    2023-01-10 11:03:50,559 INFO ONNX model output num : 3
    2023-01-10 11:03:50,567 INFO End model checking....
    ```
    

- æ”¹åè¾“å‡º
    
    ```bash
    cd $(dirname $0) || exit
    
    MODEL_NAME=${1:-yolov5s}
    
    model_type="onnx"
    onnx_model="./models/$MODEL_NAME.onnx"
    march="bernoulli2"
    
    hb_mapper checker --model-type ${model_type} \
                      --model ${onnx_model} \
                      --march ${march}
    /usr/local/lib/python3.6/site-packages/paramiko/transport.py:33: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography and will be removed in a future release.
      from cryptography.hazmat.backends import default_backend
    2023-01-10 12:19:43,654 INFO log will be stored in /open_explorer/smart_vision/hb_mapper_checker.log
    2023-01-10 12:19:43,654 INFO Start hb_mapper....
    2023-01-10 12:19:43,654 INFO hbdk version 3.41.4
    2023-01-10 12:19:43,654 INFO horizon_nn version 0.15.3
    2023-01-10 12:19:43,654 INFO hb_mapper version 1.13.3
    2023-01-10 12:19:43,674 INFO Model type: onnx
    2023-01-10 12:19:43,674 INFO input names []
    2023-01-10 12:19:43,674 INFO input shapes {}
    2023-01-10 12:19:43,674 INFO Begin model checking....
    2023-01-10 12:19:43,684 INFO [Tue Jan 10 12:19:43 2023] Start to Horizon NN Model Convert.
    2023-01-10 12:19:43,684 INFO The input parameter is not specified, convert with default parameters.
    2023-01-10 12:19:43,684 INFO Parsing the hbdk parameter:{'hbdk_pass_through_params': '--O0'}
    2023-01-10 12:19:43,684 INFO HorizonNN version: 0.15.3
    2023-01-10 12:19:43,684 INFO HBDK version: 3.41.4
    2023-01-10 12:19:43,685 INFO [Tue Jan 10 12:19:43 2023] Start to parse the onnx model.
    2023-01-10 12:19:43,702 INFO Input ONNX model infomation:
    ONNX IR version:          6
    Opset version:            [11]
    Producer:                 pytorch1.12.1
    Domain:                   none
    Input name:               data, [1, 3, 672, 672]
    Output name:              output, [1, 84, 84, 255]
    Output name:              380, [1, 42, 42, 255]
    Output name:              382, [1, 21, 21, 255]
    2023-01-10 12:19:43,804 INFO [Tue Jan 10 12:19:43 2023] End to parse the onnx model.
    2023-01-10 12:19:43,804 INFO Model input names parsed from model: ['data']
    2023-01-10 12:19:43,818 INFO Saving the original float model: ./.hb_check/original_float_model.onnx.
    2023-01-10 12:19:43,818 INFO [Tue Jan 10 12:19:43 2023] Start to optimize the model.
    2023-01-10 12:19:44,201 INFO [Tue Jan 10 12:19:44 2023] End to optimize the model.
    2023-01-10 12:19:44,216 INFO Saving the optimized model: ./.hb_check/optimized_float_model.onnx.
    2023-01-10 12:19:44,217 INFO [Tue Jan 10 12:19:44 2023] Start to calibrate the model.
    2023-01-10 12:19:44,222 INFO There are 1 samples in the calibration data set.
    2023-01-10 12:19:44,366 INFO Run calibration model with max method.
    max calibration in progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.21it/s]
    2023-01-10 12:19:44,806 INFO [Tue Jan 10 12:19:44 2023] End to calibrate the model.
    2023-01-10 12:19:44,807 INFO [Tue Jan 10 12:19:44 2023] Start to quantize the model.
    2023-01-10 12:19:45,900 INFO [Tue Jan 10 12:19:45 2023] End to quantize the model.
    2023-01-10 12:19:46,075 INFO Saving the quantized model: ./.hb_check/quantized_model.onnx.
    2023-01-10 12:19:46,597 INFO [Tue Jan 10 12:19:46 2023] Start to compile the model with march bernoulli2.
    2023-01-10 12:19:46,842 INFO Compile submodel: torch_jit_subgraph_0
    2023-01-10 12:19:47,212 INFO hbdk-cc parameters:['--O0', '--input-layout', 'NHWC', '--output-layout', 'NHWC']
    2023-01-10 12:19:47,239 INFO INFO: "-j" or "--jobs" is not specified, launch 16 threads for optimization
    [==================================================] 100%
    2023-01-10 12:19:48,270 INFO consumed time 1.0345
    2023-01-10 12:19:48,379 INFO FPS=10.37, latency = 96402.8 us   (see ./.hb_check/torch_jit_subgraph_0.html)
    2023-01-10 12:19:48,519 INFO [Tue Jan 10 12:19:48 2023] End to compile the model with march bernoulli2.
    2023-01-10 12:19:48,520 INFO The converted model node information:
    ==============================================================================================
    Node                                                ON   Subgraph  Type                       
    ----------------------------------------------------------------------------------------------
    Slice_5                                             CPU  --        Slice                      
    Slice_10                                            CPU  --        Slice                      
    Slice_15                                            CPU  --        Slice                      
    Slice_20                                            CPU  --        Slice                      
    Slice_25                                            CPU  --        Slice                      
    Slice_30                                            CPU  --        Slice                      
    Slice_35                                            CPU  --        Slice                      
    Slice_40                                            CPU  --        Slice                      
    Concat_41                                           CPU  --        Concat                     
    Conv_42                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_43                                        BPU  id(0)     HzLeakyRelu                
    Conv_44                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_45                                        BPU  id(0)     HzLeakyRelu                
    Conv_46                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_47                                        BPU  id(0)     HzLeakyRelu                
    Conv_48                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_49                                        BPU  id(0)     HzLeakyRelu                
    Conv_50                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_51                                        BPU  id(0)     HzLeakyRelu                
    UNIT_CONV_FOR_Add_52                                BPU  id(0)     HzSQuantizedConv           
    Conv_53                                             BPU  id(0)     HzSQuantizedConv           
    Conv_54                                             BPU  id(0)     HzSQuantizedConv           
    Concat_55                                           BPU  id(0)     Concat                     
    LeakyRelu_57                                        BPU  id(0)     HzLeakyRelu                
    Conv_58                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_59                                        BPU  id(0)     HzLeakyRelu                
    Conv_60                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_61                                        BPU  id(0)     HzLeakyRelu                
    Conv_62                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_63                                        BPU  id(0)     HzLeakyRelu                
    Conv_64                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_65                                        BPU  id(0)     HzLeakyRelu                
    Conv_66                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_67                                        BPU  id(0)     HzLeakyRelu                
    UNIT_CONV_FOR_Add_68                                BPU  id(0)     HzSQuantizedConv           
    Conv_69                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_70                                        BPU  id(0)     HzLeakyRelu                
    Conv_71                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_72                                        BPU  id(0)     HzLeakyRelu                
    UNIT_CONV_FOR_Add_73                                BPU  id(0)     HzSQuantizedConv           
    Conv_74                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_75                                        BPU  id(0)     HzLeakyRelu                
    Conv_76                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_77                                        BPU  id(0)     HzLeakyRelu                
    UNIT_CONV_FOR_Add_78                                BPU  id(0)     HzSQuantizedConv           
    Conv_79                                             BPU  id(0)     HzSQuantizedConv           
    Conv_80                                             BPU  id(0)     HzSQuantizedConv           
    Concat_81                                           BPU  id(0)     Concat                     
    LeakyRelu_83                                        BPU  id(0)     HzLeakyRelu                
    Conv_84                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_85                                        BPU  id(0)     HzLeakyRelu                
    Conv_86                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_87                                        BPU  id(0)     HzLeakyRelu                
    Conv_88                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_89                                        BPU  id(0)     HzLeakyRelu                
    Conv_90                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_91                                        BPU  id(0)     HzLeakyRelu                
    Conv_92                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_93                                        BPU  id(0)     HzLeakyRelu                
    UNIT_CONV_FOR_Add_94                                BPU  id(0)     HzSQuantizedConv           
    Conv_95                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_96                                        BPU  id(0)     HzLeakyRelu                
    Conv_97                                             BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_98                                        BPU  id(0)     HzLeakyRelu                
    UNIT_CONV_FOR_Add_99                                BPU  id(0)     HzSQuantizedConv           
    Conv_100                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_101                                       BPU  id(0)     HzLeakyRelu                
    Conv_102                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_103                                       BPU  id(0)     HzLeakyRelu                
    UNIT_CONV_FOR_Add_104                               BPU  id(0)     HzSQuantizedConv           
    Conv_105                                            BPU  id(0)     HzSQuantizedConv           
    Conv_106                                            BPU  id(0)     HzSQuantizedConv           
    Concat_107                                          BPU  id(0)     Concat                     
    LeakyRelu_109                                       BPU  id(0)     HzLeakyRelu                
    Conv_110                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_111                                       BPU  id(0)     HzLeakyRelu                
    Conv_112                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_113                                       BPU  id(0)     HzLeakyRelu                
    Conv_114                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_115                                       BPU  id(0)     HzLeakyRelu                
    MaxPool_116                                         BPU  id(0)     HzQuantizedMaxPool         
    MaxPool_117                                         BPU  id(0)     HzQuantizedMaxPool         
    MaxPool_118                                         BPU  id(0)     HzQuantizedMaxPool         
    Concat_119                                          BPU  id(0)     Concat                     
    Conv_120                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_121                                       BPU  id(0)     HzLeakyRelu                
    Conv_122                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_123                                       BPU  id(0)     HzLeakyRelu                
    Conv_124                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_125                                       BPU  id(0)     HzLeakyRelu                
    Conv_126                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_127                                       BPU  id(0)     HzLeakyRelu                
    Conv_128                                            BPU  id(0)     HzSQuantizedConv           
    Conv_129                                            BPU  id(0)     HzSQuantizedConv           
    Concat_130                                          BPU  id(0)     Concat                     
    LeakyRelu_132                                       BPU  id(0)     HzLeakyRelu                
    Conv_133                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_134                                       BPU  id(0)     HzLeakyRelu                
    Conv_135                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_136                                       BPU  id(0)     HzLeakyRelu                
    Resize_138                                          BPU  id(0)     HzQuantizedResizeUpsample  
    Concat_139                                          BPU  id(0)     Concat                     
    Conv_140                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_141                                       BPU  id(0)     HzLeakyRelu                
    Conv_142                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_143                                       BPU  id(0)     HzLeakyRelu                
    Conv_144                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_145                                       BPU  id(0)     HzLeakyRelu                
    Conv_146                                            BPU  id(0)     HzSQuantizedConv           
    Conv_147                                            BPU  id(0)     HzSQuantizedConv           
    Concat_148                                          BPU  id(0)     Concat                     
    LeakyRelu_150                                       BPU  id(0)     HzLeakyRelu                
    Conv_151                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_152                                       BPU  id(0)     HzLeakyRelu                
    Conv_153                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_154                                       BPU  id(0)     HzLeakyRelu                
    Resize_156                                          BPU  id(0)     HzQuantizedResizeUpsample  
    Concat_157                                          BPU  id(0)     Concat                     
    Conv_158                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_159                                       BPU  id(0)     HzLeakyRelu                
    Conv_160                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_161                                       BPU  id(0)     HzLeakyRelu                
    Conv_162                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_163                                       BPU  id(0)     HzLeakyRelu                
    Conv_164                                            BPU  id(0)     HzSQuantizedConv           
    Conv_165                                            BPU  id(0)     HzSQuantizedConv           
    Concat_166                                          BPU  id(0)     Concat                     
    LeakyRelu_168                                       BPU  id(0)     HzLeakyRelu                
    Conv_169                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_170                                       BPU  id(0)     HzLeakyRelu                
    Conv_171                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_172                                       BPU  id(0)     HzLeakyRelu                
    ...CONV_FOR_onnx::Resize_325_0.04157_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv           
    Concat_173                                          BPU  id(0)     Concat                     
    Conv_174                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_175                                       BPU  id(0)     HzLeakyRelu                
    Conv_176                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_177                                       BPU  id(0)     HzLeakyRelu                
    Conv_178                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_179                                       BPU  id(0)     HzLeakyRelu                
    Conv_180                                            BPU  id(0)     HzSQuantizedConv           
    Conv_181                                            BPU  id(0)     HzSQuantizedConv           
    Concat_182                                          BPU  id(0)     Concat                     
    LeakyRelu_184                                       BPU  id(0)     HzLeakyRelu                
    Conv_185                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_186                                       BPU  id(0)     HzLeakyRelu                
    Conv_187                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_188                                       BPU  id(0)     HzLeakyRelu                
    ...CONV_FOR_onnx::Resize_304_0.03234_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv           
    Concat_189                                          BPU  id(0)     Concat                     
    Conv_190                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_191                                       BPU  id(0)     HzLeakyRelu                
    Conv_192                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_193                                       BPU  id(0)     HzLeakyRelu                
    Conv_194                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_195                                       BPU  id(0)     HzLeakyRelu                
    Conv_196                                            BPU  id(0)     HzSQuantizedConv           
    Conv_197                                            BPU  id(0)     HzSQuantizedConv           
    Concat_198                                          BPU  id(0)     Concat                     
    LeakyRelu_200                                       BPU  id(0)     HzLeakyRelu                
    Conv_201                                            BPU  id(0)     HzSQuantizedConv           
    LeakyRelu_202                                       BPU  id(0)     HzLeakyRelu                
    Conv_203                                            BPU  id(0)     HzSQuantizedConv           
    Conv_205                                            BPU  id(0)     HzSQuantizedConv           
    Conv_207                                            BPU  id(0)     HzSQuantizedConv
    2023-01-10 12:19:48,521 INFO [Tue Jan 10 12:19:48 2023] End to Horizon NN Model Convert.
    2023-01-10 12:19:48,526 INFO ONNX model output num : 3
    2023-01-10 12:19:48,535 INFO End model checking....
    ```
    

å¯è§æ”¹åŠ¨å¯¹æ¨¡å‹æ£€æŸ¥ç»“æœäº§ç”Ÿäº†å½±å“ï¼Œæ”¹åŠ¨å‰ç½‘ç»œæœ€åéƒ¨åˆ†å±‚ä½¿ç”¨CPUï¼Œæ”¹åå…¨éƒ¨ä½¿ç”¨BPUï¼ˆå¯èƒ½éƒ¨åˆ†å±‚ä¸å†åœ¨ç½‘ç»œä¸­ä½“ç°ï¼Œè€Œæ˜¯ä¾èµ–ä¹‹åé¢å¤–å®ç°åå¤„ç†ï¼‰

<aside>
ğŸ’¡ åç»­ç ”ç©¶å·²ç»è¯æ˜ï¼Œä½¿ç”¨ `export.py` æ—¶ä¼šä½¿ç”¨ `yolo.py` ä¸­çš„ç½‘ç»œç»“æ„å®šä¹‰ã€‚åœ¨v7.0ç‰ˆæœ¬çš„yolov5ä¸­ï¼Œ `Detect` ç±»çš„ `forward` å‡½æ•°å®šä¹‰å¦‚ä¸‹ã€‚æ³¨æ„å…¶ä¸­å·²å‚ç…§åœ°å¹³çº¿çš„å¤„ç†æ–¹å¼å¯¹ `x[i]` åšå‡ºä¿®æ”¹ï¼Œè¿™æ ·å°±èƒ½ä¿è¯ç”Ÿæˆçš„æ¨¡å‹å…¼å®¹åœ°å¹³çº¿åœ¨OEå‘å¸ƒåŒ…ä¸­æä¾›çš„è½¬æ¢åŠæ¨ç†ä»£ç ã€‚å…¶ä»–ç›¸å…³ä¿®æ”¹å‚è§ä»¥ä¸‹æ¯”è¾ƒï¼ˆmainåˆ†æ”¯ä¸ºé’ˆå¯¹X3æ´¾å®šåˆ¶çš„åˆ†æ”¯ï¼Œmasteråˆ†æ”¯ä¸ºYOLOv5å®˜æ–¹ä¸»åˆ†æ”¯ï¼‰ï¼š

[](https://github.com/SOTA-Robotics/yolov5/compare/master...main)

```python
def forward(self, x):
    z = []  # inference output
    for i in range(self.nl):
        x[i] = self.m[i](x[i])  # conv
        bs, _, ny, nx = x[i].shape  # x(bs,255,20,20) to x(bs,3,20,20,85)
        # x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()
        x[i] = x[i].permute(0, 2, 3, 1).contiguous()

    #     if not self.training:  # inference
    #         if self.dynamic or self.grid[i].shape[2:4] != x[i].shape[2:4]:
    #             self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)
    #
    #         if isinstance(self, Segment):  # (boxes + masks)
    #             xy, wh, conf, mask = x[i].split((2, 2, self.nc + 1, self.no - self.nc - 5), 4)
    #             xy = (xy.sigmoid() * 2 + self.grid[i]) * self.stride[i]  # xy
    #             wh = (wh.sigmoid() * 2) ** 2 * self.anchor_grid[i]  # wh
    #             y = torch.cat((xy, wh, conf.sigmoid(), mask), 4)
    #         else:  # Detect (boxes only)
    #             xy, wh, conf = x[i].sigmoid().split((2, 2, self.nc + 1), 4)
    #             xy = (xy * 2 + self.grid[i]) * self.stride[i]  # xy
    #             wh = (wh * 2) ** 2 * self.anchor_grid[i]  # wh
    #             y = torch.cat((xy, wh, conf), 4)
    #         z.append(y.view(bs, self.na * nx * ny, self.no))
    #
    # return x if self.training else (torch.cat(z, 1),) if self.export else (torch.cat(z, 1), x)
    return x
```

</aside>

æœªåšä¿®æ”¹æ—¶ `bash 03_build.sh` çš„è¾“å‡ºï¼Œå…¶ä¸­å‡ºç°ä»¥ä¸‹è­¦å‘Šä¿¡æ¯ï¼š

<aside>
âš ï¸ 2023-01-10 11:25:59.341249719 [E:onnxruntime:, sequential_executor.cc:183 Execute] Non-zero status code returned while running Reshape node. Name:'Reshape_210' Status Message: /home/jenkins/agent/workspace/model_convert/onnxruntime/onnxruntime/core/providers/cpu/tensor/reshape_helper.h:43 onnxruntime::ReshapeHelper::ReshapeHelper(const onnxruntime::TensorShape&, std::vector<long int>&) gsl::narrow_cast<int64_t>(input_shape.Size()) == size was false. The input tensor cannot be reshaped to the requested shape. Input shape:{8,255,21,21}, requested shape:{1,3,85,21,21}

</aside>

åšå‡ºä¿®æ”¹åï¼Œä¸å†å‡ºç°è¯¥ä¿¡æ¯ã€‚

- `bash 04_inference.sh` å¾—åˆ°çš„å›¾åƒ
    
    ![demo.jpg](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/a3102d3d-048e-4a49-b36a-c955e0dd4869/demo.jpg)
    

- æ”¹åinferenceç»“æœå›¾åƒï¼ˆ**è¯†åˆ«æ­£å¸¸ï¼**ï¼‰
    
    ![demo.jpg](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/59d360d6-762e-46e8-acb0-2e534b36794e/demo.jpg)
    

## PTè½¬ONNXï¼ˆv7.0ï¼‰

æœ¬éƒ¨åˆ†ä¸»è¦æ£€éªŒä»¥ä¸ŠåŸºäºv2.0ç‰ˆçš„å®éªŒå¯¹äºæœ€æ–°ç‰ˆçš„è½¬æ¢æ˜¯å¦ä¹Ÿæœ‰å‚è€ƒä»·å€¼ã€‚åœ¨è½¬æ¢å‰å¯¹YOLOv5ä»£ç åšå‡ºä»¥ä¸‹ä¿®æ”¹ï¼š

[](https://github.com/SOTA-Robotics/yolov5/compare/master...main)

ä¹‹åï¼Œæ­£å¸¸è¿è¡Œä»¥ä¸‹è„šæœ¬è¿›è¡Œæ¨¡å‹è½¬æ¢ï¼š

```bash
python ./export.py --weights ./weights/yolov5s-latest.pt --include onnx --opset 11
```

```bash
export: data=data/coco128.yaml, weights=['./weights/yolov5s-latest.pt'], imgsz=[672, 672], batch_size=1, device=cpu, half=False, inplace=False, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=11, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['onnx']
YOLOv5 ğŸš€ v7.0-66-g11d63e3 Python-3.8.10 torch-1.12.1+cu116 CPU

Fusing layers... 
YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs

PyTorch: starting from weights/yolov5s-latest.pt with output shape (1, 84, 84, 255) (14.1 MB)

ONNX: starting export with onnx 1.12.0...
ONNX: export success âœ… 0.8s, saved as weights/yolov5s-latest.onnx (27.6 MB)

Export complete (2.9s)
Results saved to /home/dzp/yolov5/weights
Detect:          python detect.py --weights weights/yolov5s-latest.onnx 
Validate:        python val.py --weights weights/yolov5s-latest.onnx 
PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'weights/yolov5s-latest.onnx')  
Visualize:       https://netron.app
```

```bash
export: data=data/coco128.yaml, weights=['./models/yolov5s.pt'], imgsz=[640, 640], batch_size=1, device=cpu, half=False, inplace=False, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=11, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['onnx']
YOLOv5 ğŸš€ v7.0-56-gc0ca1d2 Python-3.8.10 torch-1.12.1+cu116 CPU

Fusing layers... 
YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients

PyTorch: starting from models/yolov5s.pt with output shape (1, 25200, 85) (14.1 MB)

ONNX: starting export with onnx 1.12.0...
ONNX: export success âœ… 0.9s, saved as models/yolov5s.onnx (28.0 MB)

Export complete (1.2s)
Results saved to /home/dzp/yolov5/models
Detect:          python detect.py --weights models/yolov5s.onnx 
Validate:        python val.py --weights models/yolov5s.onnx 
PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'models/yolov5s.onnx')  
Visualize:       https://netron.app
```

## å°†v7.0 ONNXè½¬æ¢ä¸ºbin

1. è¿›å…¥OEå®¹å™¨ï¼ˆ[å‡†å¤‡å¼€å‘ç¯å¢ƒ](https://www.notion.so/27e5449af9af4b07853f44b8dbe7eb00) ï¼‰ï¼›
2. å¯¹è½¬æ¢å¾—åˆ°çš„ONNXï¼Œä½¿ç”¨ `01_check.sh` è¿›è¡Œæ£€éªŒ
    - æ£€éªŒè¾“å‡º
        
        ```bash
        cd $(dirname $0) || exit
        
        MODEL_NAME=${1:-yolov5s}
        
        model_type="onnx"
        onnx_model="./models/$MODEL_NAME-latest.onnx"
        march="bernoulli2"
        
        hb_mapper checker --model-type ${model_type} \
                          --model ${onnx_model} \
                          --march ${march}
        /usr/local/lib/python3.6/site-packages/paramiko/transport.py:33: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography and will be removed in a future release.
          from cryptography.hazmat.backends import default_backend
        2023-01-10 19:05:01,477 INFO log will be stored in /open_explorer/smart_vision/hb_mapper_checker.log
        2023-01-10 19:05:01,477 INFO Start hb_mapper....
        2023-01-10 19:05:01,477 INFO hbdk version 3.41.4
        2023-01-10 19:05:01,477 INFO horizon_nn version 0.15.3
        2023-01-10 19:05:01,477 INFO hb_mapper version 1.13.3
        2023-01-10 19:05:01,496 INFO Model type: onnx
        2023-01-10 19:05:01,496 INFO input names []
        2023-01-10 19:05:01,496 INFO input shapes {}
        2023-01-10 19:05:01,496 INFO Begin model checking....
        2023-01-10 19:05:01,506 INFO [Tue Jan 10 19:05:01 2023] Start to Horizon NN Model Convert.
        2023-01-10 19:05:01,507 INFO The input parameter is not specified, convert with default parameters.
        2023-01-10 19:05:01,507 INFO Parsing the hbdk parameter:{'hbdk_pass_through_params': '--O0'}
        2023-01-10 19:05:01,507 INFO HorizonNN version: 0.15.3
        2023-01-10 19:05:01,507 INFO HBDK version: 3.41.4
        2023-01-10 19:05:01,507 INFO [Tue Jan 10 19:05:01 2023] Start to parse the onnx model.
        2023-01-10 19:05:01,523 INFO Input ONNX model infomation:
        ONNX IR version:          6
        Opset version:            [11]
        Producer:                 pytorch1.12.1
        Domain:                   none
        Input name:               data, [1, 3, 672, 672]
        Output name:              output0, [1, 84, 84, 255]
        Output name:              332, [1, 42, 42, 255]
        Output name:              334, [1, 21, 21, 255]
        2023-01-10 19:05:01,616 INFO [Tue Jan 10 19:05:01 2023] End to parse the onnx model.
        2023-01-10 19:05:01,616 INFO Model input names parsed from model: ['data']
        2023-01-10 19:05:01,639 INFO Saving the original float model: ./.hb_check/original_float_model.onnx.
        2023-01-10 19:05:01,639 INFO [Tue Jan 10 19:05:01 2023] Start to optimize the model.
        2023-01-10 19:05:01,903 INFO [Tue Jan 10 19:05:01 2023] End to optimize the model.
        2023-01-10 19:05:01,925 INFO Saving the optimized model: ./.hb_check/optimized_float_model.onnx.
        2023-01-10 19:05:01,925 INFO [Tue Jan 10 19:05:01 2023] Start to calibrate the model.
        2023-01-10 19:05:01,931 INFO There are 1 samples in the calibration data set.
        2023-01-10 19:05:02,046 INFO Run calibration model with max method.
        max calibration in progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.97it/s]
        2023-01-10 19:05:02,533 INFO [Tue Jan 10 19:05:02 2023] End to calibrate the model.
        2023-01-10 19:05:02,534 INFO [Tue Jan 10 19:05:02 2023] Start to quantize the model.
        2023-01-10 19:05:03,590 INFO [Tue Jan 10 19:05:03 2023] End to quantize the model.
        2023-01-10 19:05:03,777 INFO Saving the quantized model: ./.hb_check/quantized_model.onnx.
        2023-01-10 19:05:04,307 INFO [Tue Jan 10 19:05:04 2023] Start to compile the model with march bernoulli2.
        2023-01-10 19:05:04,541 INFO Compile submodel: torch_jit_subgraph_0
        2023-01-10 19:05:04,895 INFO hbdk-cc parameters:['--O0', '--input-layout', 'NHWC', '--output-layout', 'NHWC']
        2023-01-10 19:05:04,925 INFO INFO: "-j" or "--jobs" is not specified, launch 16 threads for optimization
        2023-01-10 19:05:05,062 INFO INFO: Layer "Mul_3" will be executed on CPU
        2023-01-10 19:05:05,062 INFO INFO: Layer "Mul_6" will be executed on CPU
        2023-01-10 19:05:05,062 INFO INFO: Layer "Mul_9" will be executed on CPU
        2023-01-10 19:05:05,062 INFO INFO: Layer "Mul_19" will be executed on CPU
        2023-01-10 19:05:05,062 INFO INFO: Layer "Mul_12" will be executed on CPU
        2023-01-10 19:05:05,062 INFO INFO: Layer "Mul_15" will be executed on CPU
        2023-01-10 19:05:05,062 INFO INFO: Layer "Mul_23" will be executed on CPU
        2023-01-10 19:05:05,062 INFO INFO: Layer "Mul_26" will be executed on CPU
        2023-01-10 19:05:05,062 INFO INFO: Layer "Mul_29" will be executed on CPU
        2023-01-10 19:05:05,062 INFO INFO: Layer "Mul_46" will be executed on CPU
        2023-01-10 19:05:05,062 INFO INFO: Layer "Mul_32" will be executed on CPU
        2023-01-10 19:05:05,063 INFO INFO: Layer "Mul_35" will be executed on CPU
        2023-01-10 19:05:05,063 INFO INFO: Layer "Mul_39" will be executed on CPU
        2023-01-10 19:05:05,063 INFO INFO: Layer "Mul_42" will be executed on CPU
        2023-01-10 19:05:05,063 INFO INFO: Layer "Mul_50" will be executed on CPU
        2023-01-10 19:05:05,063 INFO INFO: Layer "Mul_53" will be executed on CPU
        2023-01-10 19:05:05,063 INFO INFO: Layer "Mul_56" will be executed on CPU
        2023-01-10 19:05:05,063 INFO INFO: Layer "Mul_80" will be executed on CPU
        2023-01-10 19:05:05,063 INFO INFO: Layer "Mul_59" will be executed on CPU
        2023-01-10 19:05:05,063 INFO INFO: Layer "Mul_62" will be executed on CPU
        2023-01-10 19:05:05,063 INFO INFO: Layer "Mul_66" will be executed on CPU
        2023-01-10 19:05:05,063 INFO INFO: Layer "Mul_69" will be executed on CPU
        2023-01-10 19:05:05,063 INFO INFO: Layer "Mul_73" will be executed on CPU
        2023-01-10 19:05:05,064 INFO INFO: Layer "Mul_76" will be executed on CPU
        2023-01-10 19:05:05,064 INFO INFO: Layer "Mul_84" will be executed on CPU
        2023-01-10 19:05:05,064 INFO INFO: Layer "Mul_87" will be executed on CPU
        2023-01-10 19:05:05,064 INFO INFO: Layer "Mul_90" will be executed on CPU
        2023-01-10 19:05:05,064 INFO INFO: Layer "Mul_100" will be executed on CPU
        2023-01-10 19:05:05,064 INFO INFO: Layer "Mul_93" will be executed on CPU
        2023-01-10 19:05:05,064 INFO INFO: Layer "Mul_96" will be executed on CPU
        2023-01-10 19:05:05,064 INFO INFO: Layer "Mul_104" will be executed on CPU
        2023-01-10 19:05:05,064 INFO INFO: Layer "Mul_107" will be executed on CPU
        2023-01-10 19:05:05,064 INFO INFO: Layer "Mul_114" will be executed on CPU
        2023-01-10 19:05:05,064 INFO INFO: Layer "Mul_117" will be executed on CPU
        2023-01-10 19:05:05,064 INFO INFO: Layer "Mul_123" will be executed on CPU
        2023-01-10 19:05:05,064 INFO INFO: Layer "Mul_132" will be executed on CPU
        2023-01-10 19:05:05,065 INFO INFO: Layer "Mul_126" will be executed on CPU
        2023-01-10 19:05:05,065 INFO INFO: Layer "Mul_129" will be executed on CPU
        2023-01-10 19:05:05,065 INFO INFO: Layer "Mul_136" will be executed on CPU
        2023-01-10 19:05:05,065 INFO INFO: Layer "Mul_139" will be executed on CPU
        2023-01-10 19:05:05,065 INFO INFO: Layer "Mul_145" will be executed on CPU
        2023-01-10 19:05:05,065 INFO INFO: Layer "Mul_154" will be executed on CPU
        2023-01-10 19:05:05,065 INFO INFO: Layer "Mul_148" will be executed on CPU
        2023-01-10 19:05:05,065 INFO INFO: Layer "Mul_151" will be executed on CPU
        2023-01-10 19:05:05,065 INFO INFO: Layer "Mul_158" will be executed on CPU
        2023-01-10 19:05:05,065 INFO INFO: Layer "Mul_161" will be executed on CPU
        2023-01-10 19:05:05,065 INFO INFO: Layer "Mul_165" will be executed on CPU
        2023-01-10 19:05:05,065 INFO INFO: Layer "Mul_174" will be executed on CPU
        2023-01-10 19:05:05,066 INFO INFO: Layer "Mul_168" will be executed on CPU
        2023-01-10 19:05:05,066 INFO INFO: Layer "Mul_171" will be executed on CPU
        2023-01-10 19:05:05,066 INFO INFO: Layer "Mul_178" will be executed on CPU
        2023-01-10 19:05:05,066 INFO INFO: Layer "Mul_181" will be executed on CPU
        2023-01-10 19:05:05,066 INFO INFO: Layer "Mul_185" will be executed on CPU
        2023-01-10 19:05:05,066 INFO INFO: Layer "Mul_194" will be executed on CPU
        2023-01-10 19:05:05,066 INFO INFO: Layer "Mul_188" will be executed on CPU
        2023-01-10 19:05:05,066 INFO INFO: Layer "Mul_191" will be executed on CPU
        2023-01-10 19:05:05,066 INFO INFO: Layer "Mul_198" will be executed on CPU
        [==================================================] 100%
        2023-01-10 19:05:05,486 INFO consumed time 0.565374
        2023-01-10 19:05:05,552 WARNING Performance information does not include operators in the model running on the CPU (including HzLut whose shape is over 8192)
        2023-01-10 19:05:05,587 INFO FPS=14.73, latency = 67885.9 us   (see ./.hb_check/torch_jit_subgraph_0.html)
        2023-01-10 19:05:05,713 INFO [Tue Jan 10 19:05:05 2023] End to compile the model with march bernoulli2.
        2023-01-10 19:05:05,714 INFO The converted model node information:
        ==============================================================================================
        Node                                                ON   Subgraph  Type                       
        ----------------------------------------------------------------------------------------------
        Conv_1                                              BPU  id(0)     HzSQuantizedConv           
        Mul_3                                               BPU  id(0)     HzLut                      
        Conv_4                                              BPU  id(0)     HzSQuantizedConv           
        Mul_6                                               BPU  id(0)     HzLut                      
        Conv_7                                              BPU  id(0)     HzSQuantizedConv           
        Mul_9                                               BPU  id(0)     HzLut                      
        Conv_10                                             BPU  id(0)     HzSQuantizedConv           
        Mul_12                                              BPU  id(0)     HzLut                      
        Conv_13                                             BPU  id(0)     HzSQuantizedConv           
        Mul_15                                              BPU  id(0)     HzLut                      
        UNIT_CONV_FOR_Add_16                                BPU  id(0)     HzSQuantizedConv           
        Conv_17                                             BPU  id(0)     HzSQuantizedConv           
        Mul_19                                              BPU  id(0)     HzLut                      
        ...CONV_FOR_onnx::Concat_143_0.20249_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv           
        Concat_20                                           BPU  id(0)     Concat                     
        Conv_21                                             BPU  id(0)     HzSQuantizedConv           
        Mul_23                                              BPU  id(0)     HzLut                      
        Conv_24                                             BPU  id(0)     HzSQuantizedConv           
        Mul_26                                              BPU  id(0)     HzLut                      
        Conv_27                                             BPU  id(0)     HzSQuantizedConv           
        Mul_29                                              BPU  id(0)     HzLut                      
        Conv_30                                             BPU  id(0)     HzSQuantizedConv           
        Mul_32                                              BPU  id(0)     HzLut                      
        Conv_33                                             BPU  id(0)     HzSQuantizedConv           
        Mul_35                                              BPU  id(0)     HzLut                      
        UNIT_CONV_FOR_Add_36                                BPU  id(0)     HzSQuantizedConv           
        Conv_37                                             BPU  id(0)     HzSQuantizedConv           
        Mul_39                                              BPU  id(0)     HzLut                      
        Conv_40                                             BPU  id(0)     HzSQuantizedConv           
        Mul_42                                              BPU  id(0)     HzLut                      
        UNIT_CONV_FOR_Add_43                                BPU  id(0)     HzSQuantizedConv           
        Conv_44                                             BPU  id(0)     HzSQuantizedConv           
        Mul_46                                              BPU  id(0)     HzLut                      
        ...CONV_FOR_onnx::Concat_170_0.04201_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv           
        Concat_47                                           BPU  id(0)     Concat                     
        Conv_48                                             BPU  id(0)     HzSQuantizedConv           
        Mul_50                                              BPU  id(0)     HzLut                      
        Conv_51                                             BPU  id(0)     HzSQuantizedConv           
        Mul_53                                              BPU  id(0)     HzLut                      
        Conv_54                                             BPU  id(0)     HzSQuantizedConv           
        Mul_56                                              BPU  id(0)     HzLut                      
        Conv_57                                             BPU  id(0)     HzSQuantizedConv           
        Mul_59                                              BPU  id(0)     HzLut                      
        Conv_60                                             BPU  id(0)     HzSQuantizedConv           
        Mul_62                                              BPU  id(0)     HzLut                      
        UNIT_CONV_FOR_Add_63                                BPU  id(0)     HzSQuantizedConv           
        Conv_64                                             BPU  id(0)     HzSQuantizedConv           
        Mul_66                                              BPU  id(0)     HzLut                      
        Conv_67                                             BPU  id(0)     HzSQuantizedConv           
        Mul_69                                              BPU  id(0)     HzLut                      
        UNIT_CONV_FOR_Add_70                                BPU  id(0)     HzSQuantizedConv           
        Conv_71                                             BPU  id(0)     HzSQuantizedConv           
        Mul_73                                              BPU  id(0)     HzLut                      
        Conv_74                                             BPU  id(0)     HzSQuantizedConv           
        Mul_76                                              BPU  id(0)     HzLut                      
        UNIT_CONV_FOR_Add_77                                BPU  id(0)     HzSQuantizedConv           
        Conv_78                                             BPU  id(0)     HzSQuantizedConv           
        Mul_80                                              BPU  id(0)     HzLut                      
        ...CONV_FOR_onnx::Concat_204_0.04423_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv           
        Concat_81                                           BPU  id(0)     Concat                     
        Conv_82                                             BPU  id(0)     HzSQuantizedConv           
        Mul_84                                              BPU  id(0)     HzLut                      
        Conv_85                                             BPU  id(0)     HzSQuantizedConv           
        Mul_87                                              BPU  id(0)     HzLut                      
        Conv_88                                             BPU  id(0)     HzSQuantizedConv           
        Mul_90                                              BPU  id(0)     HzLut                      
        Conv_91                                             BPU  id(0)     HzSQuantizedConv           
        Mul_93                                              BPU  id(0)     HzLut                      
        Conv_94                                             BPU  id(0)     HzSQuantizedConv           
        Mul_96                                              BPU  id(0)     HzLut                      
        UNIT_CONV_FOR_Add_97                                BPU  id(0)     HzSQuantizedConv           
        Conv_98                                             BPU  id(0)     HzSQuantizedConv           
        Mul_100                                             BPU  id(0)     HzLut                      
        ...CONV_FOR_onnx::Concat_224_0.03371_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv           
        Concat_101                                          BPU  id(0)     Concat                     
        Conv_102                                            BPU  id(0)     HzSQuantizedConv           
        Mul_104                                             BPU  id(0)     HzLut                      
        Conv_105                                            BPU  id(0)     HzSQuantizedConv           
        Mul_107                                             BPU  id(0)     HzLut                      
        MaxPool_108                                         BPU  id(0)     HzQuantizedMaxPool         
        MaxPool_109                                         BPU  id(0)     HzQuantizedMaxPool         
        MaxPool_110                                         BPU  id(0)     HzQuantizedMaxPool         
        Concat_111                                          BPU  id(0)     Concat                     
        Conv_112                                            BPU  id(0)     HzSQuantizedConv           
        Mul_114                                             BPU  id(0)     HzLut                      
        Conv_115                                            BPU  id(0)     HzSQuantizedConv           
        Mul_117                                             BPU  id(0)     HzLut                      
        Resize_119                                          BPU  id(0)     HzQuantizedResizeUpsample  
        ...CONV_FOR_onnx::Concat_246_0.03079_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv           
        UNIT_CONV_FOR_onnx::Conv_208_0.03079_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv           
        Concat_120                                          BPU  id(0)     Concat                     
        Conv_121                                            BPU  id(0)     HzSQuantizedConv           
        Mul_123                                             BPU  id(0)     HzLut                      
        Conv_124                                            BPU  id(0)     HzSQuantizedConv           
        Mul_126                                             BPU  id(0)     HzLut                      
        Conv_127                                            BPU  id(0)     HzSQuantizedConv           
        Mul_129                                             BPU  id(0)     HzLut                      
        Conv_130                                            BPU  id(0)     HzSQuantizedConv           
        Mul_132                                             BPU  id(0)     HzLut                      
        ...CONV_FOR_onnx::Concat_256_0.02170_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv           
        ...CONV_FOR_onnx::Concat_259_0.02170_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv           
        Concat_133                                          BPU  id(0)     Concat                     
        Conv_134                                            BPU  id(0)     HzSQuantizedConv           
        Mul_136                                             BPU  id(0)     HzLut                      
        Conv_137                                            BPU  id(0)     HzSQuantizedConv           
        Mul_139                                             BPU  id(0)     HzLut                      
        Resize_141                                          BPU  id(0)     HzQuantizedResizeUpsample  
        UNIT_CONV_FOR_onnx::Conv_174_0.02784_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv           
        Concat_142                                          BPU  id(0)     Concat                     
        Conv_143                                            BPU  id(0)     HzSQuantizedConv           
        Mul_145                                             BPU  id(0)     HzLut                      
        Conv_146                                            BPU  id(0)     HzSQuantizedConv           
        Mul_148                                             BPU  id(0)     HzLut                      
        Conv_149                                            BPU  id(0)     HzSQuantizedConv           
        Mul_151                                             BPU  id(0)     HzLut                      
        Conv_152                                            BPU  id(0)     HzSQuantizedConv           
        Mul_154                                             BPU  id(0)     HzLut                      
        ...CONV_FOR_onnx::Concat_281_0.03700_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv           
        ...CONV_FOR_onnx::Concat_284_0.03700_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv           
        Concat_155                                          BPU  id(0)     Concat                     
        Conv_156                                            BPU  id(0)     HzSQuantizedConv           
        Mul_158                                             BPU  id(0)     HzLut                      
        Conv_159                                            BPU  id(0)     HzSQuantizedConv           
        Mul_161                                             BPU  id(0)     HzLut                      
        ...CONV_FOR_onnx::Resize_266_0.03217_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv           
        Concat_162                                          BPU  id(0)     Concat                     
        Conv_163                                            BPU  id(0)     HzSQuantizedConv           
        Mul_165                                             BPU  id(0)     HzLut                      
        Conv_166                                            BPU  id(0)     HzSQuantizedConv           
        Mul_168                                             BPU  id(0)     HzLut                      
        Conv_169                                            BPU  id(0)     HzSQuantizedConv           
        Mul_171                                             BPU  id(0)     HzLut                      
        Conv_172                                            BPU  id(0)     HzSQuantizedConv           
        Mul_174                                             BPU  id(0)     HzLut                      
        ...CONV_FOR_onnx::Concat_301_0.02784_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv           
        ...CONV_FOR_onnx::Concat_304_0.02784_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv           
        Concat_175                                          BPU  id(0)     Concat                     
        Conv_176                                            BPU  id(0)     HzSQuantizedConv           
        Mul_178                                             BPU  id(0)     HzLut                      
        Conv_179                                            BPU  id(0)     HzSQuantizedConv           
        Mul_181                                             BPU  id(0)     HzLut                      
        ...CONV_FOR_onnx::Concat_311_0.03079_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv           
        ...CONV_FOR_onnx::Resize_241_0.03079_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv           
        Concat_182                                          BPU  id(0)     Concat                     
        Conv_183                                            BPU  id(0)     HzSQuantizedConv           
        Mul_185                                             BPU  id(0)     HzLut                      
        Conv_186                                            BPU  id(0)     HzSQuantizedConv           
        Mul_188                                             BPU  id(0)     HzLut                      
        Conv_189                                            BPU  id(0)     HzSQuantizedConv           
        Mul_191                                             BPU  id(0)     HzLut                      
        Conv_192                                            BPU  id(0)     HzSQuantizedConv           
        Mul_194                                             BPU  id(0)     HzLut                      
        ...CONV_FOR_onnx::Concat_321_0.05753_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv           
        ...CONV_FOR_onnx::Concat_324_0.05753_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv           
        Concat_195                                          BPU  id(0)     Concat                     
        Conv_196                                            BPU  id(0)     HzSQuantizedConv           
        Mul_198                                             BPU  id(0)     HzLut                      
        Conv_199                                            BPU  id(0)     HzSQuantizedConv           
        Conv_201                                            BPU  id(0)     HzSQuantizedConv           
        Conv_203                                            BPU  id(0)     HzSQuantizedConv
        2023-01-10 19:05:05,716 INFO [Tue Jan 10 19:05:05 2023] End to Horizon NN Model Convert.
        2023-01-10 19:05:05,720 INFO ONNX model output num : 3
        2023-01-10 19:05:05,730 INFO End model checking....
        ```
        
3. åœ¨æ­¤åŸºç¡€ä¸Šï¼Œä¾æ¬¡è¿›è¡Œåç»­çš„ `02_preprocess.sh` ï¼Œ `03_build.sh` è„šæœ¬ï¼Œbuild è„šæœ¬è¾“å‡ºå¦‚ä¸‹ï¼š
    - build è„šæœ¬è¾“å‡ºï¼Œå¯è§ä¸å†äº§ç”Ÿ `Non-zero status code returned while running Reshape node` é—®é¢˜ã€‚
        
        ```bash
        cd $(dirname $0)
        
        MODEL_NAME=${1:-yolov5s}
        
        config_file="./configs/${MODEL_NAME}_config.yaml"
        model_type="onnx"
        
        # build model
        hb_mapper makertbin --config ${config_file}  \
                            --model-type ${model_type}
        /usr/local/lib/python3.6/site-packages/paramiko/transport.py:33: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography and will be removed in a future release.
          from cryptography.hazmat.backends import default_backend
        2023-01-10 19:23:43,399 INFO log will be stored in /open_explorer/smart_vision/hb_mapper_makertbin.log
        2023-01-10 19:23:43,399 INFO Start hb_mapper....
        2023-01-10 19:23:43,399 INFO hbdk version 3.41.4
        2023-01-10 19:23:43,399 INFO horizon_nn version 0.15.3
        2023-01-10 19:23:43,399 INFO hb_mapper version 1.13.3
        2023-01-10 19:23:43,399 INFO Start Model Convert....
        2023-01-10 19:23:43,406 INFO Using onnx model file: /open_explorer/smart_vision/models/yolov5s-latest.onnx
        2023-01-10 19:23:43,424 INFO Model has 1 inputs according to model file
        2023-01-10 19:23:43,424 INFO working_dir does not exist. Creating working_dir: /open_explorer/smart_vision/models/model_output
        2023-01-10 19:23:43,424 INFO Model name not given in yaml_file, using model name from model file: ['data']
        2023-01-10 19:23:43,424 INFO Model input shape not given in yaml_file, using shape from model file: [[1, 3, 672, 672]]
        2023-01-10 19:23:43,424 INFO nv12 input type rt received.
        2023-01-10 19:23:43,424 INFO custom_op does not exist, skipped
        2023-01-10 19:23:43,425 WARNING Input node data's input_source not set, it will be set to pyramid by default
        2023-01-10 19:23:43,426 WARNING Please note that the calibration file data type is set to float32, determined by the name of the calibration dir name suffix.
        2023-01-10 19:23:43,426 WARNING if you need to set it explicitly, please configure the value of cal_data_type in the calibration_parameters group in yaml.
        2023-01-10 19:23:43,426 INFO *******************************************
        2023-01-10 19:23:43,426 INFO First calibration picture name: COCO_val2014_000000181007.rgb
        2023-01-10 19:23:43,427 INFO First calibration picture md5:
        136bb23027c812cc2978395421fe6be7  /open_explorer/smart_vision/calibration_data_rgb_f32/COCO_val2014_000000181007.rgb
        2023-01-10 19:23:43,438 INFO *******************************************
        2023-01-10 19:23:45,370 INFO [Tue Jan 10 19:23:45 2023] Start to Horizon NN Model Convert.
        2023-01-10 19:23:45,370 INFO Parsing the input parameter:{'data': {'input_shape': [1, 3, 672, 672], 'expected_input_type': 'YUV444_128', 'original_input_type': 'RGB', 'original_input_layout': 'NCHW', 'scales': array([0.00392157], dtype=float32)}}
        2023-01-10 19:23:45,370 INFO Parsing the calibration parameter
        2023-01-10 19:23:45,370 INFO Parsing the hbdk parameter:{'hbdk_pass_through_params': '--O3 --core-num 1 --fast ', 'input-source': {'data': 'pyramid', '_default_value': 'ddr'}}
        2023-01-10 19:23:45,370 INFO HorizonNN version: 0.15.3
        2023-01-10 19:23:45,370 INFO HBDK version: 3.41.4
        2023-01-10 19:23:45,370 INFO [Tue Jan 10 19:23:45 2023] Start to parse the onnx model.
        2023-01-10 19:23:45,384 INFO Input ONNX model infomation:
        ONNX IR version:          6
        Opset version:            [11]
        Producer:                 pytorch1.12.1
        Domain:                   none
        Input name:               data, [1, 3, 672, 672]
        Output name:              output0, [1, 84, 84, 255]
        Output name:              332, [1, 42, 42, 255]
        Output name:              334, [1, 21, 21, 255]
        2023-01-10 19:23:45,479 INFO [Tue Jan 10 19:23:45 2023] End to parse the onnx model.
        2023-01-10 19:23:45,479 INFO Model input names parsed from model: ['data']
        2023-01-10 19:23:45,479 INFO Create a preprocessing operator for input_name data with means=None, std=[254.99998492], original_input_layout=NCHW, color convert from 'RGB' to 'YUV_BT601_FULL_RANGE'.
        2023-01-10 19:23:45,544 INFO Saving the original float model: yolov5s_672x672_nv12_original_float_model.onnx.
        2023-01-10 19:23:45,544 INFO [Tue Jan 10 19:23:45 2023] Start to optimize the model.
        2023-01-10 19:23:45,821 INFO [Tue Jan 10 19:23:45 2023] End to optimize the model.
        2023-01-10 19:23:45,834 INFO Saving the optimized model: yolov5s_672x672_nv12_optimized_float_model.onnx.
        2023-01-10 19:23:45,835 INFO [Tue Jan 10 19:23:45 2023] Start to calibrate the model.
        2023-01-10 19:23:45,835 INFO There are 50 samples in the calibration data set.
        2023-01-10 19:23:45,951 INFO Run calibration model with default calibration method.
        Default calibration in progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:28<00:00,  4.00s/it]
        2023-01-10 19:24:22,966 INFO Select kl method.
        2023-01-10 19:24:22,989 INFO [Tue Jan 10 19:24:22 2023] End to calibrate the model.
        2023-01-10 19:24:22,990 INFO [Tue Jan 10 19:24:22 2023] Start to quantize the model.
        2023-01-10 19:24:26,866 INFO input data is from pyramid. Its layout is set to NHWC
        2023-01-10 19:24:27,065 INFO [Tue Jan 10 19:24:27 2023] End to quantize the model.
        2023-01-10 19:24:27,232 INFO Saving the quantized model: yolov5s_672x672_nv12_quantized_model.onnx.
        2023-01-10 19:24:27,731 INFO [Tue Jan 10 19:24:27 2023] Start to compile the model with march bernoulli2.
        2023-01-10 19:24:27,956 INFO Compile submodel: torch_jit_subgraph_0
        2023-01-10 19:24:28,285 INFO hbdk-cc parameters:['--O3', '--core-num', '1', '--fast', '--input-layout', 'NHWC', '--output-layout', 'NHWC', '--input-source', 'pyramid']
        2023-01-10 19:24:28,317 INFO INFO: "-j" or "--jobs" is not specified, launch 16 threads for optimization
        2023-01-10 19:24:28,317 WARNING missing stride for pyramid input[0], use its aligned width by default.
        2023-01-10 19:24:28,453 INFO INFO: Layer "Mul_3" will be executed on CPU
        2023-01-10 19:24:28,453 INFO INFO: Layer "Mul_6" will be executed on CPU
        2023-01-10 19:24:28,453 INFO INFO: Layer "Mul_9" will be executed on CPU
        2023-01-10 19:24:28,453 INFO INFO: Layer "Mul_19" will be executed on CPU
        2023-01-10 19:24:28,453 INFO INFO: Layer "Mul_12" will be executed on CPU
        2023-01-10 19:24:28,453 INFO INFO: Layer "Mul_15" will be executed on CPU
        2023-01-10 19:24:28,453 INFO INFO: Layer "Mul_23" will be executed on CPU
        2023-01-10 19:24:28,453 INFO INFO: Layer "Mul_26" will be executed on CPU
        2023-01-10 19:24:28,454 INFO INFO: Layer "Mul_29" will be executed on CPU
        2023-01-10 19:24:28,454 INFO INFO: Layer "Mul_46" will be executed on CPU
        2023-01-10 19:24:28,454 INFO INFO: Layer "Mul_32" will be executed on CPU
        2023-01-10 19:24:28,454 INFO INFO: Layer "Mul_35" will be executed on CPU
        2023-01-10 19:24:28,454 INFO INFO: Layer "Mul_39" will be executed on CPU
        2023-01-10 19:24:28,454 INFO INFO: Layer "Mul_42" will be executed on CPU
        2023-01-10 19:24:28,454 INFO INFO: Layer "Mul_50" will be executed on CPU
        2023-01-10 19:24:28,454 INFO INFO: Layer "Mul_53" will be executed on CPU
        2023-01-10 19:24:28,454 INFO INFO: Layer "Mul_56" will be executed on CPU
        2023-01-10 19:24:28,454 INFO INFO: Layer "Mul_80" will be executed on CPU
        2023-01-10 19:24:28,454 INFO INFO: Layer "Mul_59" will be executed on CPU
        2023-01-10 19:24:28,455 INFO INFO: Layer "Mul_62" will be executed on CPU
        2023-01-10 19:24:28,455 INFO INFO: Layer "Mul_66" will be executed on CPU
        2023-01-10 19:24:28,455 INFO INFO: Layer "Mul_69" will be executed on CPU
        2023-01-10 19:24:28,455 INFO INFO: Layer "Mul_73" will be executed on CPU
        2023-01-10 19:24:28,455 INFO INFO: Layer "Mul_76" will be executed on CPU
        2023-01-10 19:24:28,455 INFO INFO: Layer "Mul_84" will be executed on CPU
        2023-01-10 19:24:28,455 INFO INFO: Layer "Mul_87" will be executed on CPU
        2023-01-10 19:24:28,455 INFO INFO: Layer "Mul_90" will be executed on CPU
        2023-01-10 19:24:28,455 INFO INFO: Layer "Mul_100" will be executed on CPU
        2023-01-10 19:24:28,455 INFO INFO: Layer "Mul_93" will be executed on CPU
        2023-01-10 19:24:28,455 INFO INFO: Layer "Mul_96" will be executed on CPU
        2023-01-10 19:24:28,455 INFO INFO: Layer "Mul_104" will be executed on CPU
        2023-01-10 19:24:28,456 INFO INFO: Layer "Mul_107" will be executed on CPU
        2023-01-10 19:24:28,456 INFO INFO: Layer "Mul_114" will be executed on CPU
        2023-01-10 19:24:28,456 INFO INFO: Layer "Mul_117" will be executed on CPU
        2023-01-10 19:24:28,456 INFO INFO: Layer "Mul_123" will be executed on CPU
        2023-01-10 19:24:28,456 INFO INFO: Layer "Mul_132" will be executed on CPU
        2023-01-10 19:24:28,456 INFO INFO: Layer "Mul_126" will be executed on CPU
        2023-01-10 19:24:28,456 INFO INFO: Layer "Mul_129" will be executed on CPU
        2023-01-10 19:24:28,456 INFO INFO: Layer "Mul_136" will be executed on CPU
        2023-01-10 19:24:28,456 INFO INFO: Layer "Mul_139" will be executed on CPU
        2023-01-10 19:24:28,456 INFO INFO: Layer "Mul_145" will be executed on CPU
        2023-01-10 19:24:28,456 INFO INFO: Layer "Mul_154" will be executed on CPU
        2023-01-10 19:24:28,456 INFO INFO: Layer "Mul_148" will be executed on CPU
        2023-01-10 19:24:28,456 INFO INFO: Layer "Mul_151" will be executed on CPU
        2023-01-10 19:24:28,457 INFO INFO: Layer "Mul_158" will be executed on CPU
        2023-01-10 19:24:28,457 INFO INFO: Layer "Mul_161" will be executed on CPU
        2023-01-10 19:24:28,457 INFO INFO: Layer "Mul_165" will be executed on CPU
        2023-01-10 19:24:28,457 INFO INFO: Layer "Mul_174" will be executed on CPU
        2023-01-10 19:24:28,457 INFO INFO: Layer "Mul_168" will be executed on CPU
        2023-01-10 19:24:28,457 INFO INFO: Layer "Mul_171" will be executed on CPU
        2023-01-10 19:24:28,457 INFO INFO: Layer "Mul_178" will be executed on CPU
        2023-01-10 19:24:28,457 INFO INFO: Layer "Mul_181" will be executed on CPU
        2023-01-10 19:24:28,457 INFO INFO: Layer "Mul_185" will be executed on CPU
        2023-01-10 19:24:28,457 INFO INFO: Layer "Mul_194" will be executed on CPU
        2023-01-10 19:24:28,457 INFO INFO: Layer "Mul_188" will be executed on CPU
        2023-01-10 19:24:28,457 INFO INFO: Layer "Mul_191" will be executed on CPU
        2023-01-10 19:24:28,457 INFO INFO: Layer "Mul_198" will be executed on CPU
        [==================================================] 100%
        2023-01-10 19:24:34,257 INFO consumed time 5.9439
        2023-01-10 19:24:34,328 WARNING Performance information does not include operators in the model running on the CPU (including HzLut whose shape is over 8192)
        2023-01-10 19:24:34,376 INFO FPS=18.71, latency = 53440.5 us   (see torch_jit_subgraph_0.html)
        2023-01-10 19:24:34,510 INFO [Tue Jan 10 19:24:34 2023] End to compile the model with march bernoulli2.
        2023-01-10 19:24:34,512 INFO The converted model node information:
        ============================================================================================================================================
        Node                                                ON   Subgraph  Type                       Cosine Similarity  Threshold                   
        ---------------------------------------------------------------------------------------------------------------------------------------------
        HZ_PREPROCESS_FOR_data                              BPU  id(0)     HzSQuantizedPreprocess     0.999625           127.000000                  
        Conv_1                                              BPU  id(0)     HzSQuantizedConv           0.998592           1.004736                    
        Mul_3                                               BPU  id(0)     HzLut                      0.998138           13.985225                   
        Conv_4                                              BPU  id(0)     HzSQuantizedConv           0.992651           13.985213                   
        Mul_6                                               BPU  id(0)     HzLut                      0.994966           16.703127                   
        Conv_7                                              BPU  id(0)     HzSQuantizedConv           0.990321           16.703127                   
        Mul_9                                               BPU  id(0)     HzLut                      0.998465           7.794779                    
        Conv_10                                             BPU  id(0)     HzSQuantizedConv           0.983401           7.791570                    
        Mul_12                                              BPU  id(0)     HzLut                      0.997777           8.028659                    
        Conv_13                                             BPU  id(0)     HzSQuantizedConv           0.991031           8.026042                    
        Mul_15                                              BPU  id(0)     HzLut                      0.992943           8.116323                    
        UNIT_CONV_FOR_Add_16                                BPU  id(0)     HzSQuantizedConv           0.995336           7.791570                    
        Conv_17                                             BPU  id(0)     HzSQuantizedConv           0.990945           16.703127                   
        Mul_19                                              BPU  id(0)     HzLut                      0.996793           17.747612                   
        ...CONV_FOR_onnx::Concat_143_0.06933_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv                                                          
        Concat_20                                           BPU  id(0)     Concat                     0.995108           8.804478                    
        Conv_21                                             BPU  id(0)     HzSQuantizedConv           0.985998           8.804478                    
        Mul_23                                              BPU  id(0)     HzLut                      0.992025           7.598925                    
        Conv_24                                             BPU  id(0)     HzSQuantizedConv           0.991117           7.595119                    
        Mul_26                                              BPU  id(0)     HzLut                      0.991777           5.766149                    
        Conv_27                                             BPU  id(0)     HzSQuantizedConv           0.994640           5.748147                    
        Mul_29                                              BPU  id(0)     HzLut                      0.996433           3.026174                    
        Conv_30                                             BPU  id(0)     HzSQuantizedConv           0.994104           2.886191                    
        Mul_32                                              BPU  id(0)     HzLut                      0.995512           4.508018                    
        Conv_33                                             BPU  id(0)     HzSQuantizedConv           0.993648           4.458879                    
        Mul_35                                              BPU  id(0)     HzLut                      0.994182           3.558093                    
        UNIT_CONV_FOR_Add_36                                BPU  id(0)     HzSQuantizedConv           0.994743           2.886191                    
        Conv_37                                             BPU  id(0)     HzSQuantizedConv           0.991709           2.473211                    
        Mul_39                                              BPU  id(0)     HzLut                      0.989208           4.479204                    
        Conv_40                                             BPU  id(0)     HzSQuantizedConv           0.992944           4.428968                    
        Mul_42                                              BPU  id(0)     HzLut                      0.994286           6.980838                    
        UNIT_CONV_FOR_Add_43                                BPU  id(0)     HzSQuantizedConv           0.995198           2.473211                    
        Conv_44                                             BPU  id(0)     HzSQuantizedConv           0.990863           5.748147                    
        Mul_46                                              BPU  id(0)     HzLut                      0.990956           4.114643                    
        ...CONV_FOR_onnx::Concat_170_0.04494_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv                                                          
        Concat_47                                           BPU  id(0)     Concat                     0.993840           5.707380                    
        Conv_48                                             BPU  id(0)     HzSQuantizedConv           0.994418           5.707380                    
        Mul_50                                              BPU  id(0)     HzLut                      0.991736           5.388514                    
        Conv_51                                             BPU  id(0)     HzSQuantizedConv           0.993635           5.364007                    
        Mul_53                                              BPU  id(0)     HzLut                      0.986075           7.765623                    
        Conv_54                                             BPU  id(0)     HzSQuantizedConv           0.996115           7.762331                    
        Mul_56                                              BPU  id(0)     HzLut                      0.990948           3.816494                    
        Conv_57                                             BPU  id(0)     HzSQuantizedConv           0.987893           3.734321                    
        Mul_59                                              BPU  id(0)     HzLut                      0.986812           5.819736                    
        Conv_60                                             BPU  id(0)     HzSQuantizedConv           0.990948           5.802512                    
        Mul_62                                              BPU  id(0)     HzLut                      0.981153           5.626144                    
        UNIT_CONV_FOR_Add_63                                BPU  id(0)     HzSQuantizedConv           0.985675           3.734321                    
        Conv_64                                             BPU  id(0)     HzSQuantizedConv           0.986720           2.895749                    
        Mul_66                                              BPU  id(0)     HzLut                      0.977147           6.111077                    
        Conv_67                                             BPU  id(0)     HzSQuantizedConv           0.978817           6.097551                    
        Mul_69                                              BPU  id(0)     HzLut                      0.974796           6.300752                    
        UNIT_CONV_FOR_Add_70                                BPU  id(0)     HzSQuantizedConv           0.978137           2.895749                    
        Conv_71                                             BPU  id(0)     HzSQuantizedConv           0.985211           4.546500                    
        Mul_73                                              BPU  id(0)     HzLut                      0.971530           6.672524                    
        Conv_74                                             BPU  id(0)     HzSQuantizedConv           0.964964           6.664093                    
        Mul_76                                              BPU  id(0)     HzLut                      0.966502           10.009397                   
        UNIT_CONV_FOR_Add_77                                BPU  id(0)     HzSQuantizedConv           0.969769           4.546500                    
        Conv_78                                             BPU  id(0)     HzSQuantizedConv           0.988043           7.762331                    
        Mul_80                                              BPU  id(0)     HzLut                      0.986741           5.253876                    
        ...CONV_FOR_onnx::Concat_204_0.03503_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv                                                          
        Concat_81                                           BPU  id(0)     Concat                     0.973960           4.448520                    
        Conv_82                                             BPU  id(0)     HzSQuantizedConv           0.987208           4.448520                    
        Mul_84                                              BPU  id(0)     HzLut                      0.973802           6.913193                    
        Conv_85                                             BPU  id(0)     HzSQuantizedConv           0.981681           6.906324                    
        Mul_87                                              BPU  id(0)     HzLut                      0.965594           9.224026                    
        Conv_88                                             BPU  id(0)     HzSQuantizedConv           0.992448           9.223116                    
        Mul_90                                              BPU  id(0)     HzLut                      0.988430           5.606626                    
        Conv_91                                             BPU  id(0)     HzSQuantizedConv           0.968618           5.586105                    
        Mul_93                                              BPU  id(0)     HzLut                      0.958150           10.471902                   
        Conv_94                                             BPU  id(0)     HzSQuantizedConv           0.969298           10.471604                   
        Mul_96                                              BPU  id(0)     HzLut                      0.964260           10.146297                   
        UNIT_CONV_FOR_Add_97                                BPU  id(0)     HzSQuantizedConv           0.964661           5.586105                    
        Conv_98                                             BPU  id(0)     HzSQuantizedConv           0.975004           9.223116                    
        Mul_100                                             BPU  id(0)     HzLut                      0.962438           9.911333                    
        ...CONV_FOR_onnx::Concat_224_0.03322_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv                                                          
        Concat_101                                          BPU  id(0)     Concat                     0.963729           4.219078                    
        Conv_102                                            BPU  id(0)     HzSQuantizedConv           0.972310           4.219078                    
        Mul_104                                             BPU  id(0)     HzLut                      0.959204           9.914267                    
        Conv_105                                            BPU  id(0)     HzSQuantizedConv           0.977106           9.913776                    
        Mul_107                                             BPU  id(0)     HzLut                      0.982392           6.799733                    
        MaxPool_108                                         BPU  id(0)     HzQuantizedMaxPool         0.993679           6.792165                    
        MaxPool_109                                         BPU  id(0)     HzQuantizedMaxPool         0.996352           6.792165                    
        MaxPool_110                                         BPU  id(0)     HzQuantizedMaxPool         0.997350           6.792165                    
        ...ONV_FOR_onnx::MaxPool_231_0.06787_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv                                                          
        ...ONV_FOR_onnx::MaxPool_232_0.06787_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv                                                          
        ...ONV_FOR_onnx::MaxPool_233_0.06787_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv                                                          
        ...CONV_FOR_onnx::Concat_234_0.06787_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv                                                          
        Concat_111                                          BPU  id(0)     Concat                     0.995251           6.792165                    
        Conv_112                                            BPU  id(0)     HzSQuantizedConv           0.988744           8.619161                    
        Mul_114                                             BPU  id(0)     HzLut                      0.972662           8.022479                    
        Conv_115                                            BPU  id(0)     HzSQuantizedConv           0.980147           8.019848                    
        Mul_117                                             BPU  id(0)     HzLut                      0.965953           8.967721                    
        Resize_119                                          BPU  id(0)     HzQuantizedResizeUpsample  0.965893           8.966578                    
        ...CONV_FOR_onnx::Concat_246_0.01916_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv                                                          
        UNIT_CONV_FOR_onnx::Conv_208_0.01916_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv                                                          
        Concat_120                                          BPU  id(0)     Concat                     0.963391           8.966578                    
        Conv_121                                            BPU  id(0)     HzSQuantizedConv           0.986149           2.433284                    
        Mul_123                                             BPU  id(0)     HzLut                      0.983297           6.423621                    
        Conv_124                                            BPU  id(0)     HzSQuantizedConv           0.979580           6.413213                    
        Mul_126                                             BPU  id(0)     HzLut                      0.976023           6.405385                    
        Conv_127                                            BPU  id(0)     HzSQuantizedConv           0.972830           6.394816                    
        Mul_129                                             BPU  id(0)     HzLut                      0.967925           7.185949                    
        Conv_130                                            BPU  id(0)     HzSQuantizedConv           0.976136           2.433284                    
        Mul_132                                             BPU  id(0)     HzLut                      0.969723           6.963424                    
        ...CONV_FOR_onnx::Concat_256_0.01522_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv                                                          
        ...CONV_FOR_onnx::Concat_259_0.01522_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv                                                          
        Concat_133                                          BPU  id(0)     Concat                     0.957710           7.180512                    
        Conv_134                                            BPU  id(0)     HzSQuantizedConv           0.954683           1.933006                    
        Mul_136                                             BPU  id(0)     HzLut                      0.945891           9.066763                    
        Conv_137                                            BPU  id(0)     HzSQuantizedConv           0.953563           9.065717                    
        Mul_139                                             BPU  id(0)     HzLut                      0.965812           7.352169                    
        Resize_141                                          BPU  id(0)     HzQuantizedResizeUpsample  0.965765           7.347457                    
        ...CONV_FOR_onnx::Concat_271_0.02880_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv                                                          
        UNIT_CONV_FOR_onnx::Conv_174_0.02880_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv                                                          
        Concat_142                                          BPU  id(0)     Concat                     0.974294           7.347457                    
        Conv_143                                            BPU  id(0)     HzSQuantizedConv           0.989032           3.657588                    
        Mul_145                                             BPU  id(0)     HzLut                      0.992494           6.087980                    
        Conv_146                                            BPU  id(0)     HzSQuantizedConv           0.989104           6.074192                    
        Mul_148                                             BPU  id(0)     HzLut                      0.992540           5.660322                    
        Conv_149                                            BPU  id(0)     HzSQuantizedConv           0.975980           5.640685                    
        Mul_151                                             BPU  id(0)     HzLut                      0.978878           9.938995                    
        Conv_152                                            BPU  id(0)     HzSQuantizedConv           0.976293           3.657588                    
        Mul_154                                             BPU  id(0)     HzLut                      0.978075           7.166039                    
        ...CONV_FOR_onnx::Concat_281_0.03712_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv                                                          
        ...CONV_FOR_onnx::Concat_284_0.03712_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv                                                          
        Concat_155                                          BPU  id(0)     Concat                     0.978210           9.938516                    
        Conv_156                                            BPU  id(0)     HzSQuantizedConv           0.944852           4.713646                    
        Mul_158                                             BPU  id(0)     HzLut                      0.956471           24.037889                   
        Conv_159                                            BPU  id(0)     HzSQuantizedConv           0.948493           24.037889                   
        Mul_161                                             BPU  id(0)     HzLut                      0.945453           7.151889                    
        ...CONV_FOR_onnx::Concat_291_0.04806_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv                                                          
        ...CONV_FOR_onnx::Resize_266_0.04806_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv                                                          
        Concat_162                                          BPU  id(0)     Concat                     0.955909           7.146291                    
        Conv_163                                            BPU  id(0)     HzSQuantizedConv           0.945652           6.103609                    
        Mul_165                                             BPU  id(0)     HzLut                      0.938230           7.221455                    
        Conv_166                                            BPU  id(0)     HzSQuantizedConv           0.962912           7.216181                    
        Mul_168                                             BPU  id(0)     HzLut                      0.956445           6.634083                    
        Conv_169                                            BPU  id(0)     HzSQuantizedConv           0.953755           6.625372                    
        Mul_171                                             BPU  id(0)     HzLut                      0.951723           10.860644                   
        Conv_172                                            BPU  id(0)     HzSQuantizedConv           0.950328           6.103609                    
        Mul_174                                             BPU  id(0)     HzLut                      0.955650           6.775457                    
        ...CONV_FOR_onnx::Concat_301_0.03780_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv                                                          
        ...CONV_FOR_onnx::Concat_304_0.03780_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv                                                          
        Concat_175                                          BPU  id(0)     Concat                     0.953305           10.860435                   
        Conv_176                                            BPU  id(0)     HzSQuantizedConv           0.929372           4.801002                    
        Mul_178                                             BPU  id(0)     HzLut                      0.941431           21.555998                   
        Conv_179                                            BPU  id(0)     HzSQuantizedConv           0.943251           21.555998                   
        Mul_181                                             BPU  id(0)     HzLut                      0.933456           8.890406                    
        ...CONV_FOR_onnx::Concat_311_0.02306_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv                                                          
        ...CONV_FOR_onnx::Resize_241_0.02306_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv                                                          
        Concat_182                                          BPU  id(0)     Concat                     0.943703           8.889181                    
        Conv_183                                            BPU  id(0)     HzSQuantizedConv           0.946935           2.928516                    
        Mul_185                                             BPU  id(0)     HzLut                      0.931021           8.757660                    
        Conv_186                                            BPU  id(0)     HzSQuantizedConv           0.937357           8.756283                    
        Mul_188                                             BPU  id(0)     HzLut                      0.918907           10.897411                   
        Conv_189                                            BPU  id(0)     HzSQuantizedConv           0.937940           10.897210                   
        Mul_191                                             BPU  id(0)     HzLut                      0.925729           12.400668                   
        Conv_192                                            BPU  id(0)     HzSQuantizedConv           0.952533           2.928516                    
        Mul_194                                             BPU  id(0)     HzLut                      0.952878           8.299829                    
        ...CONV_FOR_onnx::Concat_321_0.03825_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv                                                          
        ...CONV_FOR_onnx::Concat_324_0.03825_TO_FUSE_SCALE  BPU  id(0)     HzSQuantizedConv                                                          
        Concat_195                                          BPU  id(0)     Concat                     0.939141           12.400617                   
        Conv_196                                            BPU  id(0)     HzSQuantizedConv           0.936492           4.857968                    
        Mul_198                                             BPU  id(0)     HzLut                      0.948842           16.812071                   
        Conv_199                                            BPU  id(0)     HzSQuantizedConv           0.997939           24.037889                   
        Conv_201                                            BPU  id(0)     HzSQuantizedConv           0.998180           21.555998                   
        Conv_203                                            BPU  id(0)     HzSQuantizedConv           0.998646           16.812071
        2023-01-10 19:24:34,513 INFO [Tue Jan 10 19:24:34 2023] End to Horizon NN Model Convert.
        2023-01-10 19:24:34,587 INFO start convert to *.bin file....
        2023-01-10 19:24:34,616 INFO ONNX model output num : 3
        2023-01-10 19:24:34,621 INFO ############# model deps info #############
        2023-01-10 19:24:34,621 INFO hb_mapper version   : 1.13.3
        2023-01-10 19:24:34,621 INFO hbdk version        : 3.41.4
        2023-01-10 19:24:34,621 INFO hbdk runtime version: 3.15.7.0
        2023-01-10 19:24:34,621 INFO horizon_nn version  : 0.15.3
        2023-01-10 19:24:34,621 INFO ############# model_parameters info #############
        2023-01-10 19:24:34,621 INFO onnx_model          : /open_explorer/smart_vision/models/yolov5s-latest.onnx
        2023-01-10 19:24:34,621 INFO BPU march           : bernoulli2
        2023-01-10 19:24:34,621 INFO layer_out_dump      : False
        2023-01-10 19:24:34,621 INFO log_level           : DEBUG
        2023-01-10 19:24:34,621 INFO working dir         : /open_explorer/smart_vision/models/model_output
        2023-01-10 19:24:34,621 INFO output_model_file_prefix: yolov5s_672x672_nv12
        2023-01-10 19:24:34,621 INFO ############# input_parameters info #############
        2023-01-10 19:24:34,621 INFO ------------------------------------------
        2023-01-10 19:24:34,621 INFO ---------input info : data ---------
        2023-01-10 19:24:34,621 INFO input_name          : data
        2023-01-10 19:24:34,621 INFO input_type_rt       : nv12
        2023-01-10 19:24:34,621 INFO input_space&range   : regular
        2023-01-10 19:24:34,621 INFO input_layout_rt     : None
        2023-01-10 19:24:34,621 INFO input_type_train    : rgb
        2023-01-10 19:24:34,621 INFO input_layout_train  : NCHW
        2023-01-10 19:24:34,621 INFO norm_type           : data_scale
        2023-01-10 19:24:34,621 INFO input_shape         : 1x3x672x672
        2023-01-10 19:24:34,622 INFO scale_value         : 0.003921568627451,
        2023-01-10 19:24:34,622 INFO cal_data_dir        : /open_explorer/smart_vision/calibration_data_rgb_f32
        2023-01-10 19:24:34,622 INFO ---------input info : data end -------
        2023-01-10 19:24:34,622 INFO ------------------------------------------
        2023-01-10 19:24:34,622 INFO ############# calibration_parameters info #############
        2023-01-10 19:24:34,622 INFO preprocess_on       : False
        2023-01-10 19:24:34,622 INFO calibration_type:   : default
        2023-01-10 19:24:34,622 INFO ############# compiler_parameters info #############
        2023-01-10 19:24:34,622 INFO hbdk_pass_through_params: --O3 --core-num 1 --fast
        2023-01-10 19:24:34,622 INFO input-source        : {'data': 'pyramid', '_default_value': 'ddr'}
        2023-01-10 19:24:34,626 INFO Convert to runtime bin file sucessfully!
        2023-01-10 19:24:34,626 INFO End Model Convert
        ```
        
4. æœ€åä½¿ç”¨ `04_inference.sh` è¿›è¡Œæ¨æ–­ï¼Œ**èƒ½å¤Ÿå¾—åˆ°æ­£ç¡®æ¨æ–­ç»“æœï¼**
    
    ![ç›¸æ¯”äºv2.0æ¨¡å‹çš„è¯†åˆ«ç»“æœï¼Œèƒ½å¤Ÿè¯†åˆ«é è¿‘æ ‘æ¢¢çš„kite](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/e917c1e0-3563-4bdd-ad15-d679965548f9/demo.jpg)
    
    ç›¸æ¯”äºv2.0æ¨¡å‹çš„è¯†åˆ«ç»“æœï¼Œèƒ½å¤Ÿè¯†åˆ«é è¿‘æ ‘æ¢¢çš„kite
    

# YOLOv5è‡ªå®šä¹‰æ¨¡å‹è®­ç»ƒ

æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼š

> The commands below reproduce YOLOv5Â [COCO](https://github.com/ultralytics/yolov5/blob/master/data/scripts/get_coco.sh)Â results.Â [Models](https://github.com/ultralytics/yolov5/tree/master/models)Â andÂ [datasets](https://github.com/ultralytics/yolov5/tree/master/data)Â download automatically from the latest YOLOv5Â [release](https://github.com/ultralytics/yolov5/releases). Training times for YOLOv5n/s/m/l/x are 1/2/4/6/8 days on a V100 GPU ([Multi-GPU](https://github.com/ultralytics/yolov5/issues/475)Â times faster). Use the largestÂ `--batch-size`Â possible, or passÂ `--batch-size -1`Â for YOLOv5Â [AutoBatch](https://github.com/ultralytics/yolov5/pull/5092). Batch sizes shown for V100-16GB.
> 

```bash
python train.py --data coco.yaml --epochs 300 --weights '' --cfg yolov5n.yaml  --batch-size 128
                                                                 yolov5s                    64
                                                                 yolov5m                    40
                                                                 yolov5l                    24
                                                                 yolov5x                    16
```

ä½¿ç”¨V100åŸºäºCOCOæ•°æ®é›†è®­ç»ƒ `yolov5s` çš„æ‰¹å°ºå¯¸ä¸º64ï¼Œæ—¶é—´ä¸º2å¤©ã€‚æ ¹æ®GPUæ€§èƒ½å¯¹æ¯”ï¼š[https://technical.city/en/video/GeForce-RTX-3090-vs-Tesla-V100-PCIe](https://technical.city/en/video/GeForce-RTX-3090-vs-Tesla-V100-PCIe)ï¼Œ 3090æ€§èƒ½æ›´å¥½ï¼Œæ˜¾å­˜æ›´å¤§ï¼ˆ24GB vs 16GBï¼‰ï¼Œåœ¨æœåŠ¡å™¨ä¸Šè¿›è¡Œè®­ç»ƒçš„è€—æ—¶æˆ–å°äºå®˜æ–¹æ•°æ®ã€‚

å®é™…åœ¨å®éªŒå®¤æœåŠ¡å™¨ä¸Šè¿›è¡Œè®­ç»ƒï¼Œéœ€è¦å¯¹è®­ç»ƒè„šæœ¬è¾“å…¥å‚æ•°è¿›è¡Œè°ƒæ•´ã€‚

1. é¦–å…ˆï¼Œå¦‚æœæŒ‡å®š `weights` ï¼Œåˆ™ä¼šå°†å…¶ä½œä¸ºé¢„è®­ç»ƒæƒé‡ï¼Œå¦åˆ™æ ¹æ® `cfg` æ‰€ç»™å®šçš„æ¨¡å‹ç»“æ„ä»å¤´å¼€å§‹è®­ç»ƒã€‚è‡ªå®šä¹‰æ¨¡å‹çš„è®­ç»ƒä¸å¿…ä»å¤´å¼€å§‹ï¼›
2. å¯ä»¥ä½¿ç”¨ `--device 1` ç‰¹åˆ«æŒ‡å®šä½¿ç”¨ç¬¬äºŒä¸ªGPUï¼›
3. é»˜è®¤è®­ç»ƒçš„æ¨¡å‹ç»“æ„æ˜¯çŸ©å½¢æ¡†æ£€æµ‹ç½‘ç»œã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œ `--rect` å‚æ•°çš„å«ä¹‰æ˜¯ä½¿ç”¨çŸ©å½¢ï¼ˆè€Œä¸æ˜¯é»˜è®¤çš„æ­£æ–¹å½¢ï¼‰å›¾åƒä½œä¸ºè¾“å…¥ï¼›è¯¥é€‰é¡¹é»˜è®¤ä¸º Falseï¼›
https://github.com/ultralytics/yolov5/issues/2009
4. ä½¿ç”¨é»˜è®¤çš„ `batch_size=16` ï¼Œæ˜¾å­˜ä½¿ç”¨ä¸º 5.541GBï¼Œä¼°ç®—åœ¨3090ä¸Šå¯ä»¥ä½¿ç”¨çš„æœ€å¤§æ‰¹é‡ä¸º64ã€‚

## å‡†å¤‡è‡ªå®šä¹‰æ•°æ®é›†

[Combined Object Detection Dataset (v1, 2022-11-23 7:30am) by Y3IndividualProject](https://universe.roboflow.com/y3individualproject/combined-yizo3/dataset/1)

æ‰€å¾—æ•°æ®é›†æ–‡ä»¶å¤¹ä¸­åº”åŒ…æ‹¬ä¸€ä¸ªyamlæ–‡ä»¶ï¼Œå…¶ä¸­åº”æŒ‡å®štrain, valid, testä¸‰ç»„æ–‡ä»¶å¤¹çš„ä½ç½®ã€‚è¿™é‡Œä¸‹è½½çš„æ•°æ®é›†ä»…åŒ…å«train setï¼Œæ•…å°†å…¶å¤åˆ¶ä¸¤ä»½å¹¶åˆ†åˆ«ä½œä¸º valid, testï¼Œå¯¹yamlä¸­å®šä¹‰çš„æ•°æ®é›†è·¯å¾„ç›¸åº”è¿›è¡Œä¿®æ”¹ã€‚

## å¼€å§‹è®­ç»ƒ

æˆ‘ä»¬å·²åœ¨ä»¥ä¸‹è½¯ä»¶åŒ…ä¸­å®ç°è‡ªå®šä¹‰æ•°æ®é›†è®­ç»ƒï¼Œå¯å‚è€ƒå…¶å†…å®¹ï¼š

[](https://github.com/SOTA-Robotics/yolov5/blob/main/SOTA-README.md)

## PTæ¨¡å‹è½¬æ¢ä¸ºONNX

åŸºæœ¬æµç¨‹ä¸ä¹‹å‰è½¬æ¢å®˜æ–¹æ¨¡å‹ç›¸åŒï¼Œå‚è€ƒä¸Šè¿°é“¾æ¥ã€‚

# YOLOv5è‡ªå®šä¹‰æ¨¡å‹è½¬æ¢

æ–¹æ³•ä¸éƒ¨ç½²å®˜æ–¹æ¨¡å‹åŸºæœ¬ç±»ä¼¼ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯æ•°æ®é›†ä¸åŒï¼Œéœ€è¯†åˆ«çš„ç±»åˆ«ä¹Ÿä¸åŒï¼Œç”±æ­¤éœ€è¦å¯¹æºä»£ç è¿›è¡Œéƒ¨åˆ†ä¿®æ”¹ã€‚æˆ‘ä»¬ç›®å‰å·²åœ¨SmartVisionä¸­å®ç°ç›¸å…³ä»£ç ï¼Œæ¨¡å‹è½¬æ¢æµç¨‹å‚è§å…¶READMEï¼š
https://github.com/SOTA-Robotics/SmartVision

# æ¿ç«¯è¿è¡Œè½¬æ¢çš„æ¨¡å‹

```bash
class hobot_dnn.pyeasy_dnn.TensorProperties
Parametersï¼š
    1ã€tensor_type (string)ï¼šè¡¨ç¤ºtensorçš„æ•°æ®ç±»å‹ï¼Œä¾‹å¦‚ï¼šNV12ã€BGRã€float32ç­‰
    2ã€dtype (string)ï¼šè¡¨ç¤ºæ•°æ®çš„å­˜å‚¨ç±»å‹ï¼ŒåŒnumpyæ•°æ®ç±»å‹ï¼Œä¾‹å¦‚ï¼šint8ã€uint8ã€float32ç­‰
    3ã€layout (string)ï¼šè¡¨ç¤ºæ•°æ®æ’å¸ƒæ ¼å¼ï¼ŒNHWCæˆ–è€…NCHW
    4ã€shape (tuple)ï¼šè¡¨ç¤ºå­˜å‚¨æ•°æ®çš„shapeä¿¡æ¯ï¼Œä¾‹å¦‚ï¼š(1,3,224,224)
```

```bash
class hobot_dnn.pyeasy_dnn.pyDNNTensor
Parametersï¼š
    1ã€properties (TensorProperties)ï¼šè¡¨ç¤ºæ¨¡å‹tensorçš„å±æ€§ï¼Œè¯¦ç»†å‚è§ `class hobot_dnn.pyeasy_dnn.TensorProperties` 
    2ã€buffer (numpy)ï¼šè¡¨ç¤ºæ¨¡å‹tensorä¸­çš„æ•°æ®ï¼Œæ•°æ®è®¿é—®æ–¹å¼åŒnumpy
    3ã€name (string)ï¼šè¡¨ç¤ºæ¨¡å‹tensorçš„åç§°
```

```bash
class hobot_dnn.pyeasy_dnn.Model
Parametersï¼š
    1ã€name (string)ï¼šè¡¨ç¤ºæ¨¡å‹åç§°
    2ã€inputs (tuple(pyDNNTensor))ï¼šè¡¨ç¤ºæ¨¡å‹çš„è¾“å…¥tensorä¿¡æ¯
    3ã€outputs (tuple(pyDNNTensor))ï¼šè¡¨ç¤ºæ¨¡å‹çš„è¾“å‡ºtensorä¿¡æ¯
    4ã€forward (args &args, kwargs &kwargs)ï¼šæ¨¡å‹æ¨ç†å‡½æ•°æ¥å£ï¼Œè¾“å…¥æ¨¡å‹æ¨ç†æ‰€å¿…è¦çš„å‚æ•°ï¼Œè¿”å›æ¨¡å‹æ¨ç†ç»“æœ
        parametersï¼š
            args: æä¾›ä¸‰ç§å½¢å¼çš„tensorè¾“å…¥ï¼Œè¯¦ç»†ä½¿ç”¨å‚è€ƒæ–‡æœ«ç¤ºä¾‹ï¼Œæˆ–è€…SDKçš„ç¤ºä¾‹è„šæœ¬
                éresizeræ¨¡å‹ï¼š
                    a. numpyï¼šå•è¾“å…¥æ¨¡å‹åœºæ™¯ï¼Œç›´æ¥æä¾›numpyæ•°æ®è¿›è¡Œæ¨ç†
                    b. list[numpy, numpy, ...]ï¼šå¤šè¾“å…¥æ¨¡å‹åœºæ™¯ï¼Œå°†numpyæ•°æ®æ‰“åŒ…æˆlistï¼Œlisté•¿åº¦åº”å½“ä¸ºæ¨¡å‹çš„è¾“å…¥ä¸ªæ•°
                resizeræ¨¡å‹ï¼š
                    a. list[list[numpy, list], list[numpy, list], ...]ï¼šå°†numpyæ•°æ®ä¸roiæ¡†çš„ä¿¡æ¯æ‰“åŒ…æˆä¸€ä¸ªlistï¼Œä½œä¸ºä¸€ä¸ªtensorè¾“å…¥ï¼Œå¤šä¸ªtensoræ‰“åŒ…æˆä¸€ä¸ªlistï¼Œä½œä¸ºæ¨¡å‹æ•´ä½“è¾“å…¥
            kwargsï¼šcore_id (int)ï¼šè¡¨ç¤ºæ¨¡å‹æ¨ç†çš„core idï¼Œå¯ä¸º0,1,2ï¼Œé»˜è®¤ä¸º0è¡¨ç¤ºä»»æ„æ ¸æ¨ç†ã€‚
            kwargsï¼špriority (int)ï¼šè¡¨ç¤ºå½“å‰æ¨¡å‹æ¨ç†ä»»åŠ¡çš„ä¼˜å…ˆçº§ï¼ŒèŒƒå›´[0~255]ï¼Œè¶Šå¤§ä¼˜å…ˆçº§è¶Šé«˜ã€‚
        returns: æ¥å£è¿”å›æ¨¡å‹è¾“å‡ºç»“æœ
            éresizeræ¨¡å‹ï¼š
                a. è¾“å‡ºä¸ºä¸€ç»´tuple: tuple(pyDNNTensor)ï¼Œtupleé•¿åº¦ä¸ºæ¨¡å‹è¾“å‡ºä¸ªæ•°; 
            resizeræ¨¡å‹ï¼š
                a. è¾“å‡ºä¸ºäºŒç»´tuple: tuple(tupe(pyDNNTensor))ï¼Œlen(output)é•¿åº¦ä¸ºroiçš„æ•°é‡ï¼Œlen(output[0])é•¿åº¦ä¸ºæ¨¡å‹å•ä¸ªroiè¾“å‡ºæ•°é‡ã€‚
```

[5.3. BPU ç®—æ³•æ¨ç† - æ—­æ—¥X3æ´¾ç”¨æˆ·æ‰‹å†Œ 1.0.0 æ–‡æ¡£](https://developer.horizon.ai/api/v1/fileData/html/Python_devolep/python_dnn.html)

# æ¿ç«¯è¿è¡Œä¼˜åŒ–

[](https://developer.horizon.ai/forumDetail/136488103547258549)

## æ ¡å‡†æ•°æ®æ•°é‡å¯¹ç²¾åº¦çš„å½±å“

ä¸ºéªŒè¯æ ¡å‡†æ•°æ®æ•°é‡å¯¹é‡åŒ–æ¨¡å‹çš„ç²¾åº¦æ˜¯å¦äº§ç”Ÿå½±å“ï¼Œé’ˆå¯¹åœ¨combinedæ•°æ®é›†ä¸Šè®­ç»ƒå¾—åˆ°çš„æ¨¡å‹ï¼Œåˆ†åˆ«ä½¿ç”¨ä¸åŒæ•°é‡çš„æ ¡å‡†å›¾ç‰‡ï¼ŒåŒæ ·åœ¨can.jpgä¸Šè¿›è¡Œæ¨ç†æµ‹è¯•ï¼Œè¯„ä¼°æ•°æ®é‡å¯¹é‡åŒ–ç½®ä¿¡åº¦çš„å½±å“ï¼ˆåŸå§‹æ¨¡å‹ç½®ä¿¡åº¦ä¸º0.4798ï¼‰ï¼š

| æ ¡å‡†å›¾åƒæ•°é‡ | 1 | 5 | 20 | 25 | 50 | 75 | 100-1ï¼ˆå°†åŸ50ç»„å›¾ç‰‡å¤åˆ¶ä¸€ä»½ï¼‰ | 100-2ï¼ˆäº’ä¸ç›¸åŒï¼Œä½†åŒ…å«åŸ50å¼ ï¼‰ | 100-3ï¼ˆä¸åŒ…å«åŸ50å¼ ï¼‰ |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| é‡åŒ–æ¨¡å‹ç½®ä¿¡åº¦ | 0.4387 | 0.4739 |  | 0.4482 | 0.4438 | 0.4359 | 0.4766 | 0.4386 | 0.4462 |

![75](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/f1a2b97d-1ef3-4c5c-af54-5bd79b924bfa/demo.jpg)

75

![100-2](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/8bf8d5b3-577c-4404-921f-c4c5071ea15e/demo.jpg)

100-2

![100-3](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/73fe32cd-12b5-4c66-b2ce-097b90630872/demo.jpg)

100-3

<aside>
âš ï¸ æ¨¡å‹é‡åŒ–çš„å‚è€ƒå›¾åƒçš„å­˜æ”¾ç›®å½•ï¼Œå›¾ç‰‡æ ¼å¼æ”¯æŒJpegã€Bmpç­‰æ ¼å¼ï¼Œè¾“å…¥çš„å›¾ç‰‡åº”è¯¥æ˜¯ä½¿ç”¨çš„å…¸å‹åœºæ™¯ï¼Œä¸€èˆ¬æ˜¯ä»æµ‹è¯•é›†ä¸­é€‰æ‹©20~100å¼ å›¾ç‰‡ï¼Œå¦å¤–è¾“å…¥çš„å›¾ç‰‡è¦è¦†ç›–å…¸å‹åœºæ™¯ï¼Œä¸è¦æ˜¯ååƒ»åœºæ™¯ï¼Œå¦‚è¿‡æ›å…‰ã€é¥±å’Œã€æ¨¡ç³Šã€çº¯é»‘ã€çº¯ç™½ç­‰å›¾ç‰‡è‹¥æœ‰å¤šä¸ªè¾“å…¥èŠ‚ç‚¹, åˆ™åº”ä½¿ç”¨';'è¿›è¡Œåˆ†éš”

</aside>

<aside>
âš ï¸ å®éªŒå‘ç°ï¼Œåœ¨æŒ‡å®šæ–‡ä»¶å¤¹ä¸­æ”¾ç½®100å¼ ä»¥ä¸Šå›¾ç‰‡ï¼Œåªèƒ½å°†å…¶ä¸­100å¼ è½¬æ¢ä¸ºæ ‡å®šæ•°æ®ã€‚

</aside>

ä»ä»¥ä¸Šå®éªŒç»“æœå¯å¾—å‡ºåˆæ­¥ç»“è®ºï¼š

1. æ ¡å‡†æ•°æ®æ•°é‡è¶Šå¤§ï¼Œåœ¨ç‰¹å®šå›¾ç‰‡ä¸Šå–å¾—çš„ç½®ä¿¡åº¦ä¸€èˆ¬è¶Šä½ï¼ŒåŸå› å¯èƒ½æ˜¯è¦é’ˆå¯¹æ›´å¤šçš„å›¾ç‰‡è°ƒä¼˜ï¼Œåœ¨æ¨¡å‹å‚æ•°ä¸Šä¼šå‡ºç°æ‘‡æ‘†ã€‚
2. æ ¡å‡†æ•ˆæœä¸é€‰å–çš„å›¾ç‰‡æœ‰å…³ï¼Œå¦‚æœä¸æµ‹è¯•å›¾ç‰‡æ¥è¿‘ï¼Œåˆ™æœ‰å¯èƒ½å–å¾—æ›´å¥½çš„æ•ˆæœã€‚
3. åœ¨æ›´å¤šæ•°æ®ä¸Šä»èƒ½å–å¾—è¾ƒå¥½æ•ˆæœçš„æ¨¡å‹åº”ä¼˜å…ˆé€‰ç”¨ã€‚

# å‚è€ƒæ–‡æ¡£

[é™„å½•ï¼šå¼€å‘æ‰‹å†Œ](https://developer.horizon.ai/api/v1/fileData/doc/cn/source_doc/x3_ddk_docs.html)

## ISSUE

- bash: /home/clover/.local/bin/hb_mapper: æ²¡æœ‰é‚£ä¸ªæ–‡ä»¶æˆ–ç›®å½•æˆ–pythonç‰ˆæœ¬ä¸å…¼å®¹é—®é¢˜ã€‚
    
    åŸå› æ˜¯æ²¡æœ‰è¿›å…¥åˆ°condaç¯å¢ƒçš„binæ‰§è¡Œæ–‡ä»¶å¤¹ä¸­ï¼Œéœ€è¦æ£€æŸ¥bashrcæ–‡ä»¶å¯¹äºPATHçš„è®¾å®šï¼Œæœ‰å¯èƒ½å‡ºç°åœ¨å¿˜è®°è®¾ç½®condaçš„pathæˆ–è€…å¤šè®¾ç½®äº†.localæ–‡ä»¶çš„binæ–‡ä»¶å¤¹ä¸ºPATHã€‚